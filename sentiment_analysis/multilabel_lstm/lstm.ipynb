{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eT8xByt1lymi"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bnVqQvmIlymj",
    "outputId": "40f3f1be-9481-4467-a723-fd5bc5c6be43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (1804874, 9)\n",
      "Test Dataset: (97320, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train Dataset:\", train_data.shape)\n",
    "print(\"Test Dataset:\", test_data.shape)\n",
    "\n",
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "train_data['text'] = train_data['text'].fillna('').apply(clean_text)\n",
    "test_data['text'] = test_data['text'].fillna('').apply(clean_text)\n",
    "\n",
    "# Build vocabulary and tokenize\n",
    "def build_vocab(sentences, max_vocab_size=50000):\n",
    "    counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        counter.update(sentence.split())\n",
    "    vocab = {word: idx + 1 for idx, (word, _) in enumerate(counter.most_common(max_vocab_size))}\n",
    "    vocab['<PAD>'] = 0\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(train_data['text'], max_vocab_size=50000)\n",
    "\n",
    "def text_to_sequence(text, vocab):\n",
    "    return [vocab[word] for word in text.split() if word in vocab]\n",
    "\n",
    "train_data['sequence'] = train_data['text'].apply(lambda x: text_to_sequence(x, vocab))\n",
    "test_data['sequence'] = test_data['text'].apply(lambda x: text_to_sequence(x, vocab))\n",
    "\n",
    "# Labels for multilabel classification\n",
    "labels = ['toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit']\n",
    "y = train_data[labels].values\n",
    "y = (y > 0.5).astype(int)\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data['sequence'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dataset class\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, max_len=512):\n",
    "        self.sequences = [torch.tensor(seq[:max_len], dtype=torch.long) for seq in sequences]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    sequences = pad_sequence(sequences, batch_first=True, padding_value=0).long()\n",
    "    labels = torch.stack(labels)\n",
    "    return sequences, labels\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = CommentDataset(X_train, y_train)\n",
    "val_dataset = CommentDataset(X_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZqZGQ6Tlymk"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c2wJd0B7lymk"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFf1aoI1lyml"
   },
   "source": [
    "w/ conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C0f8hA_6lyml"
   },
   "outputs": [],
   "source": [
    "### Model tests\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size = 3, padding=\"valid\")\n",
    "        self.avgpool = nn.AvgPool1d(2)\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, num_layers=2, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 7)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x, (ht, hc) = self.lstm1(x)\n",
    "\n",
    "        # for bidirectional\n",
    "        hidden = torch.cat((ht[-2,:,:], ht[-1,:,:]), dim = 1)\n",
    "        hidden = self.dropout(hidden)\n",
    "\n",
    "        output = self.fc1(hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc3(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxkU3Qr0lyml"
   },
   "source": [
    "#  Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAn4AK9Vlyml"
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted, actual):\n",
    "    predictions = torch.sigmoid(predicted)\n",
    "    predictions_binary = (predictions > 0.5).float()\n",
    "    correct = (predictions_binary == actual).float().sum()\n",
    "    total = actual.numel()\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def focal_binary_cross_entropy(logits, targets, alpha = 1, gamma=2):\n",
    "    bce_loss = nn.BCEWithLogitsLoss(reduction='none')(logits, targets)\n",
    "    pt = torch.exp(-bce_loss)\n",
    "    focal = alpha * (1-pt)**gamma * bce_loss\n",
    "    loss = focal.mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_model(model, train_dl, val_dl, lr=0.001, num_epochs=3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        val_loss = 0\n",
    "        train_acc = 0\n",
    "        val_acc = 0\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device).float()\n",
    "\n",
    "            output = model(x_batch)\n",
    "            loss = focal_binary_cross_entropy(output, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_acc += accuracy(output, y_batch).item()\n",
    "\n",
    "        model.eval()\n",
    "        for xval_batch, yval_batch in val_dl:\n",
    "            xval_batch = xval_batch.to(device)\n",
    "            yval_batch = yval_batch.to(device).float()\n",
    "\n",
    "            output = model(xval_batch)\n",
    "            loss = focal_binary_cross_entropy(output, yval_batch)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_acc += accuracy(output, yval_batch).item()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}, Train Loss: {running_loss/len(train_dl)}, Train Acc: {train_acc/len(train_dl)}, Val Loss: {val_loss/len(val_dl)}, Val Acc: {val_acc/len(val_dl)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRUROiPFlyml",
    "outputId": "85f8b8e9-cefa-41ea-9797-9a80be596288"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(50001, 512)\n",
       "  (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "  (avgpool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  (lstm1): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(vocab_size, 512, 512)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkqdWhN6lyml",
    "outputId": "e46df638-6a5f-468f-f494-c6eb79f8981e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.011916747608985782, Train Acc: 0.9878492992726166, Val Loss: 0.0093505106980443, Val Acc: 0.989038545640304\n",
      "Epoch: 2, Train Loss: 0.008481274089425263, Train Acc: 0.989717175790823, Val Loss: 0.008422755174751316, Val Acc: 0.9897690068172914\n",
      "Epoch: 3, Train Loss: 0.0075113286404278655, Train Acc: 0.9903123132314176, Val Loss: 0.008078490154353113, Val Acc: 0.9899652735220373\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dl, val_dl, lr=0.0001, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vB8b1i6slymm"
   },
   "outputs": [],
   "source": [
    "test_dataset = CommentDataset(test_data['sequence'], np.zeros((len(test_data), len(labels))))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for sequences, _ in test_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        outputs = model(sequences)\n",
    "\n",
    "        # forgot to add this\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "predictions = np.vstack(predictions)\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Save predictions\n",
    "test_results = pd.DataFrame(predictions_binary, columns=labels)\n",
    "test_results.insert(0, 'id', test_data['id'])\n",
    "test_results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k944t4delymm"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SW9iJEnlymm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangj\\AppData\\Local\\Temp\\ipykernel_28616\\1936407481.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('model.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(50001, 512)\n",
       "  (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "  (avgpool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  (lstm1): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('model.pt')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97315</th>\n",
       "      <td>97315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97316</th>\n",
       "      <td>97316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97317</th>\n",
       "      <td>97317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97318</th>\n",
       "      <td>97318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97319</th>\n",
       "      <td>97319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97320 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  toxicity  severe_toxicity  obscene  threat  insult  \\\n",
       "0          0         0                0        0       0       0   \n",
       "1          1         0                0        0       0       0   \n",
       "2          2         0                0        0       0       0   \n",
       "3          3         0                0        0       0       0   \n",
       "4          4         0                0        0       0       0   \n",
       "...      ...       ...              ...      ...     ...     ...   \n",
       "97315  97315         0                0        0       0       0   \n",
       "97316  97316         0                0        0       0       0   \n",
       "97317  97317         1                0        0       0       1   \n",
       "97318  97318         0                0        0       0       0   \n",
       "97319  97319         0                0        0       0       0   \n",
       "\n",
       "       identity_attack  sexual_explicit  \n",
       "0                    0                0  \n",
       "1                    0                0  \n",
       "2                    0                0  \n",
       "3                    0                0  \n",
       "4                    0                0  \n",
       "...                ...              ...  \n",
       "97315                0                0  \n",
       "97316                0                0  \n",
       "97317                0                0  \n",
       "97318                0                0  \n",
       "97319                0                0  \n",
       "\n",
       "[97320 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = CommentDataset(test_data['sequence'], np.zeros((len(test_data), len(labels))))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for sequences, _ in test_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        outputs = model(sequences)\n",
    "\n",
    "        # forgot to add this\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "predictions = np.vstack(predictions)\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Save predictions\n",
    "test_results = pd.DataFrame(predictions_binary, columns=labels)\n",
    "test_results.insert(0, 'id', test_data['id'])\n",
    "test_results.to_csv('predictions_3.csv', index=False)\n",
    "\n",
    "display(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(predictions, columns=labels)\n",
    "test_results.insert(0, 'id', test_data['id'])\n",
    "test_results.to_csv('predictions_prob.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6073527,
     "sourceId": 9889651,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
