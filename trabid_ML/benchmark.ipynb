{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66de9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from benchmarkUtils import Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ce06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 10000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "TESTING = False\n",
    "TESTING_SIZE = 0.01\n",
    "random_state = 245\n",
    "benchmark_util = Benchmark(iter_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5b9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_val_split(df, random_state=random_state):\n",
    "    X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "        df.iloc[:, :-1], df.iloc[:, -1], test_size=0.3, random_state=random_state\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_tmp, y_tmp, test_size=0.5, random_state=random_state\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f973b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if IN_COLAB:\n",
    "#     prepend_path = (\n",
    "#         \"/content/drive/MyDrive/Syncable/sjsu/data-245/DATA 245 Project Files/data\"\n",
    "#     )\n",
    "# else:\n",
    "#     prepend_path = \"./data\"\n",
    "prepend_path = \"./data\"\n",
    "known_attacks_path = f\"{prepend_path}/probe_known_attacks_small.csv\"\n",
    "similar_attacks_path = f\"{prepend_path}/probe_similar_attacks_small.csv\"\n",
    "new_attacks_path = f\"{prepend_path}/probe_new_attacks_small.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18662787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(known_attacks_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fc26a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85060, 51)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TESTING:\n",
    "    df = df.sample(frac=TESTING_SIZE, random_state=random_state)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97ab2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ip_type', 'ip_len', 'ip_id', 'ip_offset', 'ip_RF', 'ip_DF', 'ip_MF', 'ip_proto', 'ip_checksum', 'udp_sport', 'udp_dport', 'udp_len', 'udp_chk', 'icmp_type', 'icmp_code', 'icmp_chk', 'tcp_sport', 'tcp_dport', 'tcp_seq', 'tcp_ack', 'tcp_ffyn', 'tcp_fsyn', 'tcp_frst', 'tcp_fpush', 'tcp_fack', 'tcp_furg', 'fr_length', 'conn_status', 'count_fr_src_dst', 'count_fr_dst_src', 'count_serv_src_dst', 'count_serv_dst_src', 'num_bytes_src_dst', 'num_bytes_dst_src', 'num_bytes_serv_src_dst', 'num_bytes_serv_dst_src', 'num_pushed_src_dst', 'num_pushed_dst_src', 'num_syn_fin_src_dst', 'num_syn_fin_dst_src', 'num_fin_src_dst', 'num_fin_dst_src', 'num_ack_src_dst', 'num_ack_dst_src', 'num_syn_src_dst', 'num_syn_dst_src', 'num_rst_src_dst', 'num_rst_dst_src', 'first_packet', 'first_serv_packet', 'class'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6108ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_type</th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_id</th>\n",
       "      <th>ip_offset</th>\n",
       "      <th>ip_RF</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>ip_MF</th>\n",
       "      <th>ip_proto</th>\n",
       "      <th>ip_checksum</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_dport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>udp_chk</th>\n",
       "      <th>icmp_type</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_seq</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_frst</th>\n",
       "      <th>tcp_fpush</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>tcp_furg</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>count_fr_src_dst</th>\n",
       "      <th>count_fr_dst_src</th>\n",
       "      <th>count_serv_src_dst</th>\n",
       "      <th>count_serv_dst_src</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_pushed_src_dst</th>\n",
       "      <th>num_pushed_dst_src</th>\n",
       "      <th>num_syn_fin_src_dst</th>\n",
       "      <th>num_syn_fin_dst_src</th>\n",
       "      <th>num_fin_src_dst</th>\n",
       "      <th>num_fin_dst_src</th>\n",
       "      <th>num_ack_src_dst</th>\n",
       "      <th>num_ack_dst_src</th>\n",
       "      <th>num_syn_src_dst</th>\n",
       "      <th>num_syn_dst_src</th>\n",
       "      <th>num_rst_src_dst</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_packet</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>552</td>\n",
       "      <td>13968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>49165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>54640</td>\n",
       "      <td>2925601313</td>\n",
       "      <td>2784850843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>6</td>\n",
       "      <td>416</td>\n",
       "      <td>579</td>\n",
       "      <td>416</td>\n",
       "      <td>579</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>552</td>\n",
       "      <td>13969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>49164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>54640</td>\n",
       "      <td>2925601825</td>\n",
       "      <td>2784850843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>6</td>\n",
       "      <td>416</td>\n",
       "      <td>580</td>\n",
       "      <td>416</td>\n",
       "      <td>580</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>25941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>44274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58502</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>394780220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>56525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>56195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56069</td>\n",
       "      <td>80</td>\n",
       "      <td>7130052</td>\n",
       "      <td>2926006578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>500</td>\n",
       "      <td>16916</td>\n",
       "      <td>500</td>\n",
       "      <td>16916</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>27415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54640</td>\n",
       "      <td>80</td>\n",
       "      <td>2784850843</td>\n",
       "      <td>2925599265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>417</td>\n",
       "      <td>580</td>\n",
       "      <td>417</td>\n",
       "      <td>580</td>\n",
       "      <td>5133</td>\n",
       "      <td>65535</td>\n",
       "      <td>5133</td>\n",
       "      <td>65535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ip_type  ip_len  ip_id  ip_offset  ip_RF  ip_DF  ip_MF  ip_proto  ip_checksum  udp_sport  udp_dport  udp_len  udp_chk  icmp_type  icmp_code  icmp_chk  tcp_sport  tcp_dport     tcp_seq     tcp_ack  tcp_ffyn  tcp_fsyn  tcp_frst  tcp_fpush  tcp_fack  tcp_furg  fr_length  conn_status  count_fr_src_dst  count_fr_dst_src  count_serv_src_dst  count_serv_dst_src  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_pushed_src_dst  num_pushed_dst_src  num_syn_fin_src_dst  num_syn_fin_dst_src  num_fin_src_dst  num_fin_dst_src  num_ack_src_dst  num_ack_dst_src  num_syn_src_dst  num_syn_dst_src  num_rst_src_dst  num_rst_dst_src  first_packet  first_serv_packet   class\n",
       "0        0     552  13968          0      0      0      0         6        49165          0          0        0        0          0          0         0         80      54640  2925601313  2784850843         0         0         0          0         1         0        512            6               416               579                 416                 579               5121              65535                    5121                   65535                   1                   0                    0                    0                0                0              415              579                1                1                0                0             0                  0  normal\n",
       "1        0     552  13969          0      0      0      0         6        49164          0          0        0        0          0          0         0         80      54640  2925601825  2784850843         0         0         0          0         1         0        512            6               416               580                 416                 580               5121              65535                    5121                   65535                   1                   0                    0                    0                0                0              415              580                1                1                0                0             0                  0  normal\n",
       "2        0      40  25941          0      0      0      0         6        44274          0          0        0        0          0          0         0      58502         80           0   394780220         0         0         0          0         1         0          6            1                 1                 0                   1                   0                  6                  0                       6                       0                   0                   0                    0                    0                0                0                1                0                0                0                0                0             1                  1  attack\n",
       "3        0      52  56525          0      0      1      0         6        56195          0          0        0        0          0          0         0      56069         80     7130052  2926006578         0         0         0          0         1         0         12            6                31                37                  31                  37                500              16916                     500                   16916                   1                   0                    0                    0                0                0               30               37                1                1                0                0             0                  0  normal\n",
       "4        0      52  27415          0      0      1      0         6        19834          0          0        0        0          0          0         0      54640         80  2784850843  2925599265         0         0         0          0         1         0         12            6               417               580                 417                 580               5133              65535                    5133                   65535                   1                   0                    0                    0                0                0              416              580                1                1                0                0             0                  0  normal"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82889d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_type</th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_id</th>\n",
       "      <th>ip_offset</th>\n",
       "      <th>ip_RF</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>ip_MF</th>\n",
       "      <th>ip_proto</th>\n",
       "      <th>ip_checksum</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_dport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>udp_chk</th>\n",
       "      <th>icmp_type</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_seq</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_frst</th>\n",
       "      <th>tcp_fpush</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>tcp_furg</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>count_fr_src_dst</th>\n",
       "      <th>count_fr_dst_src</th>\n",
       "      <th>count_serv_src_dst</th>\n",
       "      <th>count_serv_dst_src</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_pushed_src_dst</th>\n",
       "      <th>num_pushed_dst_src</th>\n",
       "      <th>num_syn_fin_src_dst</th>\n",
       "      <th>num_syn_fin_dst_src</th>\n",
       "      <th>num_fin_src_dst</th>\n",
       "      <th>num_fin_dst_src</th>\n",
       "      <th>num_ack_src_dst</th>\n",
       "      <th>num_ack_dst_src</th>\n",
       "      <th>num_syn_src_dst</th>\n",
       "      <th>num_syn_dst_src</th>\n",
       "      <th>num_rst_src_dst</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_packet</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.0</td>\n",
       "      <td>85060.0</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.0</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>8.506000e+04</td>\n",
       "      <td>8.506000e+04</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.754667</td>\n",
       "      <td>100.386174</td>\n",
       "      <td>31165.699577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.039925</td>\n",
       "      <td>33087.734246</td>\n",
       "      <td>7335.142699</td>\n",
       "      <td>4493.626499</td>\n",
       "      <td>7.966353</td>\n",
       "      <td>6440.783964</td>\n",
       "      <td>0.062168</td>\n",
       "      <td>0.054456</td>\n",
       "      <td>620.470245</td>\n",
       "      <td>27821.129226</td>\n",
       "      <td>13938.420973</td>\n",
       "      <td>1.471971e+09</td>\n",
       "      <td>1.008449e+09</td>\n",
       "      <td>0.553903</td>\n",
       "      <td>0.568152</td>\n",
       "      <td>0.527980</td>\n",
       "      <td>0.486151</td>\n",
       "      <td>0.913884</td>\n",
       "      <td>0.473360</td>\n",
       "      <td>65.945121</td>\n",
       "      <td>5.869821</td>\n",
       "      <td>405.885857</td>\n",
       "      <td>520.797084</td>\n",
       "      <td>328.958617</td>\n",
       "      <td>291.029732</td>\n",
       "      <td>10105.989772</td>\n",
       "      <td>28114.899694</td>\n",
       "      <td>8279.352187</td>\n",
       "      <td>17662.463144</td>\n",
       "      <td>40.784376</td>\n",
       "      <td>44.620327</td>\n",
       "      <td>36.238349</td>\n",
       "      <td>74.642147</td>\n",
       "      <td>83.044075</td>\n",
       "      <td>19.918340</td>\n",
       "      <td>162.481060</td>\n",
       "      <td>265.684047</td>\n",
       "      <td>113.913144</td>\n",
       "      <td>30.737621</td>\n",
       "      <td>37.778486</td>\n",
       "      <td>140.026957</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.089560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.925130</td>\n",
       "      <td>191.572060</td>\n",
       "      <td>19906.379891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.450021</td>\n",
       "      <td>18710.567547</td>\n",
       "      <td>17846.337785</td>\n",
       "      <td>13369.749481</td>\n",
       "      <td>21.495346</td>\n",
       "      <td>15363.667022</td>\n",
       "      <td>0.491994</td>\n",
       "      <td>0.400504</td>\n",
       "      <td>4495.728132</td>\n",
       "      <td>24382.931287</td>\n",
       "      <td>20878.971872</td>\n",
       "      <td>1.419588e+09</td>\n",
       "      <td>1.377824e+09</td>\n",
       "      <td>0.820632</td>\n",
       "      <td>0.819572</td>\n",
       "      <td>0.821924</td>\n",
       "      <td>0.822284</td>\n",
       "      <td>0.710662</td>\n",
       "      <td>0.821969</td>\n",
       "      <td>190.189264</td>\n",
       "      <td>4.249343</td>\n",
       "      <td>1235.773115</td>\n",
       "      <td>1367.500610</td>\n",
       "      <td>1956.456315</td>\n",
       "      <td>1413.383988</td>\n",
       "      <td>17353.336438</td>\n",
       "      <td>41288.108509</td>\n",
       "      <td>17651.159114</td>\n",
       "      <td>29433.799558</td>\n",
       "      <td>1117.698208</td>\n",
       "      <td>1485.625396</td>\n",
       "      <td>786.401261</td>\n",
       "      <td>1124.563326</td>\n",
       "      <td>1294.569237</td>\n",
       "      <td>968.524034</td>\n",
       "      <td>1637.743817</td>\n",
       "      <td>1173.387641</td>\n",
       "      <td>1556.568989</td>\n",
       "      <td>1363.660077</td>\n",
       "      <td>1310.832438</td>\n",
       "      <td>666.280141</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.285552</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14018.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16980.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>31076.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>34049.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36378.000000</td>\n",
       "      <td>1057.000000</td>\n",
       "      <td>1.237088e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3989.000000</td>\n",
       "      <td>343.500000</td>\n",
       "      <td>1377.500000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>48434.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>47231.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50326.000000</td>\n",
       "      <td>33354.000000</td>\n",
       "      <td>2.578381e+09</td>\n",
       "      <td>2.032205e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>9528.000000</td>\n",
       "      <td>59434.750000</td>\n",
       "      <td>5046.000000</td>\n",
       "      <td>33812.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>192.000000</td>\n",
       "      <td>4108.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>65534.000000</td>\n",
       "      <td>63399.000000</td>\n",
       "      <td>65024.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>65533.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>65030.000000</td>\n",
       "      <td>65389.000000</td>\n",
       "      <td>65389.000000</td>\n",
       "      <td>4.294916e+09</td>\n",
       "      <td>4.294913e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4068.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>66329.000000</td>\n",
       "      <td>65799.000000</td>\n",
       "      <td>155647.000000</td>\n",
       "      <td>86070.000000</td>\n",
       "      <td>140123.000000</td>\n",
       "      <td>262140.000000</td>\n",
       "      <td>135204.000000</td>\n",
       "      <td>262140.000000</td>\n",
       "      <td>79380.000000</td>\n",
       "      <td>131070.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>125971.000000</td>\n",
       "      <td>65556.000000</td>\n",
       "      <td>65536.000000</td>\n",
       "      <td>130773.000000</td>\n",
       "      <td>65976.000000</td>\n",
       "      <td>131072.000000</td>\n",
       "      <td>95251.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65538.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ip_type        ip_len         ip_id  ip_offset    ip_RF         ip_DF    ip_MF      ip_proto   ip_checksum     udp_sport     udp_dport       udp_len       udp_chk     icmp_type     icmp_code      icmp_chk     tcp_sport     tcp_dport       tcp_seq       tcp_ack      tcp_ffyn      tcp_fsyn      tcp_frst     tcp_fpush      tcp_fack      tcp_furg     fr_length   conn_status  count_fr_src_dst  count_fr_dst_src  count_serv_src_dst  count_serv_dst_src  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_pushed_src_dst  num_pushed_dst_src  num_syn_fin_src_dst  num_syn_fin_dst_src  num_fin_src_dst  num_fin_dst_src  num_ack_src_dst  num_ack_dst_src  num_syn_src_dst  num_syn_dst_src  num_rst_src_dst  num_rst_dst_src  first_packet  first_serv_packet   class\n",
       "count   85060.000000  85060.000000  85060.000000    85060.0  85060.0  85060.000000  85060.0  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  8.506000e+04  8.506000e+04  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000      85060.000000      85060.000000        85060.000000        85060.000000       85060.000000       85060.000000            85060.000000            85060.000000        85060.000000        85060.000000         85060.000000         85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000  85060.000000       85060.000000   85060\n",
       "unique           NaN           NaN           NaN        NaN      NaN           NaN      NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN               NaN               NaN                 NaN                 NaN                NaN                NaN                     NaN                     NaN                 NaN                 NaN                  NaN                  NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN           NaN                NaN       2\n",
       "top              NaN           NaN           NaN        NaN      NaN           NaN      NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN               NaN               NaN                 NaN                 NaN                NaN                NaN                     NaN                     NaN                 NaN                 NaN                  NaN                  NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN           NaN                NaN  normal\n",
       "freq             NaN           NaN           NaN        NaN      NaN           NaN      NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN               NaN               NaN                 NaN                 NaN                NaN                NaN                     NaN                     NaN                 NaN                 NaN                  NaN                  NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN           NaN                NaN   48432\n",
       "mean        0.754667    100.386174  31165.699577        0.0      0.0      0.363931      0.0      8.039925  33087.734246   7335.142699   4493.626499      7.966353   6440.783964      0.062168      0.054456    620.470245  27821.129226  13938.420973  1.471971e+09  1.008449e+09      0.553903      0.568152      0.527980      0.486151      0.913884      0.473360     65.945121      5.869821        405.885857        520.797084          328.958617          291.029732       10105.989772       28114.899694             8279.352187            17662.463144           40.784376           44.620327            36.238349            74.642147        83.044075        19.918340       162.481060       265.684047       113.913144        30.737621        37.778486       140.026957      0.003492           0.089560     NaN\n",
       "std         5.925130    191.572060  19906.379891        0.0      0.0      0.481132      0.0      4.450021  18710.567547  17846.337785  13369.749481     21.495346  15363.667022      0.491994      0.400504   4495.728132  24382.931287  20878.971872  1.419588e+09  1.377824e+09      0.820632      0.819572      0.821924      0.822284      0.710662      0.821969    190.189264      4.249343       1235.773115       1367.500610         1956.456315         1413.383988       17353.336438       41288.108509            17651.159114            29433.799558         1117.698208         1485.625396           786.401261          1124.563326      1294.569237       968.524034      1637.743817      1173.387641      1556.568989      1363.660077      1310.832438       666.280141      0.058987           0.285552     NaN\n",
       "min         0.000000     28.000000      0.000000        0.0      0.0      0.000000      0.0      1.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000  0.000000e+00  0.000000e+00      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      1.000000          0.000000          0.000000            0.000000            0.000000           0.000000           0.000000                0.000000                0.000000            0.000000            0.000000             0.000000             0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000      0.000000           0.000000     NaN\n",
       "25%         0.000000     40.000000  14018.000000        0.0      0.0      0.000000      0.0      6.000000  16980.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000     80.000000     80.000000  0.000000e+00  0.000000e+00      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      6.000000      2.000000         39.000000         38.000000            5.000000            2.000000         813.000000          18.000000               30.000000                0.000000            0.000000            0.000000             0.000000             0.000000         0.000000         0.000000         1.000000         1.000000         1.000000         0.000000         0.000000         0.000000      0.000000           0.000000     NaN\n",
       "50%         0.000000     52.000000  31076.500000        0.0      0.0      0.000000      0.0      6.000000  34049.500000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000  36378.000000   1057.000000  1.237088e+09  0.000000e+00      0.000000      0.000000      0.000000      0.000000      1.000000      0.000000     12.000000      6.000000        250.000000        301.000000           94.000000           56.000000        3989.000000         343.500000             1377.500000              125.000000            0.000000            0.000000             0.000000             0.000000         0.000000         0.000000        11.000000        77.000000         1.000000         1.000000         0.000000         2.000000      0.000000           0.000000     NaN\n",
       "75%         0.000000     60.000000  48434.500000        0.0      0.0      1.000000      0.0      6.000000  47231.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000  50326.000000  33354.000000  2.578381e+09  2.032205e+09      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000     20.000000      8.000000        651.000000        763.000000          461.000000          386.000000        9528.000000       59434.750000             5046.000000            33812.000000            3.000000            0.000000             0.000000             0.000000         2.000000         1.000000       135.000000       384.000000         3.000000         2.000000         0.000000        78.000000      0.000000           0.000000     NaN\n",
       "max       192.000000   4108.000000  65535.000000        0.0      0.0      1.000000      0.0     17.000000  65534.000000  63399.000000  65024.000000    200.000000  65533.000000     14.000000      3.000000  65030.000000  65389.000000  65389.000000  4.294916e+09  4.294913e+09      2.000000      2.000000      2.000000      2.000000      2.000000      2.000000   4068.000000     15.000000      66329.000000      65799.000000       155647.000000        86070.000000      140123.000000      262140.000000           135204.000000           262140.000000        79380.000000       131070.000000         65535.000000        125971.000000     65556.000000     65536.000000    130773.000000     65976.000000    131072.000000     95251.000000     65535.000000     65538.000000      1.000000           1.000000     NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b81c59",
   "metadata": {},
   "source": [
    "It seems as though ip_RF, ip_MF, and ip_offset do not contain any valuable information. They can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ea437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ip_RF\", \"ip_MF\", \"ip_offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1372f388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ip_type', 'ip_len', 'ip_id', 'ip_DF', 'ip_proto', 'ip_checksum', 'udp_sport', 'udp_dport', 'udp_len', 'udp_chk', 'icmp_type', 'icmp_code', 'icmp_chk', 'tcp_sport', 'tcp_dport', 'tcp_seq', 'tcp_ack', 'tcp_ffyn', 'tcp_fsyn', 'tcp_frst', 'tcp_fpush', 'tcp_fack', 'tcp_furg', 'fr_length', 'conn_status', 'count_fr_src_dst', 'count_fr_dst_src', 'count_serv_src_dst', 'count_serv_dst_src', 'num_bytes_src_dst', 'num_bytes_dst_src', 'num_bytes_serv_src_dst', 'num_bytes_serv_dst_src', 'num_pushed_src_dst', 'num_pushed_dst_src', 'num_syn_fin_src_dst', 'num_syn_fin_dst_src', 'num_fin_src_dst', 'num_fin_dst_src', 'num_ack_src_dst', 'num_ack_dst_src', 'num_syn_src_dst', 'num_syn_dst_src', 'num_rst_src_dst', 'num_rst_dst_src', 'first_packet', 'first_serv_packet', 'class'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b32ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "normal    48432\n",
      "attack    36628\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "normal    56.938632\n",
      "attack    43.061368\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"class\"].value_counts())\n",
    "print(df[\"class\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60be66c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ip_type                    int64\n",
       "ip_len                     int64\n",
       "ip_id                      int64\n",
       "ip_DF                      int64\n",
       "ip_proto                   int64\n",
       "ip_checksum                int64\n",
       "udp_sport                  int64\n",
       "udp_dport                  int64\n",
       "udp_len                    int64\n",
       "udp_chk                    int64\n",
       "icmp_type                  int64\n",
       "icmp_code                  int64\n",
       "icmp_chk                   int64\n",
       "tcp_sport                  int64\n",
       "tcp_dport                  int64\n",
       "tcp_seq                    int64\n",
       "tcp_ack                    int64\n",
       "tcp_ffyn                   int64\n",
       "tcp_fsyn                   int64\n",
       "tcp_frst                   int64\n",
       "tcp_fpush                  int64\n",
       "tcp_fack                   int64\n",
       "tcp_furg                   int64\n",
       "fr_length                  int64\n",
       "conn_status                int64\n",
       "count_fr_src_dst           int64\n",
       "count_fr_dst_src           int64\n",
       "count_serv_src_dst         int64\n",
       "count_serv_dst_src         int64\n",
       "num_bytes_src_dst          int64\n",
       "num_bytes_dst_src          int64\n",
       "num_bytes_serv_src_dst     int64\n",
       "num_bytes_serv_dst_src     int64\n",
       "num_pushed_src_dst         int64\n",
       "num_pushed_dst_src         int64\n",
       "num_syn_fin_src_dst        int64\n",
       "num_syn_fin_dst_src        int64\n",
       "num_fin_src_dst            int64\n",
       "num_fin_dst_src            int64\n",
       "num_ack_src_dst            int64\n",
       "num_ack_dst_src            int64\n",
       "num_syn_src_dst            int64\n",
       "num_syn_dst_src            int64\n",
       "num_rst_src_dst            int64\n",
       "num_rst_dst_src            int64\n",
       "first_packet               int64\n",
       "first_serv_packet          int64\n",
       "class                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f50d06c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ip_type\n",
       "0      83516\n",
       "40      1528\n",
       "192       16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ip_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5069353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = df[\"class\"].replace({\"normal\": 0, \"attack\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e84b89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "692a08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "029181b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0d73b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                     1.000000\n",
       "tcp_sport                 0.376711\n",
       "first_serv_packet         0.288401\n",
       "tcp_fsyn                  0.183862\n",
       "tcp_ffyn                  0.179369\n",
       "udp_sport                 0.159150\n",
       "num_rst_dst_src           0.148479\n",
       "tcp_furg                  0.081623\n",
       "ip_id                     0.070370\n",
       "ip_proto                  0.068846\n",
       "tcp_fpush                 0.068064\n",
       "udp_chk                   0.050838\n",
       "udp_dport                 0.043169\n",
       "num_syn_fin_dst_src       0.032562\n",
       "num_syn_src_dst           0.023503\n",
       "num_fin_src_dst           0.018179\n",
       "count_fr_dst_src          0.016557\n",
       "num_syn_fin_src_dst       0.010139\n",
       "num_pushed_src_dst       -0.005405\n",
       "num_pushed_dst_src       -0.006834\n",
       "num_fin_dst_src          -0.008403\n",
       "num_rst_src_dst          -0.008925\n",
       "count_serv_src_dst       -0.010181\n",
       "ip_checksum              -0.015762\n",
       "num_syn_dst_src          -0.017306\n",
       "count_fr_src_dst         -0.018505\n",
       "first_packet             -0.032560\n",
       "num_ack_dst_src          -0.042007\n",
       "num_ack_src_dst          -0.055285\n",
       "count_serv_dst_src       -0.058866\n",
       "icmp_type                -0.076590\n",
       "tcp_seq                  -0.082221\n",
       "tcp_frst                 -0.089140\n",
       "ip_type                  -0.098455\n",
       "icmp_chk                 -0.106911\n",
       "icmp_code                -0.115398\n",
       "num_bytes_serv_src_dst   -0.205258\n",
       "conn_status              -0.217683\n",
       "udp_len                  -0.244732\n",
       "fr_length                -0.249022\n",
       "ip_len                   -0.265645\n",
       "num_bytes_src_dst        -0.275082\n",
       "tcp_dport                -0.302774\n",
       "ip_DF                    -0.305169\n",
       "tcp_fack                 -0.406649\n",
       "tcp_ack                  -0.456281\n",
       "num_bytes_serv_dst_src   -0.520069\n",
       "num_bytes_dst_src        -0.535816\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr[\"class\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2ed53",
   "metadata": {},
   "source": [
    "The target feature does not seem to have very strong correlations with any particular feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84eb5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all features with an absolute correlation of less than 0.1\n",
    "cols_corr_gt1 = corr[\"class\"][abs(corr[\"class\"]) > 0.1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1861e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ip_len', 'ip_DF', 'udp_sport', 'udp_len', 'icmp_code', 'icmp_chk', 'tcp_sport', 'tcp_dport', 'tcp_ack', 'tcp_ffyn', 'tcp_fsyn', 'tcp_fack', 'fr_length', 'conn_status', 'num_bytes_src_dst', 'num_bytes_dst_src', 'num_bytes_serv_src_dst', 'num_bytes_serv_dst_src', 'num_rst_dst_src', 'first_serv_packet', 'class'], dtype='object')\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(cols_corr_gt1)\n",
    "print(len(cols_corr_gt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c44e95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHcCAYAAAAqQ4tyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACaZklEQVR4nOzdd1wT9x8G8CdhhL1kKSIq4sCFW9wDxT2rqK0DrdqqrYqtra271tmqrXtbba2zta3bUkdV3HsvFBVZInuF5Pv7g5KfMaAJBhPweb9evjSXy+ee3IXw8e57dxIhhAARERFRMSE1dAAiIiIifWJzQ0RERMUKmxsiIiIqVtjcEBERUbHC5oaIiIiKFTY3REREVKywuSEiIqJihc0NERERFStsboiIiKhYYXNTTA0aNAhly5bVa83169dDIpHgwYMHeq1rzCQSCaZOnarz6w4fPgyJRILDhw/rPZM2Cpq7sBh6fdCby/35P3v2rKGjaOXOnTto27Yt7O3tIZFIsHPnTkNHoreIzc0r3Lt3D8OHD0f58uVhYWEBOzs7NG7cGD/88APS09MNHa/QzJw5k18ERAYwdepUSCQSuLm5IS0tTeP5smXLolOnTgZIVvQMHDgQV65cwbfffouNGzeibt26ho70Tlq6dCnWr1//1pdr+taXWETs3r0bvXr1gkwmw4ABA1CtWjVkZWXh2LFj+Pzzz3Ht2jWsXLnS0DELxcyZM/Hee++hW7duatP79++PPn36QCaTGSZYEdKsWTOkp6fD3Nzc0FGMAteHbmJiYrBs2TKMGzfO0FGKpPT0dISFheHrr7/GqFGjDB3nnbZ06VI4Oztj0KBBb3W5bG7yEB4ejj59+sDLywv//PMPSpYsqXpu5MiRuHv3Lnbv3m3AhIZhYmICExMTQ8coEqRSKSwsLAwdw+AyMjJgbm7O9aEjPz8/zJs3DyNGjIClpaWh47xVqampsLa2fqMasbGxAAAHBwc9JKKiiIel8jB37lykpKRgzZo1ao1NrgoVKmD06NEAgAcPHkAikeS52+3lcQ+5u5xv376NDz74APb29nBxccGkSZMghMCjR4/QtWtX2NnZwd3dHd9//71avfzGvGg7nuG7775Do0aNUKJECVhaWqJOnTrYvn27RubU1FT89NNPkEgkkEgkqo775eV36tQJ5cuXz3NZ/v7+GruBf/75Z9SpUweWlpZwcnJCnz598OjRo1dmzvXkyRMMHjwYbm5ukMlkqFq1KtauXat6Pj09HZUrV0blypXVDhnGx8ejZMmSaNSoERQKBYCc8Ug2Nja4f/8+AgMDYW1tjVKlSmH69OkQQrwyx8OHDzFixAhUqlQJlpaWKFGiBHr16qXVNmnRogWqVauG69evo2XLlrCysoKHhwfmzp2rsZzMzExMmTIFFSpUgEwmg6enJ8aPH4/MzEyN+caOHQsXFxfY2tqiS5cuePz48WvXZ3R0NExNTTFt2jSN527dugWJRILFixer1uFnn32G6tWrw8bGBnZ2dmjfvj0uXbqU53vevHkzJk6cCA8PD1hZWSEpKSnP9fHvv/+iV69eKFOmjOo9jh07VuOQb+72evLkCbp16wYbGxu4uLjgs88+U23TXEqlEj/88AOqV68OCwsLuLi4oF27dhrjRAryWdy+fTskEgmOHDmi8dyKFSsgkUhw9epVAEBUVBSCg4NRunRpyGQylCxZEl27dtV6vNrkyZMRHR2NZcuWvXK+/H728/peyl2PERER6NSpE2xsbODh4YElS5YAAK5cuYJWrVrB2toaXl5e2LRpU57LTEtLw/Dhw1GiRAnY2dlhwIABeP78ucZ8e/fuRdOmTWFtbQ1bW1t07NgR165dU5snN9O9e/fQoUMH2Nra4v3333/le75w4QLat28POzs72NjYoHXr1jh58qTq+alTp8LLywsA8Pnnn0Mikbx2/GFGRgamTp2KihUrwsLCAiVLlkSPHj1w79491TypqakYN24cPD09IZPJUKlSJXz33Xca3xkSiQSjRo3Ctm3b4OvrC0tLS/j7++PKlSsAcj4rFSpUgIWFBVq0aKHxmcj9njh37hwaNWoES0tLlCtXDsuXL9fIHRMTgyFDhsDNzQ0WFhaoWbMmfvrpJ7V5cj8L3333HVauXAlvb2/IZDLUq1cPZ86c0ah58+ZNvPfee3BycoKFhQXq1q2LP//8U22e3N8Fx48fR0hICFxcXGBtbY3u3burGksg5zDqtWvXcOTIEdXvkxYtWgAA5HI5pk2bBh8fH1hYWKBEiRJo0qQJDh48+MptpTVBGjw8PET58uW1mjc8PFwAEOvWrdN4DoCYMmWK6vGUKVMEAOHn5yf69u0rli5dKjp27CgAiPnz54tKlSqJjz/+WCxdulQ0btxYABBHjhxRvX7dunUCgAgPD1dbzqFDhwQAcejQIdW0gQMHCi8vL7X5SpcuLUaMGCEWL14s5s+fL+rXry8AiF27dqnm2bhxo5DJZKJp06Zi48aNYuPGjeLEiRN5Ln/Dhg0CgDh9+rTach48eCAAiHnz5qmmzZgxQ0gkEhEUFCSWLl0qpk2bJpydnUXZsmXF8+fPX7mOo6KiROnSpYWnp6eYPn26WLZsmejSpYsAIBYsWKCa7+TJk8LExESMHTtWNa1Pnz7C0tJS3Lp1S23dWFhYCB8fH9G/f3+xePFi0alTJwFATJo0SW3ZL2/Dbdu2iZo1a4rJkyeLlStXiq+++ko4OjoKLy8vkZqa+spt0rx5c1GqVCnh6ekpRo8eLZYuXSpatWolAIg9e/ao5lMoFKJt27bCyspKjBkzRqxYsUKMGjVKmJqaiq5du6rl++CDDwQA0a9fP7F48WLRo0cPUaNGDY3ceWnVqpXw9fXVmD5t2jRhYmIioqKihBBCnDlzRnh7e4svv/xSrFixQkyfPl14eHgIe3t78eTJE4337OvrK/z8/MT8+fPFrFmzRGpqap7r45NPPhEdOnQQM2fOFCtWrBBDhgwRJiYm4r333lPLk7u9qlatKgYPHiyWLVsmevbsKQCIpUuXqs07aNAgAUC0b99eLFy4UHz33Xeia9euYtGiRap5CvpZTEtLEzY2NmLEiBEaz7Vs2VJUrVpV9bhRo0bC3t5eTJw4UaxevVrMnDlTtGzZUu3nOS+53xGxsbGiVatWws3NTaSlpame9/LyEh07dtRY5y+uVyHy/l7KXY++vr7io48+EkuWLBGNGjVSzVeqVCnx+eefi0WLFomqVasKExMTcf/+fdXrc3/+q1evLpo2bSp+/PFHMXLkSCGVSkWzZs2EUqlUzbthwwYhkUhEu3btxKJFi8ScOXNE2bJlhYODg9r318CBA4VMJhPe3t5i4MCBYvny5WLDhg35rp+rV68Ka2trUbJkSfHNN9+I2bNni3LlygmZTCZOnjwphBDi0qVLYsGCBQKA6Nu3r9i4caP4/fff862ZnZ0tWrduLQCIPn36iMWLF4tZs2aJVq1aiZ07dwohhFAqlaJVq1ZCIpGIDz/8UCxevFh07txZABBjxoxRqwdA1KhRQ3h6eorZs2eL2bNnC3t7e1GmTBmxePFi4evrK77//nsxceJEYW5uLlq2bKn2+tzvCVdXVzFq1Cjx448/iiZNmggAYs2aNar50tLSRJUqVYSZmZkYO3as+PHHH0XTpk0FALFw4UKNz0KtWrVEhQoVxJw5c8TcuXOFs7OzKF26tMjKylJbv/b29sLX11fMmTNHLF68WDRr1kxIJBLx22+/aXwWatWqJVq1aiUWLVokxo0bJ0xMTETv3r1V8/3++++idOnSonLlyqrfJwcOHBBCCPHVV18JiUQihg4dKlatWiW+//570bdvXzF79ux8t5Uu2Ny8JDExUQDQ+CWSn4I0N8OGDVNNy87OFqVLlxYSiURtoz5//lxYWlqKgQMHqqa9aXPz4pekEEJkZWWJatWqiVatWqlNt7a2VltufstPTEwUMplMjBs3Tm2+uXPnColEIh4+fCiEyGl2TExMxLfffqs235UrV4SpqanG9JcNGTJElCxZUsTFxalN79Onj7C3t1d7XxMmTBBSqVQcPXpUbNu2TeMHXYicdQNAfPLJJ6ppSqVSdOzYUZibm4vY2FjV9Je34cvrUAghwsLCBAC1L+X8mpuX58vMzBTu7u6iZ8+eqmkbN24UUqlU/Pvvv2rLWb58uQAgjh8/LoQQ4uLFiwKAxi/bfv36adXcrFixQgAQV65cUZvu6+ur9pnIyMgQCoVCbZ7w8HAhk8nE9OnTNd5z+fLlNdZTXusjr3U5a9Ystc+OEP/fXi8uSwghatWqJerUqaN6/M8//wgA4tNPP9Wom/uL900/i3379hWurq4iOztbNe3p06dCKpWq8j1//lyjudfWi83NkSNHVP/xyfWmzQ0AMXPmTNW03O8ZiUQiNm/erJp+8+ZNjc9Q7s9/nTp11H4hzp07VwAQf/zxhxBCiOTkZOHg4CCGDh2qlikqKkrY29urTc/N9OWXX2q1frp16ybMzc3FvXv3VNMiIyOFra2taNasmcb712YbrF27VmM958r93OzcuVMAEDNmzFB7/r333hMSiUTcvXtXNQ2AkMlkat/TuT9r7u7uIikpSTV9woQJGt/pud8T33//vWpaZmam8PPzE66urqp1v3DhQgFA/Pzzz6r5srKyhL+/v7CxsVEtJ3ddlChRQsTHx6vm/eOPPwQA8ddff6mmtW7dWlSvXl1kZGSorYNGjRoJHx8f1bTcz0JAQIBaUzt27FhhYmIiEhISVNOqVq0qmjdvrrFua9asqfZZ1jcelnpJUlISAMDW1rbQlvHhhx+q/m1iYoK6detCCIEhQ4aopjs4OKBSpUq4f/++3pb74rH758+fIzExEU2bNsX58+cLVC/38MTWrVvVds1u2bIFDRs2RJkyZQAAv/32G5RKJXr37o24uDjVH3d3d/j4+ODQoUP5LkMIgR07dqBz584QQqi9PjAwEImJiWr5p06diqpVq2LgwIEYMWIEmjdvjk8//TTP2i8ONMzdlZyVlYW///473zwvrkO5XI5nz56hQoUKcHBw0Go92tjY4IMPPlA9Njc3R/369dW287Zt21ClShVUrlxZ7f22atUKAFTra8+ePQCg8f7GjBnz2hwA0KNHD5iammLLli2qaVevXsX169cRFBSkmiaTySCV5nxVKBQKPHv2DDY2NqhUqVKe73ngwIFajRN5cZ7U1FTExcWhUaNGEELgwoULGvN/9NFHao+bNm2qtt527NgBiUSCKVOmaLxWIpEAeLPPIgAEBQUhJiZG7TDQ9u3boVQqVevM0tIS5ubmOHz4cJ6Ha7TVrFkztGzZEnPnztXr2Zkvfv/kfs9YW1ujd+/equmVKlWCg4NDnt8/w4YNg5mZmerxxx9/DFNTU9Xn8eDBg0hISEDfvn3V1rGJiQkaNGiQ5zr++OOPX5tboVDgwIED6Natm9rh8JIlS6Jfv344duyY6vtbFzt27ICzszM++eQTjedyPzd79uyBiYmJxs/auHHjIITA3r171aa3bt1a7VBYgwYNAAA9e/ZU+92SO/3l9Wxqaorhw4erHpubm2P48OGIiYnBuXPnVJnc3d3Rt29f1XxmZmb49NNPkZKSonH4NCgoCI6OjqrHTZs2VVt2fHw8/vnnH/Tu3RvJycmq7fbs2TMEBgbizp07ePLkiVrNYcOGqdZRbk2FQoGHDx/idRwcHHDt2jXcuXPntfMWBJubl9jZ2QEAkpOTC20Zub/0c9nb28PCwgLOzs4a09/ky/Flu3btQsOGDWFhYQEnJye4uLhg2bJlSExMLHDNoKAgPHr0CGFhYQByTp8/d+6c2i/HO3fuQAgBHx8fuLi4qP25ceMGYmJi8q0fGxuLhIQErFy5UuO1wcHBAKD2enNzc6xduxbh4eFITk7GunXr1H74ckmlUo3xQhUrVgSAV46LSE9Px+TJk1XH3Z2dneHi4oKEhASt1mPp0qU18jg6Oqpt5zt37uDatWsa7zc3X+77ffjwIaRSKby9vdXqVapU6bU5AMDZ2RmtW7fG1q1bVdO2bNkCU1NT9OjRQzVNqVRiwYIF8PHxUXvPly9fzvM9lytXTqvlR0REYNCgQXByclKNo2nevDkAaNTNHT/zopfX271791CqVCk4OTnlu8w3+SwCQLt27WBvb6/WEG7ZsgV+fn6q7SOTyTBnzhzs3bsXbm5uaNasGebOnYuoqCit1suLpk6diqioqDzHWxREXuvR3t4+z89lft8/Pj4+ao9tbGxQsmRJ1c9N7i+rVq1aaazjAwcOaKxjU1NTlC5d+rXZY2NjkZaWlufnu0qVKlAqlVqP4XvRvXv3UKlSJZia5n9+zcOHD1GqVCmN//RWqVJF9fyL8vqOBwBPT888p7+8nkuVKqUxqPrl76eHDx/Cx8dH9R8PXTPlNjq5y7579y6EEJg0aZLGdsv9D8PL2+51NV9l+vTpSEhIQMWKFVG9enV8/vnnuHz58mtfpy2eLfUSOzs7lCpVSjUw8HXy+sUJQGOg44vyOuMov7OQXtwjUpBl5fr333/RpUsXNGvWDEuXLkXJkiVhZmaGdevW5TtwUBudO3eGlZUVtm7dikaNGmHr1q2QSqXo1auXah6lUgmJRIK9e/fm+T5tbGzyra9UKgEAH3zwAQYOHJjnPDVq1FB7vH//fgA5gwTv3Lmj9S9bbXzyySdYt24dxowZA39/f9UFwvr06aPK+irabGelUonq1atj/vz5ec778hfkm+jTpw+Cg4Nx8eJF+Pn5YevWrWjdurVaoz1z5kxMmjQJgwcPxjfffAMnJydIpVKMGTMmz/eszV4bhUKBNm3aID4+Hl988QUqV64Ma2trPHnyBIMGDdKoq6+z9N7kswjkNC7dunXD77//jqVLlyI6OhrHjx/HzJkz1eYbM2YMOnfujJ07d2L//v2YNGkSZs2ahX/++Qe1atXSOm+zZs3QokULzJ07V2PPFaD7d0J+61Gbz6W2crfdxo0b4e7urvH8y03Ei3sGi4u3sZ519bpl5263zz77DIGBgXnOW6FCBZ1qvkqzZs1w7949/PHHHzhw4ABWr16NBQsWYPny5Wp7FwuKzU0eOnXqhJUrVyIsLAz+/v6vnDe3U01ISFCbrs1uOV29ybJ27NgBCwsL7N+/X+06NevWrdOYN78vzLxYW1ujU6dO2LZtG+bPn48tW7agadOmKFWqlGoeb29vCCFQrlw51f8+tJV7FpBCoUBAQMBr5798+TKmT5+u+oX94Ycf4sqVK6r/IeVSKpW4f/++Wp7bt28DwCvPrNi+fTsGDhyodiZbRkaGxjZ5E97e3rh06RJat279ym3h5eUFpVKp+p9nrlu3bmm9rG7dumH48OGqPRG3b9/GhAkT1ObZvn07WrZsiTVr1qhNT0hI0NjbqK0rV67g9u3b+OmnnzBgwADV9Dc5U8Lb2xv79+9HfHx8vntv3uSzmCsoKAg//fQTQkNDcePGDQgh1PZUvriscePGYdy4cbhz5w78/Pzw/fff4+eff9ZpeVOnTkWLFi2wYsUKjefe5vdPrjt37qBly5aqxykpKXj69Ck6dOgAAKo9ia6urlr9zGrLxcUFVlZWeX6+b968CalUWqDG39vbG6dOnYJcLlc73PYiLy8v/P3330hOTlbbe3Pz5k3V8/oUGRmpcUr8y99PXl5euHz5MpRKpVpzWNBMuXuyzczM9LrdXvUd5uTkhODgYAQHByMlJQXNmjXD1KlT9dLcFK92WU/Gjx8Pa2trfPjhh4iOjtZ4/t69e/jhhx8A5OzpcXZ2xtGjR9XmWbp0qd5z5X5pvLgshUKh1cUETUxMIJFI1P5H9+DBgzyvRGxtba3TL+ugoCBERkZi9erVuHTpksYXfY8ePWBiYoJp06ZpdPRCCDx79uyVuXv27IkdO3bkuTftxdMO5XI5Bg0ahFKlSuGHH37A+vXrER0djbFjx+ZZO/dU59wcixcvhpmZGVq3bv3KPC+/h0WLFmm190xbvXv3xpMnT7Bq1SqN59LT05GamgoAaN++PQDgxx9/VJtn4cKFWi/LwcEBgYGB2Lp1KzZv3gxzc3ONizfm9Z63bdumcfxdF7n/43uxrhBC9XNVED179oQQIs/T23OX8yafxVwBAQFwcnLCli1bsGXLFtSvX19t72BaWhoyMjLUXuPt7Q1bW1uNU/m10bx5c7Ro0QJz5szRqOvl5QUTE5O38v2Ta+XKlZDL5arHy5YtQ3Z2turzGBgYCDs7O8ycOVNtvlwv/szqwsTEBG3btsUff/yhdug4OjoamzZtQpMmTVTDCnTRs2dPxMXFqX0f5Mr9jHTo0AEKhUJjngULFkAikajeu75kZ2erNbNZWVlYsWIFXFxcUKdOHVWmqKgotUOk2dnZWLRoEWxsbFSHeLXl6uqqaqKfPn2q8XxBt1t+v09e/lmzsbFBhQoVCvQzkhfuucmDt7c3Nm3ahKCgIFSpUkXtCsUnTpzAtm3b1K62+OGHH2L27Nn48MMPUbduXRw9elTVZetT1apV0bBhQ0yYMEH1v9PNmzcjOzv7ta/t2LEj5s+fj3bt2qFfv36IiYnBkiVLUKFCBY3jnHXq1MHff/+N+fPno1SpUihXrpxq4Ftecq9P8dlnn6makRd5e3tjxowZmDBhAh48eIBu3brB1tYW4eHh+P333zFs2DB89tln+dafPXs2Dh06hAYNGmDo0KHw9fVFfHw8zp8/j7///hvx8fEAgBkzZuDixYsIDQ2Fra0tatSogcmTJ2PixIl47733VP+zBHLGHuzbtw8DBw5EgwYNsHfvXuzevRtfffWVxpiEF3Xq1AkbN26Evb09fH19ERYWhr///hslSpR45frXRf/+/bF161Z89NFHOHToEBo3bgyFQoGbN29i69at2L9/P+rWrQs/Pz/07dsXS5cuRWJiIho1aoTQ0FDcvXtXp+UFBQXhgw8+wNKlSxEYGKhx4bNOnTqp9oY1atQIV65cwS+//JLvNY60UblyZXh7e+Ozzz7DkydPYGdnhx07drzRGLOWLVuif//++PHHH3Hnzh20a9cOSqUS//77L1q2bIlRo0a98WcRyPmfbY8ePbB582akpqbiu+++U3v+9u3baN26NXr37g1fX1+Ympri999/R3R0NPr06VOg9zZlyhS1vSW57O3t0atXLyxatAgSiQTe3t7YtWvXa8cOvYmsrCzV+7t16xaWLl2KJk2aoEuXLgBy/sO3bNky9O/fH7Vr10afPn3g4uKCiIgI7N69G40bN86zkdDGjBkzcPDgQTRp0gQjRoyAqakpVqxYgczMzDyvF6WNAQMGYMOGDQgJCcHp06fRtGlTpKam4u+//8aIESPQtWtXdO7cGS1btsTXX3+NBw8eoGbNmjhw4AD++OMPjBkzRmPc25sqVaoU5syZgwcPHqBixYrYsmULLl68iJUrV6r2Lg0bNgwrVqzAoEGDcO7cOZQtWxbbt2/H8ePHsXDhwgKdFLNkyRI0adIE1atXx9ChQ1G+fHlER0cjLCwMjx8/1ri2lTbq1KmDZcuWYcaMGahQoQJcXV3RqlUr+Pr6okWLFqhTpw6cnJxw9uxZbN++XX9XlC6087CKgdu3b4uhQ4eKsmXLCnNzc2FraysaN24sFi1apHaqXFpamhgyZIiwt7cXtra2onfv3iImJibfU8FfPNVYiJzTIa2trTWW37x5c7VrZwghxL1790RAQICQyWTCzc1NfPXVV+LgwYNanQq+Zs0a4ePjI2QymahcubJYt26dKtOLbt68KZo1ayYsLS0FANVp4fmdii6EEO+//77q1MD87NixQzRp0kRYW1sLa2trUblyZTFy5Ei1a9DkJzo6WowcOVJ4enoKMzMz4e7uLlq3bi1WrlwphBDi3LlzwtTUVO30biFyTrWvV6+eKFWqlOoaJrnr+969e6rrybi5uYkpU6ZonPL88jZ8/vy5CA4OFs7OzsLGxkYEBgaKmzdvCi8vL7XT5/M7Ffzl7Zmb5+VtlZWVJebMmSOqVq0qZDKZcHR0FHXq1BHTpk0TiYmJqvnS09PFp59+KkqUKCGsra1F586dxaNHj7Q6FTxXUlKSalu/eFpproyMDDFu3DhRsmRJYWlpKRo3bizCwsJE8+bN1U7xzH3P27Zt06iR1/q4fv26CAgIEDY2NsLZ2VkMHTpUXLp0Kc9TmPP6+cjrs5udnS3mzZsnKleuLMzNzYWLi4to3769OHfunNp8b/JZFEKofuYkEol49OiR2nNxcXFi5MiRonLlysLa2lrY29uLBg0aiK1bt762bn7fEUL8/xThl0+fjY2NFT179hRWVlbC0dFRDB8+XFy9elXr9Zjf5/Ll085zf/6PHDkihg0bJhwdHYWNjY14//33xbNnzzRef+jQIREYGCjs7e2FhYWF8Pb2FoMGDRJnz559baZXOX/+vAgMDBQ2NjbCyspKtGzZUnUtrly6nAouRM53+Ndffy3KlSun+n5577331E45T05OFmPHjhWlSpUSZmZmwsfHR8ybN0/tVGghcr4zRo4cqVWevH5mcrfH2bNnhb+/v7CwsBBeXl5i8eLFGrmjo6NV30fm5uaievXqGpcledW6yOt74t69e2LAgAHC3d1dmJmZCQ8PD9GpUyexfft21Ty5n4UzZ87k+X5e/DmPiooSHTt2FLa2tgKA6jtjxowZon79+sLBwUFYWlqKypUri2+//VbtMgNvQvLfGyR6ZwwaNAjbt29HSkqKoaMQEalp0aIF4uLitD6phfLGMTdERERUrLC5ISIiomKFzQ0REREVKxxzQ0RERMUK99wQERFRscLmhoiIiIoVNjdERdT69eshkUheeaNPyiGRSDB16tS3sqwWLVqgRYsWb2VZunrw4AEkEgnWr19v6ChEhYrNDdFbMHXqVEgkEsTFxeX5fLVq1Yz2F2J+jh07hvbt28PDwwMWFhYoU6YMOnfurHYj1rS0NEydOhWHDx82XFAjlZWVhR9++AG1atWCnZ0dHBwcULVqVQwbNkx1fyAiKhjefoGoiOrfvz/69OmjdiPUt2Xbtm0ICgqCn58fRo8eDUdHR4SHh+Po0aNYtWoV+vXrByCnucm911NRa94KW8+ePbF371707dsXQ4cOhVwux82bN7Fr1y40atQIlStXNnREoiKLzQ1REWViYqK6AeXbNnXqVPj6+uLkyZMwNzdXe64w72tkDF6+W3NBnDlzBrt27cK3336Lr776Su25xYsX6/Uu84VJH+uCqDDwsBSRkVq0aBGqVq0KKysrODo6om7dumqHfPIac1O2bFl06tQJx44dQ/369WFhYYHy5ctjw4YNGvUvX76M5s2bw9LSEqVLl8aMGTOwbt06rcbx3Lt3D/Xq1dNobICcuwsDOeM7cm9COm3aNEgkErWxL5cvX8agQYNQvnx5WFhYwN3dHYMHD9a4W3DuIb27d+9i0KBBcHBwgL29PYKDg5GWlqY2b2ZmJsaOHQsXFxfY2tqiS5cuePz4sUbGhw8fYsSIEahUqRIsLS1RokQJ9OrVS+N9567jI0eOYMSIEXB1dUXp0qVVz69cuRLe3t6wtLRE/fr18e+//75yvb24/gCgcePGGs+ZmJho3Ij1yZMnGDJkCEqVKgWZTIZy5crh448/RlZWFgAgPj4en332GapXrw4bGxvY2dmhffv2Wt/o8ObNm3jvvffg5OQECwsL1K1bF3/++adO64LImHDPDZERWrVqFT799FO89957GD16NDIyMnD58mWcOnVKdcgnP3fv3sV7772HIUOGYODAgVi7di0GDRqEOnXqoGrVqgByflm2bNkSEokEEyZMgLW1NVavXq31IS4vLy+Ehobi8ePH+f6Cc3FxwbJly/Dxxx+je/fu6NGjBwCgRo0aAICDBw/i/v37CA4Ohru7O65du4aVK1fi2rVrOHnyJCQSiVq93r17o1y5cpg1axbOnz+P1atXw9XVFXPmzFHN8+GHH+Lnn39Gv3790KhRI/zzzz/o2LGjRrYzZ87gxIkT6NOnD0qXLo0HDx5g2bJlaNGiBa5fvw4rKyu1+UeMGAEXFxdMnjwZqampAIA1a9Zg+PDhaNSoEcaMGYP79++jS5cucHJygqen52vXHwD88ssvaNy4MUxN8/8qjoyMRP369ZGQkIBhw4ahcuXKePLkCbZv3460tDSYm5vj/v372LlzJ3r16oVy5cohOjoaK1asQPPmzXH9+nWUKlUq3/rXrl1D48aN4eHhgS+//BLW1tbYunUrunXrhh07dqB79+6vXRdERkcvt98kold61d2ehRCiatWqanfY7tq1a553an5RXndp9/LyEgDE0aNHVdNiYmKETCYT48aNU0375JNPhEQiERcuXFBNe/bsmXBycsr3zu8vWrNmjQAgzM3NRcuWLcWkSZPEv//+q3FX9djY2HzvUJ6WlqYx7ddff9XIn7vuBg8erDZv9+7dRYkSJVSPL168KACIESNGqM3Xr18/jQx5LTssLEwAEBs2bFBNy13HTZo0EdnZ2arpWVlZwtXVVfj5+YnMzEzV9JUrV6rd+Tg/SqVSdZdvNzc30bdvX7FkyRLx8OFDjXkHDBggpFKpxh2Yc+sIkXPn9pfXfXh4uJDJZGL69Olq0/DS3cJbt24tqlevLjIyMtTqNmrUSPj4+Lx2XRAZIx6WIjJCDg4OePz4Mc6cOaPza319fdG0aVPVYxcXF1SqVAn3799XTdu3bx/8/f3h5+enmubk5IT3339fq2UMHjwY+/btQ4sWLXDs2DF88803aNq0KXx8fHDixAmtalhaWqr+nZGRgbi4ODRs2BAAcP78eY35P/roI7XHTZs2xbNnz5CUlAQA2LNnDwDg008/VZtvzJgxr1y2XC7Hs2fPUKFCBTg4OOS57KFDh6qNbzp79ixiYmLw0UcfqR2aGzRoEOzt7fN9z7kkEgn279+PGTNmwNHREb/++itGjhwJLy8vBAUFqcbcKJVK7Ny5E507d0bdunXzrAMAMpkMUmnO17lCocCzZ89gY2ODSpUq5fl+csXHx+Off/5B7969kZycjLi4OMTFxeHZs2cIDAzEnTt38OTJk1euCyJjxOaGyEi8eBjmiy++gI2NDerXrw8fHx+MHDkSx48f16pOmTJlNKY5Ojri+fPnqscPHz5EhQoVNObLa1p+AgMDsX//fiQkJODo0aMYOXIkHj58iE6dOmk1qDg+Ph6jR4+Gm5sbLC0t4eLignLlygEAEhMTX/u+HB0dAUD1vh4+fAipVApvb2+1+SpVqqRRKz09HZMnT4anpydkMhmcnZ3h4uKChISEPJedmyvXw4cPAQA+Pj5q083MzFC+fPlXvu9cMpkMX3/9NW7cuIHIyEj8+uuvaNiwIbZu3YpRo0YBAGJjY5GUlIRq1aq9spZSqcSCBQvg4+Oj9n4uX76c5/vJdffuXQghMGnSJLi4uKj9mTJlCgDNAeIvrwsiY8QxN0RvgYWFBYCcX6p5SUtLU80DAFWqVMGtW7ewa9cu7Nu3Dzt27MDSpUsxefJk1anV+cnvf9WikG4jZ2VlhaZNm6Jp06ZwdnbGtGnTsHfvXgwcOPCVr+vduzdOnDiBzz//HH5+frCxsYFSqUS7du2gVCo15tfn+/rkk0+wbt06jBkzBv7+/rC3t4dEIkGfPn3yXPaLe3oKQ8mSJdGnTx/07NkTVatWxdatW3W60N7MmTMxadIkDB48GN988w2cnJwglUoxZsyYPN9PrtznPvvsMwQGBuY5z8sNb2GvCyJ9YHND9BbkDiC9deuWxmDTtLQ0PHr0CG3btlWbbm1tjaCgIAQFBSErKws9evTAt99+iwkTJqg1QgXNc/fuXY3peU3TRe6hk6dPnwKAxqDgXM+fP0doaCimTZuGyZMnq6bfuXOnwMv28vKCUqnEvXv31PbW3Lp1S2Pe7du3Y+DAgfj+++9V0zIyMrQ+BTt3e965cwetWrVSTZfL5QgPD0fNmjUL9B7MzMxQo0YN3LlzB3FxcXB1dYWdnR2uXr36ytdt374dLVu2xJo1a9SmJyQkwNnZOd/X5e5lMjMzQ0BAQIEyExkjHpYiegtat24Nc3NzLFu2TON/0itXrkR2djbat2+vmvby6dDm5ubw9fWFEAJyufyN8wQGBiIsLAwXL15UTYuPj8cvv/yi1etDQ0PznJ477iW3ucg96+jlpiF3L8zLe10WLlyo1fLzkrv+fvzxx9fWNDEx0Vj2okWLoFAotFpW3bp14eLiguXLl6tOxwZyTpfWpkG6c+cOIiIiNKYnJCQgLCwMjo6OcHFxgVQqRbdu3fDXX3/h7NmzGvPnvoe83s+2bds0xsu8zNXVFS1atMCKFStUDemLYmNjX/teiIwR99wQvQWurq6YPHkyJk6ciGbNmqFLly6wsrLCiRMn8Ouvv6Jt27bo3Lmzav62bdvC3d0djRs3hpubG27cuIHFixejY8eOsLW1feM848ePx88//4w2bdrgk08+UZ0KXqZMGcTHx+e7xyVX165dUa5cOXTu3Bne3t5ITU3F33//jb/++gv16tVTvRdLS0v4+vpiy5YtqFixIpycnFCtWjVUq1YNzZo1w9y5cyGXy+Hh4YEDBw4gPDy8wO/Jz88Pffv2xdKlS5GYmIhGjRohNDQ0z71RnTp1wsaNG2Fvbw9fX1+EhYXh77//1ri+TH7MzMwwY8YMDB8+HK1atUJQUBDCw8Oxbt06rcbcXLp0Cf369UP79u3RtGlTODk54cmTJ/jpp58QGRmJhQsXqhrAmTNn4sCBA2jevDmGDRuGKlWq4OnTp9i2bRuOHTsGBwcHdOrUCdOnT0dwcDAaNWqEK1eu4JdfftEqy5IlS9CkSRNUr14dQ4cORfny5REdHY2wsDA8fvxY62vlEBkVw52oRfTu+fnnn0XDhg2FtbW1kMlkonLlymLatGlqp+EKIcSKFStEs2bNRIkSJYRMJhPe3t7i888/F4mJiap58jsVvGPHjhrLbd68ucbpyRcuXBBNmzYVMplMlC5dWsyaNUv8+OOPAoCIiop65fv49ddfRZ8+fYS3t7ewtLQUFhYWwtfXV3z99dciKSlJbd4TJ06IOnXqCHNzc7VTsh8/fiy6d+8uHBwchL29vejVq5eIjIzUOG07v9Po83r/6enp4tNPPxUlSpQQ1tbWonPnzuLRo0caNZ8/fy6Cg4OFs7OzsLGxEYGBgeLmzZvCy8tLDBw4UGMZeZ2GLYQQS5cuFeXKlRMymUzUrVtXHD16NM91/bLo6Ggxe/Zs0bx5c1GyZElhamoqHB0dRatWrcT27ds15n/48KEYMGCAcHFxETKZTJQvX16MHDlSdRp6RkaGGDdunChZsqSwtLQUjRs3FmFhYRpZ8joVXAgh7t27JwYMGCDc3d2FmZmZ8PDwEJ06dVLL8rp1QWRMJEIU0ihDIipyxowZgxUrViAlJYWn+xJRkcUxN0TvqJfP3Hr27Bk2btyIJk2asLEhoiKNY26I3lH+/v5o0aIFqlSpgujoaKxZswZJSUmYNGmSoaMREb0RNjdE76gOHTpg+/btWLlyJSQSCWrXro01a9agWbNmho5GRPRGOOaGiIiIihWOuSEiIqJihc0NERERFSvv3JgbpVKJyMhI2NravvZCZURERGQchBBITk5GqVKlIJW+et/MO9fcREZGatzbh4iIiIqGR48eoXTp0q+c551rbnIvXf/o0SPY2dnptbZcLseBAwfQtm1bmJmZGU0tY6/HbMZRj9mMox6zGUc9Y86m73rGnO1FSUlJ8PT01OoWNO9cc5N7KMrOzq5QmhsrKyvY2dnp5cOmr1rGXo/ZjKMesxlHPWYzjnrGnE3f9Yw5W160GVLCAcVERERUrLC5ISIiomKFzQ0REREVK2xuiIiIqFhhc0NERETFCpsbIiIiKlbY3BAREVGxwuaGiIiIihU2N0RERFSsGLS5OXr0KDp37oxSpUpBIpFg586dr33N4cOHUbt2bchkMlSoUAHr168v9JxERERUdBi0uUlNTUXNmjWxZMkSreYPDw9Hx44d0bJlS1y8eBFjxozBhx9+iP379xdyUiIiIioqDHpvqfbt26N9+/Zaz798+XKUK1cO33//PQCgSpUqOHbsGBYsWIDAwMDCiklERERFSJG6cWZYWBgCAgLUpgUGBmLMmDGGCURERGSkhBBQCkApBMQLfwvkTM99PitLjlQ58Cw1C6amypx5hIAA/v+6/+ppIzs7G0lZhfrWXqtINTdRUVFwc3NTm+bm5oakpCSkp6fD0tJS4zWZmZnIzMxUPU5KSgKQc9dSuVyu13y59fRRV5+1jL0esxlHPWYzjnrMZhz1CiObQgnEJqUhUyFBSmb2//9kZCM1S6H6d7pcgQy5EhnZ//393+PM/x6nyxXIlCuQkmaCGVcOQyEElEogWymgUCqhEIBCKaBQateM5DAFzh7Wy3sFgLI2JuhZSL9jtSER2rZihUwikeD3339Ht27d8p2nYsWKCA4OxoQJE1TT9uzZg44dOyItLS3P5mbq1KmYNm2axvRNmzbByspKL9mJiKj4UyiBNAWQKgfSsoG0bAlSs3P+naGQIEMBpGcj528FkJEt+f+/FYBcKTH0W9CaBAKSnH9Aopr2/3+/jpct8ElVhV4zpaWloV+/fkhMTISdnd0r5y1Se27c3d0RHR2tNi06Ohp2dnZ5NjYAMGHCBISEhKgeJyUlwdPTE23btn3tytGVXC7HwYMH0aZNG5iZmRlNLWOvx2zGUY/ZjKMes72denKFEglpcjxPy0J8au7fWYhPk+N5mhzPkjNw93EUTK3skJSejefpcqRm6ueXtaWZFNYyU9io/pio/m0tM4WluQksTKWwMDOBzEwKC1MTWJhJIftvmoWZFKYQOHf2NBr5N4SFuRmkEglMTSQwkUpgKpVCKgFMpRJIpRJIJRJI/+tUpBJAKpFAIsnZqSCVANnZcoT+HYq2bQJgbm7+xu9P39s1V+6RF20UqebG398fe/bsUZt28OBB+Pv75/samUwGmUymMd3MzEyvK72waus7pzHXYzbjqMdsxlGP2XSTma1AXJoCj1KAkw8SkZipwLOULDxLzUJ87t+pmTkNTGoWkjKytagqBRJTNKbaW5rBwcoMDpZmcLAyh72lGWwtTGFrkfv3f39k/59uaQqc/PcQunVsB0sLzd9JupLL5Yi9CdTwdNJD05rTDJmbmxvddn25nrYM2tykpKTg7t27qsfh4eG4ePEinJycUKZMGUyYMAFPnjzBhg0bAAAfffQRFi9ejPHjx2Pw4MH4559/sHXrVuzevdtQb4GIiAqJEAKJ6XI8ik9HdFIG4lIyEZeSidjkTMSlZCH2v8dxyZkvNCumwJXzWtWXSABHK3M4WZvDycocjtZmcLKWwcnaDPYWpoi4cx3N/euihK0lHCzN4GhlDjtLM5hIdT+8JJfLYWUKmJrw2rlvg0Gbm7Nnz6Jly5aqx7mHjwYOHIj169fj6dOniIiIUD1frlw57N69G2PHjsUPP/yA0qVLY/Xq1TwNnIioiJIrgfuxqYhMzsLj+DRExKfhUXx6zt/P05Cs1R6WHGYmElhJlShZwg7ONrKcpsXaHCWszeFk89/f1jLVtFc1KnK5HHsSrqFFRZdC28tPhcegzU2LFi1eeWpZXlcfbtGiBS5cuFCIqYiISJ+EEHiamIH7sam4F5uC+7EpuB+XirsxKXiaaAqcOv7K17vYylDS3gLONjI425jDxVb2379z/rjYmsPZRgYrU2Dv3r3o0MGfDck7rkiNuSEiIuOlUAo8eJaKW1HJuB2djHuxqTmNTGwq0uX5D8a1NjeBp5MVPJ2sUMbJCp6OlihTwgqejlYo7WgFS3MTrZav78t7UNHF5oaIiHQihEBMcgZuPk3Grahk3IxKxq3oJNyJTkFmtjLP15hKJShTwgreLjYo72INb2cbeDlZ4O6FE+jVpY1eztIhysXmhoiI8iWEQFRSBi5GJOD8w3gcvibF1EuH8Twt770klmYmqOhmg4putqjgaoPy/zUzZZysYPbSYFq5XI6oqzmnJBPpE5sbIiJSSc6Q48rjRFx4lIBLjxJw8VECYpIzX5hDCkAOqQQoW8IaldxtUcndFpXdbVHZ3Q5lnKwgLcDZRET6xOaGiOgdJYTAo/h0nAp/htPh8bj4KAF3Y1Pw8nkeJlIJKrnZorqHHSTxD9G7bSNUKeWo9VgYoreNzQ0R0TtCCIH7cak4dT8ep8Of4VR4PJ4mZmjM5+FgCb8yDvAr7QC/Mg6oWsoOVuamOadH73mA6h72MDNjY0PGi80NEVExJYTAnegU/Bslwf4tl3DmYQJi1Q4x5Qz0rVHaHg3Kl0CdMo6o6ekAF9s3v4IukSGxuSEiKiaEELgXm4Kw+/E4ee8ZTt5/hmepWQBMAOTcl8/cVIpang5oUM4JDcqXQO0yPLxExQ+bGyKiIkoIgfC4VITdf4aT9+Nx8v4zjT0zFmZSlLHKRvs6PmhUwQU1PR1gwUNKVMyxuSEiKkLSsrJx9HYcDl6PxrG7sYhOUm9mZKZS1PFyRMPyJeDvXQK+btb4+8A+dGjpzav20juDzQ0RkZGLSc5A6I2Y/xqaOGS9cKE8cxMpapVxgL93CTQsXwJ+L+2Z4VV76V3E5oaIyMgIAdyNScGhO89w8Ho0Lj5KUDs929PJEm2quKN1FVfU8XLkYSail7C5ISIyEnEpmdh4IhybLpog9uQJtedqlrZHG183BPi6oZKbLa/qS/QKbG6IiAzsxtMkrDsejp0XI/875CSBmYkEjbydcxqaKm5wt7cwdEyiIoPNDRGRASiVAoduxWDNsXCcuPdMNb26hx1qWj7HuD5t4GhjacCEREUXmxsiorcoNTMb2889xrrj4XjwLA0AIJUA7auVxOAmZVG9pA327t0LGxm/nokKij89RERvQUxSBlb9ex+bzzxCckY2AMDOwhR965dBf38vlHa0AsCzm4j0gc0NEVEhSsnMxsqj97Hq6H2kyxUAgPLO1ghuXBY9apeGNffQEOkdf6qIiAqBXKHE5jOP8MPftxGXkgUAqFXGAZ+28kHzii6QSnm2E1FhYXNDRKRHQgjsvxaNuftu4n5cKgCgbAkrfNGuMtpVc+cp3ERvAZsbIiI9OR+RgLkH7uDcw+cAgBLW5hgd4IO+9cvAzERq4HRE7w42N0REbyg8LhVrbklxOew0gJybVQ5tWh7DmpWHrQXv50T0trG5ISIqoAy5Aj+E3sGqo/eRrZRCKgF61/XE2DYV4WbHi+4RGQqbGyKiAvj3Tiy+/v0qIuJzrlXj66DEvA8ao2ppJwMnIyI2N0REOniWkokZu2/g9wtPAADudhaY0qkyssLPoqKbrYHTERHA5oaISCtCCGw/9xjf7rmBhDQ5JBJgoH9ZfBZYCTKpwJ5wQyckolxsboiIXuN+bAq+/v0qwu7n3AOqSkk7zOpRHX6eDgB4VWEiY8PmhogoH1nZSqw4cg+LDt1FVrYSFmZSjAmoiCFNyvHUbiIjxuaGiCgPFyKe44sdl3E7OgUA0NTHGd92q44yJawMnIyIXofNDRHRC9KzFFjw922s/vc+lCLnQnyTO/uiS81SvLowURHB5oaI6D+n7j/DFzsu48GznNO7u9fywOROvnC0NjdwMiLSBZsbInrnpWRmY+6+m9gQ9hBAzund33avhtZV3AycjIgKgs0NEb3T/r0Tiy93XMGThHQAQN/6npjQoQrseNsEoiLL4MP9lyxZgrJly8LCwgINGjTA6dOn851XLpdj+vTp8Pb2hoWFBWrWrIl9+/a9xbREVFykZQNf7byG/mtO40lCOko7WuLnIQ0wq0cNNjZERZxBm5stW7YgJCQEU6ZMwfnz51GzZk0EBgYiJiYmz/knTpyIFStWYNGiRbh+/To++ugjdO/eHRcuXHjLyYmoKDt8OxazL5pg27mcqwwPalQW+8c0QxMfZwMnIyJ9MGhzM3/+fAwdOhTBwcHw9fXF8uXLYWVlhbVr1+Y5/8aNG/HVV1+hQ4cOKF++PD7++GN06NAB33///VtOTkRFkVIpMP/gbQzdeAGJcgnKlrDC1uH+mNqlKqxlPEpPVFwYrLnJysrCuXPnEBAQ8P8wUikCAgIQFhaW52syMzNhYaF+p11LS0scO3asULMSUdGXmC7H0A1n8WPoHQBAU3cl/hrpj/rleKNLouLGYP9ViYuLg0KhgJub+tkIbm5uuHnzZp6vCQwMxPz589GsWTN4e3sjNDQUv/32GxQKRb7LyczMRGZmpupxUlISgJzxO/q+ZHpuPX3U1WctY6/HbMZRrzhnuxOTghGbLuLBszTITKWY1qkSLKOvwARKo8hXWLX0Xc+Ys+m7njFn03c9Y86WV11tSIQQQq9L11JkZCQ8PDxw4sQJ+Pv7q6aPHz8eR44cwalTpzReExsbi6FDh+Kvv/6CRCKBt7c3AgICsHbtWqSnp+e5nKlTp2LatGka0zdt2gQrK15plKi4u/RMgl/uSpGplMDRXGBIJQU8bQydioh0lZaWhn79+iExMRF2dnavnNdge26cnZ1hYmKC6OhotenR0dFwd3fP8zUuLi7YuXMnMjIy8OzZM5QqVQpffvklypcvn+9yJkyYgJCQENXjpKQkeHp6om3btq9dObqSy+U4ePAg2rRpAzOzNzvbQp+1jL0esxlHveKWTaEU+OGfu1h7O+d23f7lnbCgdw2UsDYvdu+V2fRfz5iz6bueMWd7Ue6RF20YrLkxNzdHnTp1EBoaim7dugEAlEolQkNDMWrUqFe+1sLCAh4eHpDL5dixYwd69+6d77wymQwymUxjupmZmV5XemHV1ndOY67HbMZRrzhkS0yTY/SWizh8KxYA8GGTcviyfWWYvnSzy+LwXg1Rz5iz6bueMWfTdz1jzpZbT1sGPT0gJCQEAwcORN26dVG/fn0sXLgQqampCA4OBgAMGDAAHh4emDVrFgDg1KlTePLkCfz8/PDkyRNMnToVSqUS48ePN+TbICIjcisqGcM2nsXDZ2mwMJNiTs8a6OrnYehYRPQWGbS5CQoKQmxsLCZPnoyoqCj4+flh3759qkHGERERkEr//z+tjIwMTJw4Effv34eNjQ06dOiAjRs3wsHBwUDvgIiMyd4rTzFu2yWkZSlQ2tESK/rXQdVS9oaORURvmcEv7DBq1Kh8D0MdPnxY7XHz5s1x/fr1t5CKiIoSpVJgwd+3seifuwCAJhWcsahvLd7wkugdZfDmhojoTSRnyDF2y0X8fSPnyuZDm5bDF+00x9cQ0buDzQ0RFVnhcakYuuEs7sakwNxUijk9q6N7rdKGjkVEBsbmhoiKpCO3Y/HJpvNIysiGu50FVvSvg5qeDoaORURGgM0NERUpQgis+vc+Zu+9CaUAapdxwPL+deBqa/H6FxPRO4HNDREVGRlyBSbtuIqdFyMBAEF1PTG9W1XITE0MnIyIjAmbGyIqEhIygb6rz+BqZBJMpBJM7uSLAf5ekEgkho5GREaGzQ0RGb0LEQn47ooJkuVJcLQyw5L3a6ORt7OhYxGRkWJzQ0RG7Y+LT/D59svIypagspsNVg2sB08n3vSWiPLH5oaIjJIQAgv/voMfQu8AAKo7KrFxaH042FgaOBkRGTs2N0RkdDLkCny+/TL+upQzcHhok7Lwzb4Laxm/sojo9XgJTyIyKrHJmei76iT+uhQJU6kEc3pWx/jAipBy3DARaanA/w26e/cu7t27h2bNmsHS0hJCCJ61QERv5GZUEoasP4snCemwtzTD8g/qwN+7BORyuaGjEVERovOem2fPniEgIAAVK1ZEhw4d8PTpUwDAkCFDMG7cOL0HJKJ3w6GbMei59ASeJKSjnLM1do5sDH/vEoaORURFkM7NzdixY2FqaoqIiAhYWf3/jIWgoCDs27dPr+GIqPgTQmDd8XAM+ekMUrMU8C9fAr+PaIRyztaGjkZERZTOh6UOHDiA/fv3o3Rp9ZvT+fj44OHDh3oLRkTFX7ZCiWl/XcfGkznfHUF1PfFNt2owN+VwQCIqOJ2bm9TUVLU9Nrni4+Mhk8n0EoqIir/kDDlGbrqAo7djIZEAE9pXxtCm5Tl2j4jemM7/PWratCk2bNigeiyRSKBUKjF37ly0bNlSr+GIqHh6/DwN7y0Lw9HbsbA0M8HyD+pgWDNvNjZEpBc677mZO3cuWrdujbNnzyIrKwvjx4/HtWvXEB8fj+PHjxdGRiIqRi49SsCQn84iLiUTrrYyrBlYD9VL2xs6FhEVIzrvualWrRpu376NJk2aoGvXrkhNTUWPHj1w4cIFeHt7F0ZGIiom9l19iqCVYYhLyURld1vsHNmYjQ0R6V2BrnNjb2+Pr7/+Wt9ZiKiYEkJg5dH7mLX3JgCgRSUXLO5XGza84jARFQKdv1nWrVsHGxsb9OrVS236tm3bkJaWhoEDB+otHBEVfXKFEpP/uoJfTz8CAAz098KkTr4wNeEZUURUOHT+dpk1axacnZ01pru6umLmzJl6CUVExUNaNvDhxvP49fQjSCTAlM6+mNa1GhsbIipUOu+5iYiIQLly5TSme3l5ISIiQi+hiKjoe/Q8DT9cNUFUejyszE3wY59aCPB1M3QsInoH6PzfJ1dXV1y+fFlj+qVLl1CiBC+VTkTAxUcJ6LXiNKLSJXCzlWHrcH82NkT01ui856Zv37749NNPYWtri2bNmgEAjhw5gtGjR6NPnz56D0hERcuBa1H4dPMFZMiV8LAS+HV4A5RxtjV0LCJ6h+jc3HzzzTd48OABWrduDVPTnJcrlUoMGDCAY26I3nE/nXiAqX9dgxBAM58S6OgYjZL2FoaORUTvGJ2bG3Nzc2zZsgXffPMNLl26BEtLS1SvXh1eXl6FkY+IigClUmDW3htY9W84AKBPPU9M7lgJB/fzZrpE9PYV+CITFStWRMWKFfWZhYiKoAy5AuO2XsLuK08BAJ8HVsKIFt7Izs42cDIielfp3NwoFAqsX78eoaGhiImJgVKpVHv+n3/+0Vs4IjJuz1OzMHTDWZx9+BxmJhLMe68mutXyMHQsInrH6dzcjB49GuvXr0fHjh1RrVo13uiO6B318FkqBq07g/C4VNhamGJF/zpo5K15DSwiordN5+Zm8+bN2Lp1Kzp06FAYeYioCLgQ8Rwf/nQWz1Kz4OFgiXXB9VDRjWdEEZFxKNCA4goVKhRGFiIqAvZfi8Lo/071ruZhh7UD68HVjmdEEZHx0PkifuPGjcMPP/wAIURh5CEiI/bzyYf4+OdzyJAr0bKSC7YM82djQ0RGR+fm5tixY/jll1/g7e2Nzp07o0ePHmp/dLVkyRKULVsWFhYWaNCgAU6fPv3K+RcuXIhKlSrB0tISnp6eGDt2LDIyMnReLhFpTwiB7w/cwsSdV6EUQN/6nlg1oC6seVdvIjJCOn8zOTg4oHv37npZ+JYtWxASEoLly5ejQYMGWLhwIQIDA3Hr1i24urpqzL9p0yZ8+eWXWLt2LRo1aoTbt29j0KBBkEgkmD9/vl4yEZG6bIUSX/1+BVvPPgYAjAnwwejWPjyZgIiMls7Nzbp16/S28Pnz52Po0KEIDg4GACxfvhy7d+/G2rVr8eWXX2rMf+LECTRu3Bj9+vUDAJQtWxZ9+/bFqVOn9JaJiP4vPUuBUZvOI/RmDKQSYEa36ujXoIyhYxERvZLOh6X0JSsrC+fOnUNAQMD/w0ilCAgIQFhYWJ6vadSoEc6dO6c6dHX//n3s2bOHZ24RFYL41Cz0W30SoTdjIDOVYvkHddjYEFGRUKAD5tu3b8fWrVsRERGBrKwstefOnz+vVY24uDgoFAq4uanfKdjNzQ03b97M8zX9+vVDXFwcmjRpAiEEsrOz8dFHH+Grr77KdzmZmZnIzMxUPU5KSgIAyOVyyOVyrbJqK7eePurqs5ax12M246j3Yq3Hz9Mx+KdzCH+WBntLU6z8oDZql3HQaTncDoavpe96xpxN3/WMOZu+6xlztrzqakMidDzt6ccff8TXX3+NQYMGYeXKlQgODsa9e/dw5swZjBw5Et9++61WdSIjI+Hh4YETJ07A399fNX38+PE4cuRInoeaDh8+jD59+mDGjBlo0KAB7t69i9GjR2Po0KGYNGlSnsuZOnUqpk2bpjF906ZNsLKy0vJdE707nqQCy2+YIEkugYO5wMdVFHDnjwoRGVhaWhr69euHxMRE2NnZvXJenZubypUrY8qUKejbty9sbW1x6dIllC9fHpMnT0Z8fDwWL16sVZ2srCxYWVlh+/bt6Natm2r6wIEDkZCQgD/++EPjNU2bNkXDhg0xb9481bSff/4Zw4YNQ0pKCqRSzaNsee258fT0RFxc3GtXjq7kcjkOHjyINm3awMzMzGhqGXs9ZjOOenK5HEu2/42f7pkjJVOBiq42WDOwNtwLeKo3t4Pha71L2fRdz5iz6bueMWd7UVJSEpydnbVqbnQ+LBUREYFGjRoBACwtLZGcnAwA6N+/Pxo2bKh1c2Nubo46deogNDRU1dwolUqEhoZi1KhReb4mLS1No4ExMTEBgHyvuyOTySCTyTSmm5mZ6XWlF1Ztfec05nrMZth6e65EYfkNKRRCgfrlnLBqQF3YW755Rm4Hw9fSdz1jzqbvesacTd/1jDlbbj1t6Tyg2N3dHfHx8QCAMmXK4OTJkwCA8PBwnS/sFxISglWrVuGnn37CjRs38PHHHyM1NVV19tSAAQMwYcIE1fydO3fGsmXLsHnzZoSHh+PgwYOYNGkSOnfurGpyiEh3G8IeYMy2y1AICdpVdcOGwfX10tgQERmCzntuWrVqhT///BO1atVCcHAwxo4di+3bt+Ps2bM6X8QvKCgIsbGxmDx5MqKiouDn54d9+/apBhlHRESo7amZOHEiJBIJJk6ciCdPnsDFxQWdO3fWepwPEakTQmDB33fwY+gdAEBjNyUW9q4BCzP+Z4GIii6dm5uVK1dCqVQCAEaOHIkSJUrgxIkT6NKlC4YPH65zgFGjRuV7GOrw4cPqYU1NMWXKFEyZMkXn5RCROoVSYMqfV/HzyQgAwKctvVE+/RZMpLw4HxEVbTo3N1KpVG1vSp8+fdCnTx+9hiKiwpWZrUDIlkvYfeUpJBJgepeq6FPXA3v23DJ0NCKiN6ZVc3P58mVUq1YNUqkUly9ffuW8NWrU0EswIiocKZnZGL7xLI7ffQYzEwkWBPmhU41Ser8mBRGRoWjV3Pj5+SEqKgqurq7w8/ODRCLJc/CwRCKBQqHQe0gi0o9nKZkYtO4MrjxJhJW5CVb2r4smPs6GjkVEpFdaNTfh4eFwcXFR/ZuIip5H8WkYuPY07selwsnaHOsG1UNNTwdDxyIi0jutmhsvLy8AORfmmTZtGiZNmoRy5coVajAi0p9bUckYsPYUopMy4eFgiQ1D6sPbxcbQsYiICoVO17kxMzPDjh07CisLERWCcw/j0Wv5CUQnZaKimw12fNyIjQ0RFWs6X8SvW7du2LlzZyFEISJ9O3I7Fu+vPoWkjGzU8XLE1uH+cLcv2O0UiIiKCp1PBffx8cH06dNx/Phx1KlTB9bW1mrPf/rpp3oLR0QFt+tyJMZuuQi5QqBFJRcse78OLM15cT4iKv50bm7WrFkDBwcHnDt3DufOnVN7TiKRsLkhMgK/no7AV79fgRBApxolMb+3H8xNdd5RS0RUJOnc3PBsKSLjtuzwPczZdxMA8H6DMpjetRqvOkxE7xSdmxsiMk5CCMzedxMrjtwHAIxs6Y3P2laCRMLGhojeLQVqbh4/fow///wTERERyMrKUntu/vz5eglGRNpTKAUm/34Fv55+BAD4qkNlDGvmbeBURESGoXNzExoaii5duqB8+fK4efMmqlWrhgcPHkAIgdq1axdGRiJ6hWwlMHbrZey9Fg2pBJjVozqC6pUxdCwiIoPReYThhAkT8Nlnn+HKlSuwsLDAjh078OjRIzRv3hy9evUqjIxElI+0rGysuinF3mvRMDeRYkm/2mxsiOidp3Nzc+PGDQwYMAAAYGpqivT0dNjY2GD69OmYM2eO3gMSUd4S0+QYtP4cbiZKYWVugjWD6qJ99ZKGjkVEZHA6NzfW1taqcTYlS5bEvXv3VM/FxcXpLxkR5Ss2ORNBK8Nw4VEirEwE1g+qg6Y+LoaORURkFHQec9OwYUMcO3YMVapUQYcOHTBu3DhcuXIFv/32Gxo2bFgYGYnoBU8S0vHB6lMIj0uFi405BpdPQy3eAJOISEXn5mb+/PlISUkBAEybNg0pKSnYsmULfHx8eKYUUSG7H5uCD1afQmRiBjwcLPHToDq4duqwoWMRERkVnZub8uXLq/5tbW2N5cuX6zUQEeXtemQSBqw9hbiULHi7WOPnDxvA2coU1wwdjIjIyOg85ubDDz/E4cOHCyEKEeXn3MN49FkZhriULFQtZYetw/1R0t7S0LGIiIySzs1NbGws2rVrB09PT3z++ee4dOlSYeQiov8cuxOHD1afRlJGNuqVdcSvwxqihI3M0LGIiIyWzs3NH3/8gadPn2LSpEk4c+YMateujapVq2LmzJl48OBBIUQkenftvxaFwevPIF2uQLOKLtgwuAHsLMwMHYuIyKgV6DbBjo6OGDZsGA4fPoyHDx9i0KBB2LhxIypUqKDvfETvrN/OP8aIX84jS6FE+2ruWDWgDizNTQwdi4jI6L3RjTPlcjnOnj2LU6dO4cGDB3Bzc9NXLqJ32oawB5j8R85Q4ffqlMbsHtVhalKg/4sQEb1zCvRteejQIQwdOhRubm4YNGgQ7OzssGvXLjx+/Fjf+YjeOUsO3VU1NoMalcXcnjXY2BAR6UDnPTceHh6Ij49Hu3btsHLlSnTu3BkyGQc3Er0pIQTm7LuF5Udyrvr9aasKGNumIiQSiYGTEREVLTo3N1OnTkWvXr3g4OBQCHGI3k1KpcDkP6/i55MRAICvOlTGsGbeBk5FRFQ06dzcDB06tDByEL2zshVKfL79Mn6/8AQSCfBtt+ro14B39iYiKqg3GlBMRG8mM1uBTzZdwIHr0TCVSvB975ro6udh6FhEREUamxsiA0nLysbwjefw7504mJtKsbRfbQT48oxDIqI3xeaGyACS0uUY9stFnHv4HFbmJlg9oC4aVXA2dCwiomKBzQ3RW5YsBz5YexY3opJhZ2GK9YPro3YZR0PHIiIqNrRqbv7880+tC3bp0qXAYYiKu6eJGfjxqgliMpLhbGOOjUMaoEpJO0PHIiIqVrRqbrp166b2WCKRQAih9jiXQqHQOcSSJUswb948REVFoWbNmli0aBHq16+f57wtWrTAkSNHNKZ36NABu3fv1nnZRG/Lw2epeH/1acRkSFDS3gK/fNgA5V1sDB2LiKjY0eqyp0qlUvXnwIED8PPzw969e5GQkICEhATs2bMHtWvXxr59+3QOsGXLFoSEhGDKlCk4f/48atasicDAQMTExOQ5/2+//YanT5+q/ly9ehUmJibo1auXzssmelvuRCej1/IwPE7IgLOFwK8f1mNjQ0RUSHQeczNmzBgsX74cTZo0UU0LDAyElZUVhg0bhhs3buhUb/78+Rg6dCiCg4MBAMuXL8fu3buxdu1afPnllxrzOzk5qT3evHkzrKys2NyQ0br6JBED1p5GfGoWKrraoL9nAjwcLA0di4io2NL5hjX37t3L8+rE9vb2ePDggU61srKycO7cOQQEBPw/kFSKgIAAhIWFaVVjzZo16NOnD6ytrXVaNtHbcO5hPPquOon41CzUKG2Pn4fUhZ25oVMRERVvOu+5qVevHkJCQrBx40bVXcCjo6Px+eef5ztOJj9xcXFQKBQadxN3c3PDzZs3X/v606dP4+rVq1izZk2+82RmZiIzM1P1OCkpCUDOHc3lcrlOeV8nt54+6uqzlrHXK67ZTtx7ho83XURalgJ1vRyw8oPasDAResv2pvkKs5a+6xlzNn3XYzbjqGfM2fRdz5iz5VVXGxLx4shgLdy9exfdu3fH7du34enpCQB49OgRfHx8sHPnTlSoUEHrWpGRkfDw8MCJEyfg7++vmj5+/HgcOXIEp06deuXrhw8fjrCwMFy+fDnfeaZOnYpp06ZpTN+0aROsrKy0zkqki6vxEqy7LUW2kKCyvRJDKilhbmLoVERERVdaWhr69euHxMRE2Nm9+ixTnffcVKhQAZcvX8bBgwdVe1eqVKmCgIAAne9e7OzsDBMTE0RHR6tNj46Ohru7+ytfm5qais2bN2P69OmvnG/ChAkICQlRPU5KSoKnpyfatm372pWjK7lcjoMHD6JNmzYwMzMzmlrGXq+4Zdt9JQrrTl1BthBoU8UVC3rXgMxUqvds+q7HbMZRj9mMo54xZ9N3PWPO9qLcIy/aKNBF/CQSCdq2bYtmzZpBJpPp3NTkMjc3R506dRAaGqo63VypVCI0NBSjRo165Wu3bduGzMxMfPDBB6+cTyaTQSaTaUw3MzPT60ovrNr6zmnM9YpDtq1nHuHL3y5DKYBufqUwr1dNmJloDm0rDu/VEPWMOZu+6zGbcdQz5mz6rmfM2XLraUvnAcVKpRLffPMNPDw8YGNjg/DwcADApEmTXjn2JT8hISFYtWoVfvrpJ9y4cQMff/wxUlNTVWdPDRgwABMmTNB43Zo1a9CtWzeUKFFC52USFYZ1x8MxfkdOY9O3fhnM7+2XZ2NDRESFS+dv3hkzZmD9+vWYO3cuzM3/f9pHtWrVsHr1ap0DBAUF4bvvvsPkyZPh5+eHixcvYt++fapBxhEREXj69Knaa27duoVjx45hyJAhOi+PqDAsOXQX0/66DgD4sEk5zOxeDVJpwfZoEhHRm9H5sNSGDRuwcuVKtG7dGh999JFqes2aNbU6wykvo0aNyvcw1OHDhzWmVapUCTqOgyYqFEIIzNt/C0sP3wMAjG7tgzEBPgU+VEtERG9O5+bmyZMneZ4RpVQq9X7aF5ExUyoFpu+6jvUnHgAAvupQGcOaeRs2FBER6X5YytfXF//++6/G9O3bt6NWrVp6CUVk7BRKgS92XFY1Nt90q8bGhojISOi852by5MkYOHAgnjx5AqVSid9++w23bt3Chg0bsGvXrsLISGRU5Aolxm65iF2Xn0IqAea9VxM965Q2dCwiIvqPzntuunbtir/++gt///03rK2tMXnyZNy4cQN//fUX2rRpUxgZiYxGhlyBj38+h12Xn8LMRIIl/WqzsSEiMjIFus5N06ZNcfDgQX1nITJqqZnZGLbxLI7ffQaZqRTL+9dBy0quho5FREQvKVBzA+Tc9DImJgZKpVJtepkyZd44FJGxSUqXY9gvF3Hu4XNYm5tg9cB68PfmNZaIiIyRzs3NnTt3MHjwYJw4cUJtuhACEokECoVCb+GIjEGKHOi/7iyuP02GnYUpfhpcH7XKOBo6FhER5UPn5mbQoEEwNTXFrl27ULJkSV7Pg4q1mORMLLpmgqj0ZJSwNsfGIQ3gW0q/9yQjIiL90rm5uXjxIs6dO4fKlSsXRh4io/H4eRr6rT6NqHQJ3Oxk+OXDhqjgamPoWERE9Bo6Nze+vr6Ii4srjCxERuN+bAo+WH0KkYkZKCET+PXDeijPxoaIqEjQ+VTwOXPmYPz48Th8+DCePXuGpKQktT9ERd3NqCT0XnESkYkZKO9sjU+rKuDpaGXoWEREpCWd99wEBAQAAFq3bq02nQOKqTi4/DgBA9aeRkKaHFVK2mHdgFo4dTTU0LGIiEgHOjc3hw4dKowcRAZ35kE8gtedQUpmNvw8HfBTcH1YmRk6FRER6Urn5qZ58+aFkYPIoP69E4uhG84iQ65Eg3JOWDOoHmxkprwZLBFREaRVc3P58mVUq1YNUqkUly9ffuW8NWrU0Esworfl4PVojPzlPLIUSjSv6ILlH9SBpbmJoWMREVEBadXc+Pn5ISoqCq6urvDz84NEIoEQQmM+jrmhoubPS5EYu+UiFEqBdlXd8UNfP8hM2dgQERVlWjU34eHhcHFxUf2bqDjYeuYRvvjtMoQAutfywLz3asDUROcTCImIyMho1dx4eXnl+W+iomr98XBM/es6AKBfgzKY0bUapFJebZuIqDgo8I0zr1+/joiICGRlZalN79KlyxuHIipMSw7dxbz9twAAHzYph687VuFtRIiIihGdm5v79++je/fuuHLlitrYm9xfDhxzQ8ZKCIHvDtzCkkP3AACjW/tgTIAPGxsiomJG5wEGo0ePRrly5RATEwMrKytcu3YNR48eRd26dXH48OFCiEj05oQQmL7ruqqxmdC+Msa2qcjGhoioGNJ5z01YWBj++ecfODs7QyqVQiqVokmTJpg1axY+/fRTXLhwoTByEhWYQinw9e9XsPnMIwDAN12ror9/WcOGIiKiQqPznhuFQgFbW1sAgLOzMyIjIwHkDDS+deuWftMRvSG5QomQrRex+cwjSCXAd71qsrEhIirmdN5zU61aNVy6dAnlypVDgwYNMHfuXJibm2PlypUoX758YWQkKpDMbCVCtl3CgevRMJVK8EOfWuhYo6ShYxERUSHTubmZOHEiUlNTAQDTp09Hp06d0LRpU5QoUQJbtmzRe0CigshSAB/9cgHH7j6DuakUy96vjdZV3Awdi4iI3gKdm5vAwEDVvytUqICbN28iPj4ejo6OHJxJRiE5IxvLb5jgXvIzWJmbYNWAumhcwdnQsYiI6C0p8HVuXuTk5KSPMkRvLCEtC4N+Oot7yRLYyEzx0+B6qOPFzycR0btEq+amR48eWhf87bffChyG6E3EpWSi/5rTuPE0CdamAj8Prgs/NjZERO8crZobe3v7ws5B9EaikzLw/upTuBuTAmcbcwzxTkPVUnaGjkVERAagVXOzbt26ws5BVGCPn6fh/dWn8PBZGkraW+CnQXVw4/QRQ8ciIiIDKfCYm5iYGNV1bSpVqgRXV1e9hSLS1oO4VLy/+hSeJKTD08kSmz5sCHdbM9wwdDAiIjIYnS/il5SUhP79+8PDwwPNmzdH8+bN4eHhgQ8++ACJiYmFkZEoT3djktF7RRieJKSjvLM1tg73h6eTlaFjERGRgenc3AwdOhSnTp3Crl27kJCQgISEBOzatQtnz57F8OHDCyMjkYbrkUkIWnESMcmZqORmiy3D/VHS3tLQsYiIyAjo3Nzs2rULa9euRWBgIOzs7GBnZ4fAwECsWrUKf/31l84BlixZgrJly8LCwgINGjTA6dOnXzl/QkICRo4ciZIlS0Imk6FixYrYs2ePzsulouvSowT0XXUSz1KzUM3DDpuHNYSLrczQsYiIyEjoPOamRIkSeZ49ZW9vD0dHR51qbdmyBSEhIVi+fDkaNGiAhQsXIjAwELdu3cpzDE9WVhbatGkDV1dXbN++HR4eHnj48CEcHBx0fRtURJ15EI/gdWeQkpmN2mUcsC64PuwtzQwdi4iIjIjOe24mTpyIkJAQREVFqaZFRUXh888/x6RJk3SqNX/+fAwdOhTBwcHw9fXF8uXLYWVlhbVr1+Y5/9q1axEfH4+dO3eicePGKFu2LJo3b46aNWvq+jaoCDp+Nw4D1pxGSmY2GpZ3wsYhDdjYEBGRBp333Cxbtgx3795FmTJlUKZMGQBAREQEZDIZYmNjsWLFCtW858+fz7dOVlYWzp07hwkTJqimSaVSBAQEICwsLM/X/Pnnn/D398fIkSPxxx9/wMXFBf369cMXX3wBExMTXd8KFSGHbsZg+M/nkJWtRPOKLljRvw4szLjNiYhIk87NTbdu3fSy4Li4OCgUCri5qd/M0M3NDTdv3szzNffv38c///yD999/H3v27MHdu3cxYsQIyOVyTJkyJc/XZGZmIjMzU/U4KSkJACCXyyGXy/XyXnLl1tNHXX3WMvZ6r6t14Ho0xmy9DLlCIKCyCxYG1YQJlJDLlQbPVpzqMZtx1GM246hnzNn0Xc+Ys+VVVxsSIYTQ69K1FBkZCQ8PD5w4cQL+/v6q6ePHj8eRI0dw6tQpjddUrFgRGRkZCA8PV+2pmT9/PubNm4enT5/muZypU6di2rRpGtM3bdoEKyueNmzszsdJsPGOFEpIUKuEEv0rKGGi88FUIiIq6tLS0tCvXz8kJibCzu7VV6DXec/NoUOH0LJlyzyfW7Fihdangzs7O8PExATR0dFq06Ojo+Hu7p7na0qWLAkzMzO1Q1BVqlRBVFQUsrKyYG5urvGaCRMmICQkRPU4KSkJnp6eaNu27WtXjq7kcjkOHjyINm3awMzszcaC6LOWsdfLr9ZvF55g48lrUALoVrMkZnWvClMtOhtuB8PXepey6bsesxlHPWPOpu96xpztRblHXrShc3PTrl07fPrpp5g5c6YqdFxcHIKDg3Hs2DGtmxtzc3PUqVMHoaGhqkNdSqUSoaGhGDVqVJ6vady4MTZt2gSlUgmpNOeX3O3bt1GyZMk8GxsAkMlkkMk0TxM2MzPT60ovrNr6zmnM9V6stelUBL76/RoAoG99T3zbrTqkUolRZCvu9ZjNOOoxm3HUM+Zs+q5nzNly62lL5x38hw4dwu+//4569erh+vXr2L17N6pVq4akpCRcvHhRp1ohISFYtWoVfvrpJ9y4cQMff/wxUlNTERwcDAAYMGCA2oDjjz/+GPHx8Rg9ejRu376N3bt3Y+bMmRg5cqSub4OM2Lrj4fjq9ysAgEGNymJmd90bGyIienfpvOemUaNGuHjxIj766CPUrl0bSqUS33zzDcaPHw+JRLdfQEFBQYiNjcXkyZMRFRUFPz8/7Nu3TzXIOCIiQrWHBgA8PT2xf/9+jB07FjVq1ICHhwdGjx6NL774Qte3QUZq2eF7mLMvZ0D58Obl8WW7yjp/roiI6N1WoBtn3r59G2fPnkXp0qURGRmJW7duIS0tDdbW1jrXGjVqVL6HoQ4fPqwxzd/fHydPntR5OWTchAAW/XMPPx66BwAY3doHYwJ82NgQEZHOdD4sNXv2bPj7+6NNmza4evUqTp8+jQsXLqBGjRr5Xp+G6FWEEPgrQqpqbMa3q4SxbSqysSEiogLRec/NDz/8gJ07d6J9+/YAgGrVquH06dP46quv0KJFC7VryhC9jhACs/bdRmhkTp89qZMvhjQpZ+BURERUlOnc3Fy5cgXOzs5q08zMzDBv3jx06tRJb8Go+BNCYPa+m1h34iEAYGrnKhjUmI0NERG9GZ0PSzk7OyMhIQGrV6/GhAkTEB8fDyDnVgsVKlTQe0AqvhYcvI0VR+4DAHqVU+D9+p4GTkRERMWBzntuLl++jICAANjb2+PBgwcYOnQonJyc8NtvvyEiIgIbNmwojJxUzCwKvYMf/7kLAJjYoRJcnl8zcCIiIioudN5zM3bsWAwaNAh37tyBhYWFanqHDh1w9OhRvYaj4mn5kXv4/uBtAMBXHSpjoL+XgRMREVFxonNzc/bs2TyvQuzh4YGoqCi9hKLia82xcMzem3Mdm88DK2FYM28DJyIiouJG5+ZGJpPleX+H27dvw8XFRS+hqHjaGPYA3+y6DiDnOjYjW3KMFhER6Z/OzU2XLl0wffp01a3HJRIJIiIi8MUXX6Bnz556D0jFw+bTEZj0R864mo9beGNMgI+BExERUXGlc3Pz/fffIyUlBa6urkhPT0fz5s1RoUIF2Nra4ttvvy2MjFTEbT/3GBP+u1fUh03KYXxgJV6gj4iICo3OZ0vZ29vj4MGDOH78OC5duoSUlBTUrl0bAQEBhZGPirg/Lj7B+O2XIAQw0N8LX3eswsaGiIgKVYHuLQUAjRs3RuPGjfWZhYqZfVefImTrJSgF0Ld+GUzpXJWNDRERFTqdD0sRaePI7Vh88usFKJQC79UpjW+7VYNUysaGiIgKH5sb0ruzD+IxfONZyBUCHauXxJyeNdjYEBHRW8PmhvTqWmQigtefQYZcieYVXbAgyA8mbGyIiOgtYnNDenM/NgUD1pxGckY26pV1xPIP6sDclB8xIiJ6uwr0m+fevXuYOHEi+vbti5iYGADA3r17ce0a7w/0rnqSkI4PVp/Cs9QsVC1lhzWD6sHS3MTQsYiI6B2kc3Nz5MgRVK9eHadOncJvv/2GlJQUAMClS5cwZcoUvQck4xebnIn+q08hMjED3i7W2DC4PuwszAwdi4iI3lE6NzdffvklZsyYgYMHD8Lc3Fw1vVWrVjh58qRew5HxS0qXY8Da07gflwoPB0v8/GEDlLCRGToWERG9w3Rubq5cuYLu3btrTHd1dUVcXJxeQlHRkKkAhv58ATeeJsHZRoafP2yAkvaWho5FRETvOJ2bGwcHBzx9+lRj+oULF+Dh4aGXUGT8MrOVWHtLivMRCbCzMMXGIfVRztna0LGIiIh0b2769OmDL774AlFRUZBIJFAqlTh+/Dg+++wzDBgwoDAykpHJVigxbttl3EyUwsrcBOsH10eVknaGjkVERASgAM3NzJkzUblyZXh6eiIlJQW+vr5o1qwZGjVqhIkTJxZGRjIy8w/exv7rMTCRCCzt54faZRwNHYmIiEhF53tLmZubY9WqVZg0aRKuXr2KlJQU1KpVCz4+PoWRj4zMsTtxWHbkHgDggwpKNPYuYeBERERE6nRubo4dO4YmTZqgTJkyKFOmTGFkIiMVl5KJsVsvQgggqG5p1DZ7YOhIREREGnQ+LNWqVSuUK1cOX331Fa5fv14YmcgIKZUC47ZeQmxyJiq62eDr9pUMHYmIiChPOjc3kZGRGDduHI4cOYJq1arBz88P8+bNw+PHjwsjHxmJNcfCceR2LGSmUizqW5tXHyYiIqOlc3Pj7OyMUaNG4fjx47h37x569eqFn376CWXLlkWrVq0KIyMZ2KVHCZi7/yYAYHJnX1RytzVwIiIiovy90V0Ny5Urhy+//BKzZ89G9erVceTIEX3lIiORnCHHJ79egFwh0L6aO/rV5zgrIiIybgVubo4fP44RI0agZMmS6NevH6pVq4bdu3frMxsZmBACE3deRUR8GjwcLDG7Rw1IJBJDxyIiInolnc+WmjBhAjZv3ozIyEi0adMGP/zwA7p27QorK6vCyEcGtP3cY/xxMRImUgl+7OsHeyveDJOIiIyfzs3N0aNH8fnnn6N3795wdnYujExkBO7GpGDyH9cAAGMDfFDHy8nAiYiIiLSjc3Nz/PjxwshBRiRDrsAnv15AulyBRt4l8HGLCoaOREREpDWtmps///wT7du3h5mZGf78889XztulSxedQyxZsgTz5s1DVFQUatasiUWLFqF+/fp5zrt+/XoEBwerTZPJZMjIyNB5uZS32Xtv4sbTJDhZm2NBkB9MpBxnQ0RERYdWzU23bt0QFRUFV1dXdOvWLd/5JBIJFAqFTgG2bNmCkJAQLF++HA0aNMDChQsRGBiIW7duwdXVNc/X2NnZ4datW2rLJf04eD0a6088AAB836sm3OwsDBuIiIhIR1qdLaVUKlWNhlKpzPePro0NAMyfPx9Dhw5FcHAwfH19sXz5clhZWWHt2rX5vkYikcDd3V31x83NTeflkqanien4fPslAMCQJuXQsnLezSUREZEx0/lU8A0bNiAzM1NjelZWFjZs2KBTraysLJw7dw4BAQH/DySVIiAgAGFhYfm+LiUlBV5eXvD09ETXrl1x7do1nZZLmhRKgbFbLiIhTY5qHnYY3463VyAioqJJ5wHFwcHBaNeuncYho+TkZAQHB2PAgAFa14qLi4NCodDY8+Lm5oabN2/m+ZpKlSph7dq1qFGjBhITE/Hdd9+hUaNGuHbtGkqXLq0xf2ZmplozlpSUBACQy+WQy+VaZ9VGbj191NVnLW3qLT9yHyfvx8PK3ATz36sOqVBCLle+lXxv+70aqpax12M246jHbMZRz5iz6bueMWfLq642JEIIoUtxqVSK6OhouLi4qE2/dOkSWrZsifj4eK1rRUZGwsPDAydOnIC/v79q+vjx43HkyBGcOnXqtTXkcjmqVKmCvn374ptvvtF4furUqZg2bZrG9E2bNvHaPP95kAz8cNUESkjQ11uBhq46fSSIiIgKXVpaGvr164fExETY2dm9cl6t99zUqlULEokEEokErVu3hqnp/1+qUCgQHh6Odu3a6RTU2dkZJiYmiI6OVpseHR0Nd3d3rWqYmZmhVq1auHv3bp7PT5gwASEhIarHSUlJ8PT0RNu2bV+7cnQll8tx8OBBtGnTBmZmb3bBO33WelW95IxsfLc0DEqko2M1d0zrXV2rAdpF8b0aupax12M246jHbMZRz5iz6bueMWd7Ue6RF21o3dzkniV18eJFBAYGwsbGRvWcubk5ypYti549e2qf8r/X1alTB6Ghoar6SqUSoaGhGDVqlFY1FAoFrly5gg4dOuT5vEwmg0wm05huZmam15VeWLX1nfPlet/8dg2PnqfDw8ESM3vWgLm5bssqSu/VWGoZez1mM456zGYc9Yw5m77rGXO23Hra0rq5mTJlCgCgbNmyCAoKgoWFfk4RDgkJwcCBA1G3bl3Ur18fCxcuRGpqqupaNgMGDICHhwdmzZoFAJg+fToaNmyIChUqICEhAfPmzcPDhw/x4Ycf6iXPu+T3C4/x+4UnkEqAH/r4wd6St1cgIqKiT+cBxQMHDtRrgKCgIMTGxmLy5MmIioqCn58f9u3bpxpkHBERAan0/yd1PX/+HEOHDkVUVBQcHR1Rp04dnDhxAr6+vnrNVdxFPEvDpJ05Z5l92toHdcvy9gpERFQ86NzcKBQKLFiwAFu3bkVERASysrLUntdlQHGuUaNG5XsY6vDhw2qPFyxYgAULFui8DPo/uUKJTzdfQEpmNuqVdcSolry9AhERFR86X+dm2rRpmD9/PoKCgpCYmIiQkBD06NEDUqkUU6dOLYSIpG8//H0HFx8lwNbCFAuC/GBqovPHgIiIyGjp/Fvtl19+wapVqzBu3DiYmpqib9++WL16NSZPnoyTJ08WRkbSo1Ph8VhyOOfMslk9qqO0I0+HJyKi4kXn5iYqKgrVq1cHANjY2CAxMREA0KlTJ+zevVu/6UivUuXAuO1XIATQu25pdKpRytCRiIiI9E7n5qZ06dJ4+vQpAMDb2xsHDhwAAJw5cybPU67JOAghsPm+FNFJmSjvbI2pXaoaOhIREVGh0Lm56d69O0JDQwEAn3zyCSZNmgQfHx8MGDAAgwcP1ntA0o8tZ5/gcrwUZiYS/Ni3FqzMdR5LTkREVCTo/Btu9uzZqn8HBQWhTJkyCAsLg4+PDzp37qzXcKQfD+JS8e3enHt1jWvjg2oe9gZOREREVHje+L/v/v7+aveFIuOiVAqM334ZGXIlfOyUCPb3MnQkIiKiQqVVc/Pnn39qXbBLly4FDkP6t/7EA5x+EA9rcxP09c6GVPr6+0YREREVZVo1N7n3fXodiUQChULxJnlIj8LjUjF3f87hqPGBFeEQd8XAiYiIiAqfVgOKlUqlVn/Y2BiPnMNRl5AhV6JxhRLoW6+0oSMRERG9Fbw0bTG17sQDnHnwHNbmJpjTswYkEh6OIiKid4POA4qnT5/+yucnT55c4DCkH+FxqZj33+GorzpWQWlHK8jlcgOnIiIiejt0bm5+//13tcdyuRzh4eEwNTWFt7c3mxsDUygFPt+WcziqSQVn9KtfxtCRiIiI3iqdm5sLFy5oTEtKSsKgQYPQvXt3vYSiglt3PBxnHz6HjcwUs3tW5+EoIiJ65+hlzI2dnR2mTZuGSZMm6aMcFdD92BTM238LAPBVhyq8KSYREb2T9DagODExUXUTTXr7FEqBz7dfRma2Ek19nNG3vqehIxERERmEzoelfvzxR7XHQgg8ffoUGzduRPv27fUWjHSz7ng4zqkOR/HsKCIienfp3NwsWLBA7bFUKoWLiwsGDhyICRMm6C0Yae/eC4ejvu5YBR4OlgZOREREZDg6Nzfh4eGFkYMKKPfsqNzDUX3q8XAUERG923gRvyJu3fFwnI9I4OEoIiKi/+i85yYjIwOLFi3CoUOHEBMTA6VSqfb8+fPn9RaOXi0tKxs/ht4BwMNRREREuXRuboYMGYIDBw7gvffeQ/369bmnwIB+O/8ESRnZKONkhd51eTiKiIgIKEBzs2vXLuzZsweNGzcujDykJSEE1p94AAAY2KgsTKRsMomIiIACjLnx8PCAra1tYWQhHfx7Jw53Y1JgbW6CXnV5x28iIqJcOjc333//Pb744gs8fPiwMPKQltYdzzlrrVddT9hZmBk4DRERkfHQ+bBU3bp1kZGRgfLly8PKygpmZuq/WOPj4/UWjvJ2PzYFh27FQiIBBjUqa+g4RERERkXn5qZv37548uQJZs6cCTc3Nw4oNoDcsTatKrmirLO1YcMQEREZGZ2bmxMnTiAsLAw1a9YsjDz0Gonpcmw/9xgAENy4nIHTEBERGR+dx9xUrlwZ6enphZGFtLDt7COkZSlQ0c0GjSuUMHQcIiIio6NzczN79myMGzcOhw8fxrNnz5CUlKT2hwqPQvn/07+DG5fjIUEiIqI86HxYql27dgCA1q1bq00XQkAikUChUOgnGWn4+0Y0Hj9Ph4OVGbr5eRg6DhERkVHSubk5dOhQYeQgLeSe/t23fhlYmpsYOA0REZFx0rm5ad68eWHkoNe4FpmIk/fjYSKVoH9DL0PHISIiMlo6NzdHjx595fPNmjXTOcSSJUswb948REVFoWbNmli0aBHq16//2tdt3rwZffv2RdeuXbFz506dl1uUrD/+AADQrpo7SvEGmURERPnSublp0aKFxrQXB7bqOuZmy5YtCAkJwfLly9GgQQMsXLgQgYGBuHXrFlxdXfN93YMHD/DZZ5+hadOmOi2vKHqWkok/LkUCAAbz9G8iIqJX0vlsqefPn6v9iYmJwb59+1CvXj0cOHBA5wDz58/H0KFDERwcDF9fXyxfvhxWVlZYu3Ztvq9RKBR4//33MW3aNJQvX17nZRY1m05FICtbiZql7VG7jIOh4xARERk1nffc2Nvba0xr06YNzM3NERISgnPnzmldKysrC+fOncOECRNU06RSKQICAhAWFpbv66ZPnw5XV1cMGTIE//77r25voIjJylZi48mc+3jx9G8iIqLX07m5yY+bmxtu3bql02vi4uKgUCjg5uamUevmzZt5vubYsWNYs2YNLl68qNUyMjMzkZmZqXqcey0euVwOuVyuU97Xya2nj7q5NXZfjkRMciZcbWVoU9m5wLX1mU3f9ZjNOOoxm3HUYzbjqGfM2fRdz5iz5VVXGxIhhNCl+OXLl9UeCyHw9OlTzJ49G9nZ2Th27JjWtSIjI+Hh4YETJ07A399fNX38+PE4cuQITp06pTZ/cnIyatSogaVLl6J9+/YAgEGDBiEhISHfAcVTp07FtGnTNKZv2rQJVlZWWmc1BCGA+VdMEJEqQQdPBQJL67SpiIiIio20tDT069cPiYmJsLOze+W8Ou+58fPzg0Qiwcs9UcOGDV85TiYvzs7OMDExQXR0tNr06OhouLu7a8x/7949PHjwAJ07d1ZNUyqVAABTU1PcunUL3t7eaq+ZMGECQkJCVI+TkpLg6emJtm3bvnbl6Eoul+PgwYNo06aNxt3SC1Jr5W8HEZEqgbmpFJP7NUcJG5lRZNN3PWYzjnrMZhz1mM046hlzNn3XM+ZsL9LlLgg6Nzfh4eFqj6VSKVxcXGBhYaFrKZibm6NOnToIDQ1Ft27dAOQ0K6GhoRg1apTG/JUrV8aVK1fUpk2cOBHJycn44Ycf4OnpqfEamUwGmUyzKTAzM9PrSi+M2kee5oz37lqzFNwdbd64HqD/963PesxmHPWYzTjqMZtx1DPmbPquZ8zZcutpS+fmxstLvxeQCwkJwcCBA1G3bl3Ur18fCxcuRGpqKoKDgwEAAwYMgIeHB2bNmgULCwtUq1ZN7fUODg4AoDG9qHuamIFLz3IGD/Pu30RERNrT+lTwf/75B76+vnnuFkpMTETVqlULdOZSUFAQvvvuO0yePBl+fn64ePEi9u3bpxpkHBERgadPn+pct6j79cwjKCFB/bKO8C2l38NnRERExZnWe24WLlyIoUOH5jlOxd7eHsOHD8f8+fMLdFG9UaNG5XkYCgAOHz78yteuX79e5+UZOyEE/rqU09C9X1/zUBsRERHlT+s9N5cuXVLdETwvbdu21ekaN5S/C48S8DghAzKpQMtKLoaOQ0REVKRo3dxER0e/cjCPqakpYmNj9RLqXffnxZxbLVRzErz7NxERkY60bm48PDxw9erVfJ+/fPkySpYsqZdQ7zKFUmD3lZxDUnWceV0bIiIiXWnd3HTo0AGTJk1CRkaGxnPp6emYMmUKOnXqpNdw76JT958hNjkT9pamqGTP5oaIiEhXWg8onjhxIn777TdUrFgRo0aNQqVKlQAAN2/exJIlS6BQKPD1118XWtB3xV+Xcw5JtavqBlPpQwOnISIiKnq0bm7c3Nxw4sQJfPzxx5gwYYLqCsUSiQSBgYFYsmSJxj2iSDdZ2UrsuRIFAOhY3R3Pb7K5ISIi0pVOF/Hz8vLCnj178Pz5c9y9exdCCPj4+MDR0bGw8r1Tjt2NRWK6HC62MtQv64T9ed87lIiIiF6hQHcFd3R0RL169fSd5Z2Xe5ZUx+olYSKVGDgNERFR0aT1gGIqXOlZChy8nnMD0S5+pQychoiIqOhic2Mk/rkZg9QsBTwcLFHL08HQcYiIiIosNjdG4q9LOYekOtcsBYmEh6SIiIgKis2NEUjKkOOfWzEAgC41eUiKiIjoTbC5MQIHr0UjK1sJbxdrVClpa+g4RERERRqbGyPw53+HpLrU9OAhKSIiojfE5sbA4lOzcOxuHACgc03em4uIiOhNsbkxsD1XnkKhFKjmYYfyLjaGjkNERFTksbkxMNVZUjU4kJiIiEgf2NwYUFRiBk4/iAcAdOJZUkRERHrB5saAdl2OhBBAXS9HeDhYGjoOERFRscDmxoByD0nxdgtERET6w+bGQB4+S8Wlx4mQSoD21XiWFBERkb6wuTGQ3L02jSs4w8VWZuA0RERExQebGwP569JTADxLioiISN/Y3BjArahk3IpOhpmJBIHV3A0dh4iIqFhhc2MAf156AgBoXtEV9pZmBk5DRERUvLC5ecuEEKpDUjxLioiISP/Y3Lxllx4nIiI+DZZmJgio4mroOERERMUOm5u37J8b0QCAVpVdYWVuauA0RERExQ+bm7cs7P4zAEATH2cDJyEiIiqe2Ny8RelZClx8lAAA8C9fwrBhiIiIiik2N2/R2YfxkCsEStpbwKuElaHjEBERFUtsbt6isHs5h6T8y5eARCIxcBoiIqLiic3NW5Q73qahNw9JERERFRajaG6WLFmCsmXLwsLCAg0aNMDp06fznfe3335D3bp14eDgAGtra/j5+WHjxo1vMW3BpGRm4/LjRAAcb0NERFSYDN7cbNmyBSEhIZgyZQrOnz+PmjVrIjAwEDExMXnO7+TkhK+//hphYWG4fPkygoODERwcjP3797/l5Lo58yAeCqVAaUdLeDpxvA0REVFhMXhzM3/+fAwdOhTBwcHw9fXF8uXLYWVlhbVr1+Y5f4sWLdC9e3dUqVIF3t7eGD16NGrUqIFjx4695eS6OfnCeBsiIiIqPAa9ilxWVhbOnTuHCRMmqKZJpVIEBAQgLCzsta8XQuCff/7BrVu3MGfOnDznyczMRGZmpupxUlISAEAul0Mul7/hO1CXWy+vuifuxQEA6pd10Gq5r6ql72yGrsdsxlGP2YyjHrMZRz1jzqbvesacLa+62pAIIYRel66DyMhIeHh44MSJE/D391dNHz9+PI4cOYJTp07l+brExER4eHggMzMTJiYmWLp0KQYPHpznvFOnTsW0adM0pm/atAlWVm/n8FB6NjDhjAkEJJhWOxsOsreyWCIiomIjLS0N/fr1Q2JiIuzs7F45b5G8/r+trS0uXryIlJQUhIaGIiQkBOXLl0eLFi005p0wYQJCQkJUj5OSkuDp6Ym2bdu+duXoSi6X4+DBg2jTpg3MzP5/t+9/bsVCnLkALycr9Ove5I1q6TubMdRjNuOox2zGUY/ZjKOeMWfTdz1jzvai3CMv2jBoc+Ps7AwTExNER0erTY+Ojoa7u3u+r5NKpahQoQIAwM/PDzdu3MCsWbPybG5kMhlkMs1dJWZmZnpd6a+qfeZBAgCgUYUSOi9T3zmNuR6zGUc9ZjOOesxmHPWMOZu+6xlzttx62jLogGJzc3PUqVMHoaGhqmlKpRKhoaFqh6leR6lUqo2rMTaq69twMDEREVGhM/hhqZCQEAwcOBB169ZF/fr1sXDhQqSmpiI4OBgAMGDAAHh4eGDWrFkAgFmzZqFu3brw9vZGZmYm9uzZg40bN2LZsmWGfBv5SkjLwvWnObvSeKYUERFR4TN4cxMUFITY2FhMnjwZUVFR8PPzw759++Dm5gYAiIiIgFT6/x1MqampGDFiBB4/fgxLS0tUrlwZP//8M4KCggz1Fl7pVHg8hAC8Xazhamdh6DhERETFnsGbGwAYNWoURo0aledzhw8fVns8Y8YMzJgx4y2k0g/V/aR4ywUiIqK3wuAX8SvuTt7PvXifs4GTEBERvRvY3BSiZymZuBmVDABoUN7JwGmIiIjeDWxuCtGp8HgAQEU3Gzjb8Mp9REREbwObm0IUxvtJERERvXVsbgpR7vVtOJiYiIjo7WFzU0hikjNwNyYFEgnQoBybGyIioreFzU0hOXk/Z7xNZXc7OFqbGzgNERHRu4PNTSHheBsiIiLDYHNTSE5yvA0REZFBsLkpBFFJGQiPS4VUAtQvx+vbEBERvU1sbgrBqfDnAICqpexhb6m/270TERHR67G5KQS5F+/jISkiIqK3j81NIcg9U4qDiYmIiN4+Njd6Fp8JPHqeDhOpBPU43oaIiOitY3OjZ3cTJQCA6h72sJGZGjgNERHRu4fNjZ7dScppbjjehoiIyDDY3OiREAJ3/ttzw/E2REREhsHmRo8ePU/H8ywJzEwkqFvW0dBxiIiI3klsbvQo9xTwGh72sDLneBsiIiJDYHOjRyfv51y8rwHPkiIiIjIYNjd6IoRQ7blpUI6HpIiIiAyFzY2ehMelIjo5EyYSgdplHAwdh4iI6J3FgSF68iQhHU7WZnCUZsHCzMTQcYiIiN5Z3HOjJ019XHDyixYYUklh6ChERETvNDY3eiSRSGDNm4ATEREZFJsbIiIiKlbY3BAREVGxwuaGiIiIihU2N0RERFSssLkhIiKiYoXNDRERERUrbG6IiIioWGFzQ0RERMWKUTQ3S5YsQdmyZWFhYYEGDRrg9OnT+c67atUqNG3aFI6OjnB0dERAQMAr5yciIqJ3i8Gbmy1btiAkJARTpkzB+fPnUbNmTQQGBiImJibP+Q8fPoy+ffvi0KFDCAsLg6enJ9q2bYsnT5685eRERERkjAze3MyfPx9Dhw5FcHAwfH19sXz5clhZWWHt2rV5zv/LL79gxIgR8PPzQ+XKlbF69WoolUqEhoa+5eRERERkjAx6V/CsrCycO3cOEyZMUE2TSqUICAhAWFiYVjXS0tIgl8vh5OSU5/OZmZnIzMxUPU5KSgIAyOVyyOXyN0ivKbeePurqs5ax12M246jHbMZRj9mMo54xZ9N3PWPOllddbUiEEEKvS9dBZGQkPDw8cOLECfj7+6umjx8/HkeOHMGpU6deW2PEiBHYv38/rl27BgsLC43np06dimnTpmlM37RpE6ysrN7sDRAREdFbkZaWhn79+iExMRF2dnavnNege27e1OzZs7F582YcPnw4z8YGACZMmICQkBDV48TERJQpUwb+/v6wtbXVax65XI5Dhw6hZcuWMDN7s9uD67OWsddjNuOox2zGUY/ZjKOeMWfTdz1jzvai5ORkAIA2+2QM2tw4OzvDxMQE0dHRatOjo6Ph7u7+ytd+9913mD17Nv7++2/UqFEj3/lkMhlkMpnqce5hqXLlyr1BciIiIjKE5ORk2Nvbv3IegzY35ubmqFOnDkJDQ9GtWzcAUA0OHjVqVL6vmzt3Lr799lvs378fdevW1WmZpUqVwqNHj2BrawuJRPIm8TUkJSXB09MTjx49eu0us7dZy9jrMZtx1GM246jHbMZRz5iz6bueMWd7kRACycnJKFWq1GvnNfhhqZCQEAwcOBB169ZF/fr1sXDhQqSmpiI4OBgAMGDAAHh4eGDWrFkAgDlz5mDy5MnYtGkTypYti6ioKACAjY0NbGxsXrs8qVSK0qVLF94bAmBnZ6e3DarPWsZej9mMox6zGUc9ZjOOesacTd/1jDlbrtftscll8OYmKCgIsbGxmDx5MqKiouDn54d9+/bBzc0NABAREQGp9P9nrC9btgxZWVl477331OpMmTIFU6dOfZvRiYiIyAgZvLkBgFGjRuV7GOrw4cNqjx88eFD4gYiIiKjIMvhF/IoTmUyGKVOmqA1gNoZaxl6P2YyjHrMZRz1mM456xpxN3/WMOVtBGfQ6N0RERET6xj03REREVKywuSEiIqJihc0NERERFStsbvRkyZIlKFu2LCwsLNCgQQOcPn26QHVmzZqFevXqwdbWFq6urujWrRtu3bqll4yzZ8+GRCLBmDFjClzjyZMn+OCDD1CiRAlYWlqievXqOHv2bIFqKRQKTJo0CeXKlYOlpSW8vb3xzTffaHVpbQA4evQoOnfujFKlSkEikWDnzp1qzwshMHnyZJQsWRKWlpYICAjAnTt3dK4ll8vxxRdfoHr16rC2tkapUqUwYMAAREZGFjjbiz766CNIJBIsXLiwwLVu3LiBLl26wN7eHtbW1qhXrx4iIiIKVC8lJQWjRo1C6dKlYWlpCV9fXyxfvjzPWtp8XjMyMjBy5EiUKFECNjY26Nmzp8ZVybWtFx8fj08++QSVKlWCpaUlypQpg08//RSJiYkFypZLCIH27du/cltpWy8sLAytWrWCtbU17Ozs0KxZM6Snp+tcKyoqCv3794e7uzusra1Ru3Zt7NixI89sy5YtQ40aNVTXFfH398fevXtVz+uyDV5XT5dtoE22XNpsA23rabMNtK2ny3Z4WV7fubpui/xq6bodtMmWS9ttoU09XbaFPrG50YMtW7YgJCQEU6ZMwfnz51GzZk0EBgYiJiZG51pHjhzByJEjcfLkSRw8eBByuRxt27ZFamrqG2U8c+YMVqxY8cpbVbzO8+fP0bhxY5iZmWHv3r24fv06vv/+ezg6Ohao3pw5c7Bs2TIsXrwYN27cwJw5czB37lwsWrRIq9enpqaiZs2aWLJkSZ7Pz507Fz/++COWL1+OU6dOwdraGoGBgcjIyNCpVlpaGs6fP49Jkybh/Pnz+O2333Dr1i106dKlwNly/f777zh58uQrr7j5ulr37t1DkyZNULlyZRw+fBiXL1/GpEmT8r3f2uvqhYSEYN++ffj5559x48YNjBkzBqNGjcKff/6pMa82n9exY8fir7/+wrZt23DkyBFERkaiR48eeS77dfUiIyMRGRmJ7777DlevXsX69euxb98+DBkypEDZci1cuPC1VyzXpl5YWBjatWuHtm3b4vTp0zhz5gxGjRqldq0ubWsNGDAAt27dwp9//okrV66gR48e6N27Ny5cuKCRrXTp0pg9ezbOnTuHs2fPolWrVujatSuuXbum8zZ4XT1dtoE22XTZBtrU03YbaFtPl+3wovy+c3XdFvnV0nU7aJMtl7bb4nX1dN0WeiXojdWvX1+MHDlS9VihUIhSpUqJWbNmvXHtmJgYAUAcOXKkwDWSk5OFj4+POHjwoGjevLkYPXp0gep88cUXokmTJgXO8bKOHTuKwYMHq03r0aOHeP/993WuBUD8/vvvqsdKpVK4u7uLefPmqaYlJCQImUwmfv31V51q5eX06dMCgHj48KHO2XI9fvxYeHh4iKtXrwovLy+xYMGCAtUKCgoSH3zwwWtfq229qlWriunTp6tNq127tvj6669fW+/lz2tCQoIwMzMT27ZtU81z48YNAUCEhYXpXC8vW7duFebm5kIulxeo1oULF4SHh4d4+vSpVtv+VfUaNGggJk6cqNXrX1fL2tpabNiwQW0+JycnsWrVKq1qOjo6itWrV7/xNni5Xl603Qb51SroNsirXkG3QX71CrId8vvOLci20OX7W5vt8Lp6um6LV9XTx7YoKO65eUNZWVk4d+4cAgICVNOkUikCAgIQFhb2xvVzdzE6OTkVuMbIkSPRsWNHtYwF8eeff6Ju3bro1asXXF1dUatWLaxatarA9Ro1aoTQ0FDcvn0bAHDp0iUcO3YM7du3f6OcABAeHo6oqCi192xvb48GDRrobbtIJBI4ODgU6PVKpRL9+/fH559/jqpVqxY4h1KpxO7du1GxYkUEBgbC1dUVDRo00HpXcl4aNWqEP//8E0+ePIEQAocOHcLt27fRtm3b17725c/ruXPnIJfL1bZD5cqVUaZMGa22gzaf/8TERNjZ2cHU9NXXJM2rVlpaGvr164clS5a89ma9r6sXExODU6dOwdXVFY0aNYKbmxuaN2+OY8eO6VwLyNkOW7ZsQXx8PJRKJTZv3oyMjAy0aNHilbUUCgU2b96M1NRU+Pv7v/E2eLlefvm12QZ51XqTbfByvTfZBvnlK8h2yO87tyDbQpfvb222w6vqFWRb5FfvTbfFGzNIS1WMPHnyRAAQJ06cUJv++eefi/r1679RbYVCITp27CgaN25c4Bq//vqrqFatmkhPTxdCiDfacyOTyYRMJhMTJkwQ58+fFytWrBAWFhZi/fr1BaqnUCjEF198ISQSiTD9X3v3HhVz/v8B/DlNTaNIVBtJF8smqdzCuOUYq2N30V60dh3KZXMJtSK5tpuVclw3Ye3BWpdt1x6X5C6JDSEVuaRS2FWLFcklZV6/P5zmt1Nz+0xZ6ft6nNM5zefz6fl5z/s1Ta/5zGf6GBuTSCSiqKgog7JQ7RVGamoqAaA7d+6obDd8+HDy8/MTlFXds2fPqEuXLvTll18aNDYioqioKHr//fdJoVAQERl85Kbq1ZWZmRktX76cMjIyaPHixSQSiej48eMGje358+c0evRoAkDGxsYkkUho8+bNOrPUPV63bdtGEomkxrZeXl4UFhYmOK+6e/fukYODA82ZM8egrMDAQBo3bpzytq7aa8s7ffo0AaDmzZvTxo0b6cKFCxQSEkISiYSuX78ueGwlJSU0aNAgZR0sLCzo0KFDGnMuXrxI5ubmJBaLqWnTprRv3z4iMrwGmvKq06cG2rIMqYGmPENroG18Quug7TlXaC2EPH/rUwddeUJroS3P0FrUlXpx+QWmXlBQELKzsw3udG/fvo3g4GAcOXJE4/kXQigUCnTr1g1RUVEAgM6dOyM7Oxvr1q2Dv7+/4LzffvsN27Ztw/bt2+Hm5obMzEyEhITAzs7OoLz/QkVFBfz8/EBEWLt2rUEZ6enpWLVqFS5cuFDrK9MrFAoAwLBhw/D1118DADp16oRTp05h3bp18Pb2FpwZGxuLM2fOICEhAY6Ojjhx4gSCgoJgZ2en9dVjbR+vQvNKS0vx4YcfokOHDjqvK6cuKyEhAceOHdN57oS+eVW1mDBhgvLCv507d0ZSUhI2btyovPivPlkAMH/+fDx8+BBHjx6FtbU1du/eDT8/P5w8eRLu7u41clxcXJCZmYlHjx7h999/h7+/P1JSUgTfN115HTp0UG6jbw00ZeXl5RlUA015htZA230VUoe6fM4VkqVPHXTlCf190JVnaC3qzGtvnxq48vJyEovFNbrb0aNH09ChQw3ODQoKInt7e7px44bBGbt27SIAJBaLlV8ASCQSkVgspsrKSkF5Dg4OKl09EdGaNWvIzs7OoPHZ29vT6tWrVZYtXLiQXFxcBGeh2iuM/Px8AkAZGRkq2/Xr14+mTZsmKKvKixcvyNfXlzw8POj+/fsGj23FihXKGvy7LkZGRuTo6Cgoq7y8nIyNjWnhwoUq24WFhVGvXr0Ej+3p06dkYmJCiYmJKtuNGzeOfHx8NOZoerwmJSURACopKVFZ7uDgQMuXLxecV6W0tJRkMhnJ5XLlq0ahWcHBwRrr4O3tLTjvxo0bBIC2bNmistzPz0/jUT5NWXl5eQSAsrOzVZbL5XKaMGGC1vv7720DAwMNroGmvCpCaqApy9AaaMozpAba8oTWQddz7tGjR/Wuhb7P3/rWQVfelClTBNVCV17V3NW2FobiIze1JJFI0LVrVyQlJcHX1xfAq441KSlJ48VAtSEiTJ06Fbt27cLx48fh7Oxs8NjkcjkuXbqksmzMmDFo3749Zs2aBbFYLCivd+/eNT6uev36dTg6Oho0vqdPn9Y4a14sFis7/tpwdnZGixYtkJSUhE6dOgF49eomLS0NkyZNEpxXdcQmNzcXycnJsLKyMnhso0aNqnEExMfHB6NGjVK+wtGXRCKBl5dXndWloqICFRUVetdF1+O1a9euMDExQVJSEj799FMAQE5ODm7duqX2/A19Hv+lpaXw8fGBqakpEhISNL6q1ZUVHh6O8ePHqyxzd3fHihUrMGTIEMF5Tk5OsLOzU1uL6ueR6cp6+vQpANTq90OhUKC8vFxwDXTlAfrXQFfWt99+K6gGuvKE1ECfPKF10PWc27p1a71roc/zt5A66MqztrbGhAkTVNZrq4WuvDZt2tRJLQz22tun/wHx8fFkampKP/30E125coUCAwPJ0tKSiouLBWdNmjSJmjZtSsePH6eioiLl19OnT+tkrLU55+bs2bNkbGxMixYtotzcXNq2bRuZmZnR1q1bDcrz9/enVq1aUWJiIhUUFNDOnTvJ2tpa57kYVR4/fkwZGRmUkZFBAJTnnFR9gik6OposLS1pz549dPHiRRo2bBg5OzurfXWjLevFixc0dOhQsre3p8zMTJW6lJeXGzS26rSdc6Mra+fOnWRiYkLr16+n3Nxcio2NJbFYTCdPnjQoz9vbm9zc3Cg5OZlu3LhBmzZtIqlUSmvWrKmRpc/jdeLEieTg4EDHjh2j8+fPk0wmI5lMpnZsuvIePXpEPXr0IHd3d8rLy1PZpvqRSEN+l6DlHAN98lasWEEWFha0Y8cOys3NpXnz5pFUKqW8vDxBWS9evKC2bdtS3759KS0tjfLy8mjp0qUkEonUnvsSHh5OKSkpVFBQQBcvXqTw8HASiUR0+PBhwTXQlSekBvqMTUgN9MnTtwb65AmtgzrVn3OF1kJTltA66DO26nTVQlee0FrUJW5u6khsbCw5ODiQRCKh7t2705kzZwzKAaD2a9OmTXUyzto0N0REe/fupY4dO5KpqSm1b9+e1q9fb3BWaWkpBQcHk4ODA0mlUmrTpg3NnTtXY8NQXXJystq58vf3J6JXHwefP38+2drakqmpKcnlcsrJyRGcVVBQoLEuycnJBo2tOm3NjT5ZGzZsoLZt25JUKiVPT0/avXu3wfNWVFREAQEBZGdnR1KplFxcXGjZsmXKk5//TZ/H67Nnz2jy5MnUrFkzMjMzo48//piKiorUjk1XnqaxA6CCggLBY1O3f01P5vrmLV68mOzt7cnMzIxkMpnaJlOfrOvXr9Mnn3xC77zzDpmZmZGHh0eNjyRXGTt2LDk6OpJEIiEbGxuSy+UqzYOQGujKE1IDfcambm60/UHVJ0+fGuibJ6QO6lR/zhVaC01ZQuugz9iqq21zQySsFnWJrwrOGGOMsQaF/88NY4wxxhoUbm4YY4wx1qBwc8MYY4yxBoWbG8YYY4w1KNzcMMYYY6xB4eaGMcYYYw0KNzeMMcYYa1C4uWGMMcZYg8LNDWNMqbCwECKRCJmZmW96KErXrl1Dz549IZVKldcJY4wxbbi5YaweCQgIgEgkQnR0tMry3bt3QyQSvaFRvVkREREwNzdHTk4OkpKS3vRw3lr9+/dHSEjImx4GY/8Jbm4Yq2ekUiliYmJQUlLypodSZ168eGHwz+bn56NPnz5wdHSs1dXYGWP/O7i5YayeGThwIFq0aIHFixdr3Oabb76p8RbNypUr4eTkpLwdEBAAX19fREVFwdbWFpaWloiMjERlZSVmzpyJ5s2bw97eHps2baqRf+3aNfTq1QtSqRQdO3ZESkqKyvrs7GwMHjwYjRs3hq2tLUaNGoX79+8r1/fv3x9TpkxBSEgIrK2t4ePjo/Z+KBQKREZGwt7eHqampujUqRMOHjyoXC8SiZCeno7IyEiIRCJ88803GnOWLFmCtm3bwtTUFA4ODli0aJFy/aVLlzBgwAA0atQIVlZWCAwMRFlZWa3mquotvPj4eK1zlZKSgu7du8PU1BQtW7ZEeHg4KisrVeZq2rRpCAsLQ/PmzdGiRYsa9/Phw4cYP348bGxsYGFhgQEDBiArK0u5vurxsGXLFjg5OaFp06YYMWIEHj9+rLx/KSkpWLVqFUQiEUQiEQoLC1FSUoKRI0fCxsYGjRo1Qrt27dQ+Hhh723Bzw1g9IxaLERUVhdjYWPz555+1yjp27Bju3LmDEydOYPny5YiIiMBHH32EZs2aIS0tDRMnTsSECRNq7GfmzJkIDQ1FRkYGZDIZhgwZgn/++QfAqz+0AwYMQOfOnXH+/HkcPHgQf//9N/z8/FQyNm/eDIlEgtTUVKxbt07t+FatWoVly5Zh6dKluHjxInx8fDB06FDk5uYCAIqKiuDm5obQ0FAUFRVhxowZanNmz56N6OhozJ8/H1euXMH27dtha2sLAHjy5Al8fHzQrFkznDt3Djt27MDRo0cxZcqU1z5Xf/31Fz744AN4eXkhKysLa9euxYYNG/Ddd9/VmCtzc3OkpaVhyZIliIyMxJEjR5Trhw8fjrt37+LAgQNIT09Hly5dIJfL8eDBA+U2+fn52L17NxITE5GYmIiUlBTl25urVq2CTCbDV199haKiIhQVFaF169bK+Tpw4ACuXr2KtWvXwtraWu0cM/ZW+U+uPc4Y04u/vz8NGzaMiIh69uxJY8eOJSKiXbt20b9/XSMiIsjT01PlZ1esWEGOjo4qWY6OjvTy5UvlMhcXF+rbt6/ydmVlJZmbm9Mvv/xCREQFBQUEgKKjo5XbVFRUkL29PcXExBAR0cKFC2nQoEEq+759+zYBoJycHCIi8vb2ps6dO+u8v3Z2drRo0SKVZV5eXjR58mTlbU9PT4qIiNCYUVpaSqampvTjjz+qXb9+/Xpq1qwZlZWVKZft27ePjIyMqLi4mIhe31zNmTOHXFxcSKFQKLeJi4ujxo0bK/fl7e1Nffr0qTEHs2bNIiKikydPkoWFBT1//lxlm3fffZd++OEHInr1eDAzM6PS0lLl+pkzZ1KPHj2Ut729vSk4OFglY8iQITRmzBi188bY24yP3DBWT8XExGDz5s24evWqwRlubm4wMvr/X3NbW1u4u7srb4vFYlhZWeHu3bsqPyeTyZTfGxsbo1u3bspxZGVlITk5GY0bN1Z+tW/fHsCrowdVunbtqnVspaWluHPnDnr37q2yvHfv3oLu89WrV1FeXg65XK5xvaenJ8zNzVX2oVAokJOTo1z2Oubq6tWrkMlkKieD9+7dG2VlZSpHgDw8PFQyW7ZsqdxPVlYWysrKYGVlpTLnBQUFKvPt5OSEJk2aqM3QZNKkSYiPj0enTp0QFhaGU6dOad2esbeF8ZseAGNMvX79+sHHxwezZ89GQECAyjojIyMQkcqyioqKGhkmJiYqt0UikdplCoVC73GVlZVhyJAhiImJqbGuZcuWyu//3Uy8To0aNaqTnNcxV7XZd9V+ysrK0LJlSxw/frzGz1laWuqVocngwYNx8+ZN7N+/H0eOHIFcLkdQUBCWLl1q2B1hrJ7gIzeM1WPR0dHYu3cvTp8+rbLcxsYGxcXFKg1OXf5vmjNnzii/r6ysRHp6OlxdXQEAXbp0weXLl+Hk5IS2bduqfAlpaCwsLGBnZ4fU1FSV5ampqejQoYPeOe3atUOjRo00fkzc1dUVWVlZePLkico+jIyM4OLiovd+NNE2V66urjh9+rRKnVJTU9GkSRPY29vrld+lSxcUFxfD2Ni4xnwLOT9GIpHg5cuXNZbb2NjA398fW7duxcqVK7F+/Xq9Mxmrr7i5Yawec3d3x8iRI/H999+rLO/fvz/u3buHJUuWID8/H3FxcThw4ECd7TcuLg67du3CtWvXEBQUhJKSEowdOxYAEBQUhAcPHuCLL77AuXPnkJ+fj0OHDmHMmDFq/3hqM3PmTMTExODXX39FTk4OwsPDkZmZieDgYL0zpFIpZs2ahbCwMPz888/Iz8/HmTNnsGHDBgDAyJEjIZVK4e/vj+zsbCQnJ2Pq1KkYNWqU8qTj2tA2V5MnT8bt27cxdepUXLt2DXv27EFERASmT5+u8haYNgMHDoRMJoOvry8OHz6MwsJCnDp1CnPnzsX58+f1HqeTkxPS0tJQWFiI+/fvQ6FQYMGCBdizZw/y8vJw+fJlJCYmKhszxt5m3NwwVs9FRkbWeHvB1dUVa9asQVxcHDw9PXH27FmNnyQyRHR0NKKjo+Hp6Yk//vgDCQkJyqMEVUdbXr58iUGDBsHd3R0hISGwtLTU+w92lWnTpmH69OkIDQ2Fu7s7Dh48iISEBLRr105Qzvz58xEaGooFCxbA1dUVn3/+ufJ8EzMzMxw6dAgPHjyAl5cXPvvsM8jlcqxevVrQPjTRNletWrXC/v37cfbsWXh6emLixIkYN24c5s2bp3e+SCTC/v370a9fP4wZMwbvvfceRowYgZs3bwpqzmbMmAGxWIwOHTrAxsYGt27dgkQiwezZs+Hh4YF+/fpBLBYjPj5e8BwwVt+IqPob94wxxnQqLCyEs7MzMjIy+LIQjNUzfOSGMcYYYw0KNzeMMcYYa1D4bSnGGGOMNSh85IYxxhhjDQo3N4wxxhhrULi5YYwxxliDws0NY4wxxhoUbm4YY4wx1qBwc8MYY4yxBoWbG8YYY4w1KNzcMMYYY6xB4eaGMcYYYw3K/wHo6eLbpSSfkQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"class\"])\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "X_scaled = scaler_standard.fit_transform(X)\n",
    "\n",
    "pca_standard = PCA(n_components=len(df.columns) - 1)\n",
    "X_pca = pca_standard.fit_transform(X_scaled)\n",
    "\n",
    "pca_cumsum = pca_standard.explained_variance_ratio_.cumsum()\n",
    "plt.plot(pca_cumsum)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"Cumulative explained variance vs Number of components\\nUsing Standard Scaler\")\n",
    "plt.grid()\n",
    "plt.xticks(range(0, len(df.columns) - 1, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30d79cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at n=28, we have 95% of the variance explained\n"
     ]
    }
   ],
   "source": [
    "print(f\"at n={np.where(pca_cumsum > 0.95)[0][0]}, we have 95% of the variance explained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3929b6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_gt1 = df[cols_corr_gt1]\n",
    "X_gt1 = X_gt1.drop(columns=[\"class\"])\n",
    "\n",
    "scaler_standard_gt1 = StandardScaler()\n",
    "X_gt1_scaled = scaler_standard_gt1.fit_transform(X_gt1)\n",
    "\n",
    "pca_corr_gt1_standard = PCA(n_components=len(cols_corr_gt1) - 1)\n",
    "X_gt1_pca = pca_corr_gt1_standard.fit_transform(X_gt1_scaled)\n",
    "\n",
    "pca_cumsum = pca_corr_gt1_standard.explained_variance_ratio_.cumsum()\n",
    "plt.plot(pca_cumsum)\n",
    "plt.xlabel(\"Number of components with |correlation| > 0.1\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"Cumulative explained variance vs Number of components with |correlation| > 0.1\\nUsing Standard Scaler\")\n",
    "plt.grid()\n",
    "plt.xticks(range(0, len(cols_corr_gt1) - 1, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa50bf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at n=10, we have 95% of the variance explained\n"
     ]
    }
   ],
   "source": [
    "print(f\"at n={np.where(pca_cumsum > 0.95)[0][0]}, we have 95% of the variance explained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6f302",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bba22928",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, __X__, _, _, __y__ = test_train_val_split(df)\n",
    "df_known_attacks = pd.DataFrame(__X__)\n",
    "df_known_attacks[\"class\"] = __y__\n",
    "df_known_attacks.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60e94a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_attacks = pd.read_csv(similar_attacks_path, low_memory=False)\n",
    "df_similar_attacks = df_similar_attacks.drop(columns=[\"ip_RF\", \"ip_MF\", \"ip_offset\"])\n",
    "df_similar_attacks[\"class\"] = df_similar_attacks[\"class\"].replace({\"normal\": 0, \"attack\": 1})\n",
    "\n",
    "df_new_attacks = pd.read_csv(new_attacks_path, low_memory=False)\n",
    "df_new_attacks = df_new_attacks.drop(columns=[\"ip_RF\", \"ip_MF\", \"ip_offset\"])\n",
    "df_new_attacks[\"class\"] = df_new_attacks[\"class\"].replace({\"normal\": 0, \"attack\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e63e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    df_similar_attacks = df_similar_attacks.sample(frac=TESTING_SIZE, random_state=random_state)\n",
    "    df_similar_attacks.reset_index(drop=True, inplace=True)\n",
    "    df_new_attacks = df_new_attacks.sample(frac=TESTING_SIZE, random_state=random_state)\n",
    "    df_new_attacks.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "025ff8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_scaled(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs:\n",
    "        raise ValueError(\"df and scaler must be passed as keyword arguments for pipeline_scaled\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "\n",
    "    df_ = df.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pd.DataFrame(df_, columns=df.columns[:-1])\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d5b3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_corr_gt1_scaled(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs or \"cols\" not in kwargs:\n",
    "        raise ValueError(\"df, scaler, and cols must be passed as keyword arguments for pipeline_corr_gt1_scaled\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "    cols = kwargs[\"cols\"]\n",
    "\n",
    "    df_ = df[cols]\n",
    "    df_ = df_.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pd.DataFrame(df_, columns=cols[:-1])\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5474ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_pca(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs or \"pca\" not in kwargs:\n",
    "        raise ValueError(\"df, scaler, and pca must be passed as keyword arguments for pipeline_pca\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "    pca = kwargs[\"pca\"]\n",
    "    pca_cols = np.where(pca.explained_variance_ratio_.cumsum() > 0.95)[0][0]\n",
    "\n",
    "    df_ = df.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pca.transform(df_)\n",
    "    df_ = df_[:, :pca_cols]\n",
    "    df_ = pd.DataFrame(df_)\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36b7585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_corr_gt1_pca(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs or \"cols\" not in kwargs or \"pca\" not in kwargs:\n",
    "        raise ValueError(\"df, scaler, cols, and pca must be passed as keyword arguments for pipeline_corr_gt1_pca\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "    cols = kwargs[\"cols\"]\n",
    "    pca = kwargs[\"pca\"]\n",
    "    pca_cols = np.where(pca.explained_variance_ratio_.cumsum() > 0.95)[0][0]\n",
    "\n",
    "\n",
    "    df_ = df[cols]\n",
    "    df_ = df_.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pca.transform(df_)\n",
    "    df_ = df_[:, :pca_cols]\n",
    "    df_ = pd.DataFrame(df_)\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70a3f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_type</th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_id</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>ip_proto</th>\n",
       "      <th>ip_checksum</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_dport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>udp_chk</th>\n",
       "      <th>icmp_type</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_seq</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_frst</th>\n",
       "      <th>tcp_fpush</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>tcp_furg</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>count_fr_src_dst</th>\n",
       "      <th>count_fr_dst_src</th>\n",
       "      <th>count_serv_src_dst</th>\n",
       "      <th>count_serv_dst_src</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_pushed_src_dst</th>\n",
       "      <th>num_pushed_dst_src</th>\n",
       "      <th>num_syn_fin_src_dst</th>\n",
       "      <th>num_syn_fin_dst_src</th>\n",
       "      <th>num_fin_src_dst</th>\n",
       "      <th>num_fin_dst_src</th>\n",
       "      <th>num_ack_src_dst</th>\n",
       "      <th>num_ack_dst_src</th>\n",
       "      <th>num_syn_src_dst</th>\n",
       "      <th>num_syn_dst_src</th>\n",
       "      <th>num_rst_src_dst</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_packet</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.863934</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>0.859266</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.023986</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.042562</td>\n",
       "      <td>0.044490</td>\n",
       "      <td>0.203746</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.154188</td>\n",
       "      <td>0.267020</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.863884</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>0.859213</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.023987</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.043293</td>\n",
       "      <td>0.044490</td>\n",
       "      <td>0.204454</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.154188</td>\n",
       "      <td>0.267872</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>-0.315216</td>\n",
       "      <td>-0.262465</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>0.597862</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.258300</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>-1.036906</td>\n",
       "      <td>-0.445392</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>-0.315189</td>\n",
       "      <td>-1.146024</td>\n",
       "      <td>-0.327640</td>\n",
       "      <td>-0.380841</td>\n",
       "      <td>-0.167630</td>\n",
       "      <td>-0.205911</td>\n",
       "      <td>-0.582023</td>\n",
       "      <td>-0.680948</td>\n",
       "      <td>-0.468717</td>\n",
       "      <td>-0.600078</td>\n",
       "      <td>-0.036490</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>-0.098600</td>\n",
       "      <td>-0.226426</td>\n",
       "      <td>-0.073183</td>\n",
       "      <td>-0.022541</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>16.893706</td>\n",
       "      <td>3.188363</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>-0.252576</td>\n",
       "      <td>1.273936</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>1.234992</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.158517</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>-1.031884</td>\n",
       "      <td>1.391738</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.303363</td>\n",
       "      <td>-0.353784</td>\n",
       "      <td>-0.152296</td>\n",
       "      <td>-0.179733</td>\n",
       "      <td>-0.553556</td>\n",
       "      <td>-0.271239</td>\n",
       "      <td>-0.440730</td>\n",
       "      <td>-0.025361</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>-0.080893</td>\n",
       "      <td>-0.194893</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>-0.252576</td>\n",
       "      <td>-0.188418</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>-0.708360</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.099910</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>0.924837</td>\n",
       "      <td>1.391442</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>0.008994</td>\n",
       "      <td>0.043293</td>\n",
       "      <td>0.045001</td>\n",
       "      <td>0.204454</td>\n",
       "      <td>-0.286574</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178253</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.154799</td>\n",
       "      <td>0.267872</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ip_type    ip_len     ip_id     ip_DF  ip_proto  ip_checksum  udp_sport  udp_dport  udp_len   udp_chk  icmp_type  icmp_code  icmp_chk  tcp_sport  tcp_dport   tcp_seq   tcp_ack  tcp_ffyn  tcp_fsyn  tcp_frst  tcp_fpush  tcp_fack  tcp_furg  fr_length  conn_status  count_fr_src_dst  count_fr_dst_src  count_serv_src_dst  count_serv_dst_src  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_pushed_src_dst  num_pushed_dst_src  num_syn_fin_src_dst  num_syn_fin_dst_src  num_fin_src_dst  num_fin_dst_src  num_ack_src_dst  num_ack_dst_src  num_syn_src_dst  num_syn_dst_src  num_rst_src_dst  num_rst_dst_src  first_packet  first_serv_packet  class\n",
       "0 -0.127368  2.357424 -0.863934 -0.756411 -0.458411     0.859266  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014  -1.137734   1.949417  1.023986  1.289289 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889   2.345335     0.030635          0.008185          0.042562            0.044490            0.203746          -0.287266           0.906322               -0.178933                1.626457           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566         0.154188         0.267020        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0\n",
       "1 -0.127368  2.357424 -0.863884 -0.756411 -0.458411     0.859213  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014  -1.137734   1.949417  1.023987  1.289289 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889   2.345335     0.030635          0.008185          0.043293            0.044490            0.204454          -0.287266           0.906322               -0.178933                1.626457           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566         0.154188         0.267872        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0\n",
       "2 -0.127368 -0.315216 -0.262465 -0.756411 -0.458411     0.597862  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014   1.258300  -0.663754 -1.036906 -0.445392 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889  -0.315189    -1.146024         -0.327640         -0.380841           -0.167630           -0.205911          -0.582023          -0.680948               -0.468717               -0.600078           -0.036490           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566        -0.098600        -0.226426        -0.073183        -0.022541         -0.02882        -0.210164     16.893706           3.188363    1.0\n",
       "3 -0.127368 -0.252576  1.273936  1.322033 -0.458411     1.234992  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014   1.158517  -0.663754 -1.031884  1.391738 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889  -0.283641     0.030635         -0.303363         -0.353784           -0.152296           -0.179733          -0.553556          -0.271239               -0.440730               -0.025361           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566        -0.080893        -0.194893        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0\n",
       "4 -0.127368 -0.252576 -0.188418  1.322033 -0.458411    -0.708360  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014   1.099910  -0.663754  0.924837  1.391442 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889  -0.283641     0.030635          0.008994          0.043293            0.045001            0.204454          -0.286574           0.906322               -0.178253                1.626457           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566         0.154799         0.267872        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pipeline_scaled(df=df, scaler=scaler_standard)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "113f57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_scaled_train,\n",
    "    X_scaled_val,\n",
    "    X_scaled_test,\n",
    "    y_scaled_train,\n",
    "    y_scaled_val,\n",
    "    y_scaled_test,\n",
    ") = test_train_val_split(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c54a732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.315216</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.258300</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>-0.445392</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.315189</td>\n",
       "      <td>-1.146024</td>\n",
       "      <td>-0.582023</td>\n",
       "      <td>-0.680948</td>\n",
       "      <td>-0.468717</td>\n",
       "      <td>-0.600078</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>3.188363</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.252576</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.158517</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>1.391738</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.553556</td>\n",
       "      <td>-0.271239</td>\n",
       "      <td>-0.440730</td>\n",
       "      <td>-0.025361</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.252576</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.099910</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>1.391442</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.286574</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178253</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ip_len     ip_DF  udp_sport  udp_len  icmp_code  icmp_chk  tcp_sport  tcp_dport   tcp_ack  tcp_ffyn  tcp_fsyn  tcp_fack  fr_length  conn_status  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_rst_dst_src  first_serv_packet  class\n",
       "0  2.357424 -0.756411  -0.411019 -0.37061  -0.135969 -0.138014  -1.137734   1.949417  1.289289 -0.674975 -0.693234  0.121177   2.345335     0.030635          -0.287266           0.906322               -0.178933                1.626457        -0.210164          -0.313641    0.0\n",
       "1  2.357424 -0.756411  -0.411019 -0.37061  -0.135969 -0.138014  -1.137734   1.949417  1.289289 -0.674975 -0.693234  0.121177   2.345335     0.030635          -0.287266           0.906322               -0.178933                1.626457        -0.210164          -0.313641    0.0\n",
       "2 -0.315216 -0.756411  -0.411019 -0.37061  -0.135969 -0.138014   1.258300  -0.663754 -0.445392 -0.674975 -0.693234  0.121177  -0.315189    -1.146024          -0.582023          -0.680948               -0.468717               -0.600078        -0.210164           3.188363    1.0\n",
       "3 -0.252576  1.322033  -0.411019 -0.37061  -0.135969 -0.138014   1.158517  -0.663754  1.391738 -0.674975 -0.693234  0.121177  -0.283641     0.030635          -0.553556          -0.271239               -0.440730               -0.025361        -0.210164          -0.313641    0.0\n",
       "4 -0.252576  1.322033  -0.411019 -0.37061  -0.135969 -0.138014   1.099910  -0.663754  1.391442 -0.674975 -0.693234  0.121177  -0.283641     0.030635          -0.286574           0.906322               -0.178253                1.626457        -0.210164          -0.313641    0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_gt1_scaled = pipeline_corr_gt1_scaled(df=df, scaler=scaler_standard_gt1, cols=cols_corr_gt1)\n",
    "df_corr_gt1_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a8555fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_corr_gt1_scaled_train,\n",
    "    X_corr_gt1_scaled_val,\n",
    "    X_corr_gt1_scaled_test,\n",
    "    y_corr_gt1_scaled_train,\n",
    "    y_corr_gt1_scaled_val,\n",
    "    y_corr_gt1_scaled_test,\n",
    ") = test_train_val_split(df_corr_gt1_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b9ba382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.516735</td>\n",
       "      <td>-1.070537</td>\n",
       "      <td>4.199741</td>\n",
       "      <td>-1.394049</td>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.583451</td>\n",
       "      <td>1.314415</td>\n",
       "      <td>0.300038</td>\n",
       "      <td>-0.100427</td>\n",
       "      <td>-0.074686</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>-0.068260</td>\n",
       "      <td>-0.085588</td>\n",
       "      <td>-0.029476</td>\n",
       "      <td>-0.045298</td>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.115908</td>\n",
       "      <td>0.130896</td>\n",
       "      <td>-0.111055</td>\n",
       "      <td>-0.021935</td>\n",
       "      <td>-0.102228</td>\n",
       "      <td>0.114430</td>\n",
       "      <td>0.068183</td>\n",
       "      <td>-0.159354</td>\n",
       "      <td>0.227031</td>\n",
       "      <td>-0.697531</td>\n",
       "      <td>0.338713</td>\n",
       "      <td>0.248599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.516680</td>\n",
       "      <td>-1.070594</td>\n",
       "      <td>4.199846</td>\n",
       "      <td>-1.393880</td>\n",
       "      <td>0.957351</td>\n",
       "      <td>0.583922</td>\n",
       "      <td>1.314396</td>\n",
       "      <td>0.300622</td>\n",
       "      <td>-0.100220</td>\n",
       "      <td>-0.074792</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>-0.068254</td>\n",
       "      <td>-0.085581</td>\n",
       "      <td>-0.029455</td>\n",
       "      <td>-0.045232</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.130898</td>\n",
       "      <td>-0.111276</td>\n",
       "      <td>-0.022129</td>\n",
       "      <td>-0.102981</td>\n",
       "      <td>0.114281</td>\n",
       "      <td>0.068581</td>\n",
       "      <td>-0.159547</td>\n",
       "      <td>0.227155</td>\n",
       "      <td>-0.697391</td>\n",
       "      <td>0.338751</td>\n",
       "      <td>0.248571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.194275</td>\n",
       "      <td>0.599526</td>\n",
       "      <td>-2.547375</td>\n",
       "      <td>1.784875</td>\n",
       "      <td>4.735872</td>\n",
       "      <td>2.335350</td>\n",
       "      <td>-1.259882</td>\n",
       "      <td>0.229815</td>\n",
       "      <td>-6.911835</td>\n",
       "      <td>-8.327002</td>\n",
       "      <td>-2.483018</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>-2.341332</td>\n",
       "      <td>-1.531040</td>\n",
       "      <td>-0.593786</td>\n",
       "      <td>1.307459</td>\n",
       "      <td>5.735253</td>\n",
       "      <td>2.203422</td>\n",
       "      <td>1.863483</td>\n",
       "      <td>0.821762</td>\n",
       "      <td>-1.594002</td>\n",
       "      <td>-2.386889</td>\n",
       "      <td>2.089085</td>\n",
       "      <td>8.092894</td>\n",
       "      <td>1.559132</td>\n",
       "      <td>0.200839</td>\n",
       "      <td>-1.005800</td>\n",
       "      <td>0.331981</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.795953</td>\n",
       "      <td>-0.176684</td>\n",
       "      <td>-0.057415</td>\n",
       "      <td>0.785596</td>\n",
       "      <td>-0.009620</td>\n",
       "      <td>-1.722739</td>\n",
       "      <td>-0.344424</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.169341</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>-0.112997</td>\n",
       "      <td>-0.017776</td>\n",
       "      <td>-0.066358</td>\n",
       "      <td>0.030031</td>\n",
       "      <td>-0.103921</td>\n",
       "      <td>-0.081910</td>\n",
       "      <td>-0.207825</td>\n",
       "      <td>-0.091106</td>\n",
       "      <td>0.108699</td>\n",
       "      <td>0.166714</td>\n",
       "      <td>-0.022175</td>\n",
       "      <td>-0.519474</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>0.563761</td>\n",
       "      <td>-0.508144</td>\n",
       "      <td>1.405539</td>\n",
       "      <td>0.976435</td>\n",
       "      <td>-0.170937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.698577</td>\n",
       "      <td>-0.885367</td>\n",
       "      <td>1.251274</td>\n",
       "      <td>1.889236</td>\n",
       "      <td>-0.672711</td>\n",
       "      <td>-1.345817</td>\n",
       "      <td>-0.983839</td>\n",
       "      <td>0.260147</td>\n",
       "      <td>0.271514</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>-0.036208</td>\n",
       "      <td>-0.054843</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>-0.013959</td>\n",
       "      <td>-0.135784</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>-0.014911</td>\n",
       "      <td>0.071884</td>\n",
       "      <td>-0.026465</td>\n",
       "      <td>0.074480</td>\n",
       "      <td>-0.111767</td>\n",
       "      <td>-0.359301</td>\n",
       "      <td>0.286965</td>\n",
       "      <td>0.171620</td>\n",
       "      <td>-0.189821</td>\n",
       "      <td>-0.418918</td>\n",
       "      <td>-0.024381</td>\n",
       "      <td>-0.276469</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27  class\n",
       "0 -1.516735 -1.070537  4.199741 -1.394049  0.957756  0.583451  1.314415  0.300038 -0.100427 -0.074686  0.018951 -0.068260 -0.085588 -0.029476 -0.045298  0.029734  0.115908  0.130896 -0.111055 -0.021935 -0.102228  0.114430  0.068183 -0.159354  0.227031 -0.697531  0.338713  0.248599    0.0\n",
       "1 -1.516680 -1.070594  4.199846 -1.393880  0.957351  0.583922  1.314396  0.300622 -0.100220 -0.074792  0.018950 -0.068254 -0.085581 -0.029455 -0.045232  0.029740  0.115972  0.130898 -0.111276 -0.022129 -0.102981  0.114281  0.068581 -0.159547  0.227155 -0.697391  0.338751  0.248571    0.0\n",
       "2 -2.194275  0.599526 -2.547375  1.784875  4.735872  2.335350 -1.259882  0.229815 -6.911835 -8.327002 -2.483018  0.013701 -2.341332 -1.531040 -0.593786  1.307459  5.735253  2.203422  1.863483  0.821762 -1.594002 -2.386889  2.089085  8.092894  1.559132  0.200839 -1.005800  0.331981    1.0\n",
       "3 -1.795953 -0.176684 -0.057415  0.785596 -0.009620 -1.722739 -0.344424  0.030185  0.169341  0.000372 -0.112997 -0.017776 -0.066358  0.030031 -0.103921 -0.081910 -0.207825 -0.091106  0.108699  0.166714 -0.022175 -0.519474  0.144395  0.563761 -0.508144  1.405539  0.976435 -0.170937    0.0\n",
       "4 -1.698577 -0.885367  1.251274  1.889236 -0.672711 -1.345817 -0.983839  0.260147  0.271514  0.089606 -0.036208 -0.054843  0.004780 -0.013959 -0.135784 -0.008889 -0.014911  0.071884 -0.026465  0.074480 -0.111767 -0.359301  0.286965  0.171620 -0.189821 -0.418918 -0.024381 -0.276469    0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca = pipeline_pca(df=df, scaler=scaler_standard, pca=pca_standard)\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d7b39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_pca_train,\n",
    "    X_pca_val,\n",
    "    X_pca_test,\n",
    "    y_pca_train,\n",
    "    y_pca_val,\n",
    "    y_pca_test,\n",
    ") = test_train_val_split(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9fd2315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.543609</td>\n",
       "      <td>4.230357</td>\n",
       "      <td>1.869249</td>\n",
       "      <td>-0.251843</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.190714</td>\n",
       "      <td>0.364347</td>\n",
       "      <td>-0.114097</td>\n",
       "      <td>0.499856</td>\n",
       "      <td>-0.081331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.543609</td>\n",
       "      <td>4.230357</td>\n",
       "      <td>1.869249</td>\n",
       "      <td>-0.251843</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.190714</td>\n",
       "      <td>0.364347</td>\n",
       "      <td>-0.114097</td>\n",
       "      <td>0.499856</td>\n",
       "      <td>-0.081331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.994167</td>\n",
       "      <td>-1.461920</td>\n",
       "      <td>-0.938954</td>\n",
       "      <td>0.293926</td>\n",
       "      <td>1.364275</td>\n",
       "      <td>-0.010223</td>\n",
       "      <td>0.649041</td>\n",
       "      <td>-0.738695</td>\n",
       "      <td>-0.118310</td>\n",
       "      <td>0.030188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.350594</td>\n",
       "      <td>0.261992</td>\n",
       "      <td>-0.964845</td>\n",
       "      <td>1.102809</td>\n",
       "      <td>-0.889646</td>\n",
       "      <td>-1.028780</td>\n",
       "      <td>-0.107525</td>\n",
       "      <td>0.580810</td>\n",
       "      <td>-1.068071</td>\n",
       "      <td>0.201405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.704318</td>\n",
       "      <td>1.340008</td>\n",
       "      <td>-1.522401</td>\n",
       "      <td>1.729258</td>\n",
       "      <td>-1.340019</td>\n",
       "      <td>-0.612810</td>\n",
       "      <td>-0.126361</td>\n",
       "      <td>0.481897</td>\n",
       "      <td>0.016040</td>\n",
       "      <td>-0.037508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6         7         8         9  class\n",
       "0 -0.543609  4.230357  1.869249 -0.251843  0.788871  0.190714  0.364347 -0.114097  0.499856 -0.081331    0.0\n",
       "1 -0.543609  4.230357  1.869249 -0.251843  0.788871  0.190714  0.364347 -0.114097  0.499856 -0.081331    0.0\n",
       "2 -1.994167 -1.461920 -0.938954  0.293926  1.364275 -0.010223  0.649041 -0.738695 -0.118310  0.030188    1.0\n",
       "3 -1.350594  0.261992 -0.964845  1.102809 -0.889646 -1.028780 -0.107525  0.580810 -1.068071  0.201405    0.0\n",
       "4 -0.704318  1.340008 -1.522401  1.729258 -1.340019 -0.612810 -0.126361  0.481897  0.016040 -0.037508    0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_gt1_pca = pipeline_corr_gt1_pca(df=df, scaler=scaler_standard_gt1, cols=cols_corr_gt1, pca=pca_corr_gt1_standard)\n",
    "df_corr_gt1_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f6bb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_corr_gt1_pca_train,\n",
    "    X_corr_gt1_pca_val,\n",
    "    X_corr_gt1_pca_test,\n",
    "    y_corr_gt1_pca_train,\n",
    "    y_corr_gt1_pca_val,\n",
    "    y_corr_gt1_pca_test,\n",
    ") = test_train_val_split(df_corr_gt1_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63661354",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268a3cb",
   "metadata": {},
   "source": [
    "### All features scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58616ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, random_state=245)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_scaled = SVC(**{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}, random_state=random_state)\n",
    "svm_scaled.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0275a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_scaled_train,\n",
    "    X_scaled_val,\n",
    "    X_scaled_test,\n",
    "    y_scaled_train,\n",
    "    y_scaled_val,\n",
    "    y_scaled_test,\n",
    ") = test_train_val_split(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4dddd094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.997570342503331\n",
      "Precision: 0.9971176364618988\n",
      "Recall: 0.9972972972972973\n",
      "F1: 0.9972074587874966\n",
      "Time per data per iter: 518.729681\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        svm_scaled,\n",
    "        \"SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "117aedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     15969\n",
      "           1       0.99      0.98      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9904577984777917\n",
      "Precision: 0.994659157117887\n",
      "Recall: 0.9811302681992338\n",
      "F1: 0.9878483942520976\n",
      "Time per data per iter: 1037.2630334\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        svm_scaled,\n",
    "        \"SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecfdc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.66      0.01      0.02     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.71      0.50      0.44     75890\n",
      "weighted avg       0.74      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7671366451442878\n",
      "Precision: 0.65625\n",
      "Recall: 0.00946372239747634\n",
      "F1: 0.018658374055975122\n",
      "Time per data per iter: 2984.3067799\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        svm_scaled,\n",
    "        \"SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\",\n",
    "        \"New attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0fed5",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1782f5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1000, random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1000, random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1000, random_state=245)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_corr_gt1_scaled = SVC(**{'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}, random_state=random_state)\n",
    "svm_corr_gt1_scaled.fit(X_corr_gt1_scaled_train, y_corr_gt1_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe62c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      7209\n",
      "         1.0       1.00      0.99      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9957676933928992\n",
      "Precision: 0.9971056439942113\n",
      "Recall: 0.9931531531531531\n",
      "F1: 0.9951254739122586\n",
      "Time per data per iter: 362.8911428\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        svm_corr_gt1_scaled,\n",
    "        \"SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "280aa5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     15969\n",
      "           1       1.00      0.97      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9890188950736492\n",
      "Precision: 0.9975490196078431\n",
      "Recall: 0.9746168582375478\n",
      "F1: 0.9859496124031009\n",
      "Time per data per iter: 749.0637479\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        svm_corr_gt1_scaled,\n",
    "        \"SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ad2f9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.38      0.00      0.01     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.57      0.50      0.44     75890\n",
      "weighted avg       0.68      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7656212939781263\n",
      "Precision: 0.3825503355704698\n",
      "Recall: 0.0032109058134294727\n",
      "F1: 0.00636835930953578\n",
      "Time per data per iter: 2147.5150645999997\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        svm_corr_gt1_scaled,\n",
    "        \"SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc636b",
   "metadata": {},
   "source": [
    "### All features with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58667323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=&#x27;auto&#x27;, random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=&#x27;auto&#x27;, random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma='auto', random_state=245)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pca = SVC(**{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}, random_state=random_state)\n",
    "svm_pca.fit(X_pca_train, y_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "910a2b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9968649580688141\n",
      "Precision: 0.9955035971223022\n",
      "Recall: 0.9972972972972973\n",
      "F1: 0.9963996399639964\n",
      "Time per data per iter: 689.6470952999999\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        svm_pca,\n",
    "        \"SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a38b52e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     15969\n",
      "           1       1.00      0.98      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9910636525426938\n",
      "Precision: 0.9968835216205687\n",
      "Recall: 0.9804597701149426\n",
      "F1: 0.988603438284721\n",
      "Time per data per iter: 1514.0536825\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        svm_pca,\n",
    "        \"SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd05dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.62      0.01      0.02     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.69      0.50      0.44     75890\n",
      "weighted avg       0.73      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7668203979443932\n",
      "Precision: 0.6196581196581197\n",
      "Recall: 0.00816809373591708\n",
      "F1: 0.01612365172912265\n",
      "Time per data per iter: 3798.1916195\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        svm_pca,\n",
    "        \"SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\",\n",
    "        \"New attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011fe83a",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "419afe62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1000, gamma=&#x27;auto&#x27;, random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1000, gamma=&#x27;auto&#x27;, random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1000, gamma='auto', random_state=245)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_corr_gt1_pca = SVC(**{'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}, random_state=random_state)\n",
    "svm_corr_gt1_pca.fit(X_corr_gt1_pca_train, y_corr_gt1_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53ba3e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      7209\n",
      "         1.0       1.00      0.99      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_corr_gt1_pca_test, svm_corr_gt1_pca.predict(X_corr_gt1_pca_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d89d610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      7209\n",
      "         1.0       1.00      0.99      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9964730778274159\n",
      "Precision: 0.9985509871400109\n",
      "Recall: 0.9933333333333333\n",
      "F1: 0.9959353265287688\n",
      "Time per data per iter: 428.1901944\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        svm_corr_gt1_pca,\n",
    "        \"SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e75d1d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     15969\n",
      "           1       1.00      0.97      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.988602370404029\n",
      "Precision: 0.9993105486063233\n",
      "Recall: 0.9718390804597701\n",
      "F1: 0.9853833827028602\n",
      "Time per data per iter: 830.6234297999999\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        svm_corr_gt1_pca,\n",
    "        \"SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb5b4f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.59      0.00      0.01     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.68      0.50      0.44     75890\n",
      "weighted avg       0.72      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7663855580445381\n",
      "Precision: 0.5864661654135338\n",
      "Recall: 0.004393871113114015\n",
      "F1: 0.008722393066815767\n",
      "Time per data per iter: 2294.048158\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        svm_corr_gt1_pca,\n",
    "        \"SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd6b1d",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b0858",
   "metadata": {},
   "source": [
    "### All features scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8385ec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=1.519911082952933e-07)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=1.519911082952933e-07)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=1.519911082952933e-07)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_scaled = GaussianNB(**{'var_smoothing': 1.519911082952933e-07})\n",
    "gnb_scaled.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3871b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.68      0.81      7209\n",
      "         1.0       0.71      0.99      0.83      5550\n",
      "\n",
      "    accuracy                           0.82     12759\n",
      "   macro avg       0.85      0.84      0.82     12759\n",
      "weighted avg       0.87      0.82      0.82     12759\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 1.519911082952933e-07}\n",
      "Data size: 12759\n",
      "Accuracy: 0.8173838075084254\n",
      "Precision: 0.7068876895399641\n",
      "Recall: 0.9911711711711712\n",
      "F1: 0.8252325232523252\n",
      "Time per data per iter: 9.916843\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        gnb_scaled,\n",
    "        \"GaussianNB {'var_smoothing': 1.519911082952933e-07}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c84a537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80     15969\n",
      "           1       0.66      0.99      0.79     10440\n",
      "\n",
      "    accuracy                           0.79     26409\n",
      "   macro avg       0.82      0.83      0.79     26409\n",
      "weighted avg       0.86      0.79      0.80     26409\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 1.519911082952933e-07}\n",
      "Data size: 26409\n",
      "Accuracy: 0.7948426672725207\n",
      "Precision: 0.6610647851186658\n",
      "Recall: 0.9871647509578544\n",
      "F1: 0.7918555512869765\n",
      "Time per data per iter: 19.1947635\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        gnb_scaled,\n",
    "        \"GaussianNB {'var_smoothing': 1.519911082952933e-07}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e3ca6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80     58138\n",
      "           1       0.31      0.27      0.29     17752\n",
      "\n",
      "    accuracy                           0.69     75890\n",
      "   macro avg       0.55      0.54      0.55     75890\n",
      "weighted avg       0.68      0.69      0.68     75890\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 1.519911082952933e-07}\n",
      "Data size: 75890\n",
      "Accuracy: 0.6913427329028857\n",
      "Precision: 0.3133473739634066\n",
      "Recall: 0.26819513294276703\n",
      "F1: 0.28901839373520305\n",
      "Time per data per iter: 50.2949524\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        gnb_scaled,\n",
    "        \"GaussianNB {'var_smoothing': 1.519911082952933e-07}\",\n",
    "        \"New attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ae162",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80cebf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=4.328761281083053e-06)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=4.328761281083053e-06)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=4.328761281083053e-06)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_corr_gt1_scaled = GaussianNB(**{'var_smoothing': 4.328761281083053e-06})\n",
    "gnb_corr_gt1_scaled.fit(X_corr_gt1_scaled_train, y_corr_gt1_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e13a741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.70      0.82      7209\n",
      "         1.0       0.72      0.99      0.83      5550\n",
      "\n",
      "    accuracy                           0.83     12759\n",
      "   macro avg       0.86      0.85      0.83     12759\n",
      "weighted avg       0.87      0.83      0.82     12759\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 4.328761281083053e-06}\n",
      "Data size: 12759\n",
      "Accuracy: 0.8260051728191865\n",
      "Precision: 0.7158973029045643\n",
      "Recall: 0.9947747747747748\n",
      "F1: 0.8326044337204043\n",
      "Time per data per iter: 4.6966607\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        gnb_corr_gt1_scaled,\n",
    "        \"GaussianNB {'var_smoothing': 4.328761281083053e-06}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60189921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81     15969\n",
      "           1       0.67      0.99      0.80     10440\n",
      "\n",
      "    accuracy                           0.81     26409\n",
      "   macro avg       0.83      0.84      0.81     26409\n",
      "weighted avg       0.87      0.81      0.81     26409\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 4.328761281083053e-06}\n",
      "Data size: 26409\n",
      "Accuracy: 0.805672308682646\n",
      "Precision: 0.6718911917098446\n",
      "Recall: 0.9936781609195402\n",
      "F1: 0.8017001545595053\n",
      "Time per data per iter: 7.9887782000000005\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        gnb_corr_gt1_scaled,\n",
    "        \"GaussianNB {'var_smoothing': 4.328761281083053e-06}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0bdc1338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81     58138\n",
      "           1       0.32      0.25      0.28     17752\n",
      "\n",
      "    accuracy                           0.70     75890\n",
      "   macro avg       0.55      0.54      0.55     75890\n",
      "weighted avg       0.68      0.70      0.69     75890\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 4.328761281083053e-06}\n",
      "Data size: 75890\n",
      "Accuracy: 0.6996969297667677\n",
      "Precision: 0.31934882386689617\n",
      "Recall: 0.2508449752140604\n",
      "F1: 0.2809818273599193\n",
      "Time per data per iter: 28.3544155\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        gnb_corr_gt1_scaled,\n",
    "        \"GaussianNB {'var_smoothing': 4.328761281083053e-06}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58eeb37",
   "metadata": {},
   "source": [
    "### All features with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b8bcb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=4.328761281083053e-06)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=4.328761281083053e-06)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=4.328761281083053e-06)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_pca = GaussianNB(**{'var_smoothing': 4.328761281083053e-06})\n",
    "gnb_pca.fit(X_pca_train, y_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "742d7afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.63      0.77      7209\n",
      "         1.0       0.67      0.99      0.80      5550\n",
      "\n",
      "    accuracy                           0.79     12759\n",
      "   macro avg       0.83      0.81      0.78     12759\n",
      "weighted avg       0.85      0.79      0.78     12759\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 4.328761281083053e-06}\n",
      "Data size: 12759\n",
      "Accuracy: 0.7855631319068892\n",
      "Precision: 0.6716691068814056\n",
      "Recall: 0.9918918918918919\n",
      "F1: 0.800960279353994\n",
      "Time per data per iter: 15.768047\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        gnb_pca,\n",
    "        \"GaussianNB {'var_smoothing': 4.328761281083053e-06}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74a6bc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.61      0.76     15969\n",
      "           1       0.62      0.98      0.76     10440\n",
      "\n",
      "    accuracy                           0.76     26409\n",
      "   macro avg       0.80      0.80      0.76     26409\n",
      "weighted avg       0.84      0.76      0.76     26409\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 4.328761281083053e-06}\n",
      "Data size: 26409\n",
      "Accuracy: 0.7600060585406491\n",
      "Precision: 0.6247415156307019\n",
      "Recall: 0.9839080459770115\n",
      "F1: 0.7642288520199391\n",
      "Time per data per iter: 30.440379399999998\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        gnb_pca,\n",
    "        \"GaussianNB {'var_smoothing': 4.328761281083053e-06}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0e111e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.75     58138\n",
      "           1       0.38      0.71      0.50     17752\n",
      "\n",
      "    accuracy                           0.66     75890\n",
      "   macro avg       0.63      0.68      0.62     75890\n",
      "weighted avg       0.76      0.66      0.69     75890\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 4.328761281083053e-06}\n",
      "Data size: 75890\n",
      "Accuracy: 0.6643563051785479\n",
      "Precision: 0.38287413521058383\n",
      "Recall: 0.710793150067598\n",
      "F1: 0.4976729510136468\n",
      "Time per data per iter: 83.339836\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        gnb_pca,\n",
    "        \"GaussianNB {'var_smoothing': 4.328761281083053e-06}\",\n",
    "        \"New attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085ec78",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb7fc67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=0.0005336699231206307)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=0.0005336699231206307)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=0.0005336699231206307)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_corr_gt1_pca = GaussianNB(**{'var_smoothing': 0.0005336699231206307})\n",
    "gnb_corr_gt1_pca.fit(X_corr_gt1_pca_train, y_corr_gt1_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e4b2852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94      7209\n",
      "         1.0       0.92      0.93      0.92      5550\n",
      "\n",
      "    accuracy                           0.93     12759\n",
      "   macro avg       0.93      0.93      0.93     12759\n",
      "weighted avg       0.93      0.93      0.93     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_corr_gt1_pca_test, gnb_corr_gt1_pca.predict(X_corr_gt1_pca_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3124fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94      7209\n",
      "         1.0       0.92      0.93      0.92      5550\n",
      "\n",
      "    accuracy                           0.93     12759\n",
      "   macro avg       0.93      0.93      0.93     12759\n",
      "weighted avg       0.93      0.93      0.93     12759\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 0.0005336699231206307}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9345559996864958\n",
      "Precision: 0.922718307333692\n",
      "Recall: 0.9272072072072072\n",
      "F1: 0.9249573110452054\n",
      "Time per data per iter: 12.798575900000001\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        gnb_corr_gt1_pca,\n",
    "        \"GaussianNB {'var_smoothing': 0.0005336699231206307}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "624b559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97     15969\n",
      "           1       0.94      0.98      0.96     10440\n",
      "\n",
      "    accuracy                           0.97     26409\n",
      "   macro avg       0.96      0.97      0.97     26409\n",
      "weighted avg       0.97      0.97      0.97     26409\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 0.0005336699231206307}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9686849180203718\n",
      "Precision: 0.9428729383580576\n",
      "Recall: 0.9801724137931035\n",
      "F1: 0.9611609449114732\n",
      "Time per data per iter: 22.165475100000002\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        gnb_corr_gt1_pca,\n",
    "        \"GaussianNB {'var_smoothing': 0.0005336699231206307}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69e30d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88     58138\n",
      "           1       0.73      0.19      0.30     17752\n",
      "\n",
      "    accuracy                           0.79     75890\n",
      "   macro avg       0.76      0.58      0.59     75890\n",
      "weighted avg       0.78      0.79      0.74     75890\n",
      "\n",
      "\n",
      "Model: GaussianNB {'var_smoothing': 0.0005336699231206307}\n",
      "Data size: 75890\n",
      "Accuracy: 0.793371985768876\n",
      "Precision: 0.7291436158442133\n",
      "Recall: 0.18561288868859846\n",
      "F1: 0.2959004984059988\n",
      "Time per data per iter: 41.3118332\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        gnb_corr_gt1_pca,\n",
    "        \"GaussianNB {'var_smoothing': 0.0005336699231206307}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cefd9502",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0     SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1     SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2     SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3    SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4    SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5    SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6      SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7      SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8      SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9     SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10    SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11    SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12  GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13  GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14  GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15  GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16  GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17  GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18  GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19  GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20  GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21  GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22  GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23  GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a983c9",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02930465",
   "metadata": {},
   "source": [
    "### All features scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdfdbcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', random_state=245, solver='liblinear')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scaled = LogisticRegression(**{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}, random_state=random_state)\n",
    "log_scaled.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e0b4dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      7209\n",
      "         1.0       0.99      0.99      0.99      5550\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9933380358962302\n",
      "Precision: 0.9899587591895285\n",
      "Recall: 0.9947747747747748\n",
      "F1: 0.9923609238788532\n",
      "Time per data per iter: 6.336827\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_scaled,\n",
    "        \"Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bee8826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     15969\n",
      "           1       1.00      0.95      0.97     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9800446817372865\n",
      "Precision: 0.9951053840775147\n",
      "Recall: 0.9542145593869732\n",
      "F1: 0.9742310889443059\n",
      "Time per data per iter: 18.706266\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_scaled,\n",
    "        \"Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8ffee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.85      0.04      0.08     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.81      0.52      0.48     75890\n",
      "weighted avg       0.79      0.77      0.69     75890\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7744762155751745\n",
      "Precision: 0.8450704225352113\n",
      "Recall: 0.04393871113114015\n",
      "F1: 0.08353413654618473\n",
      "Time per data per iter: 36.033333\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_scaled,\n",
    "        \"Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\",\n",
    "        \"New attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "983861f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                      SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                      SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                      SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                     SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                     SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                     SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                       SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                       SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                       SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                      SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                     SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                     SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                   GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                   GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                   GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                   GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                   GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                   GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                   GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                   GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                   GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                   GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                   GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                   GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24  Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25  Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26  Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9193c",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "201220e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibrahim/pyenv_sjsu/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/ibrahim/pyenv_sjsu/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=245, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=245, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='none', random_state=245, solver='newton-cg')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_scaled = LogisticRegression(**{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}, random_state=random_state)\n",
    "log_corr_gt1_scaled.fit(X_corr_gt1_scaled_train, y_corr_gt1_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13fa009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      7209\n",
      "         1.0       0.98      0.99      0.99      5550\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9896543616270868\n",
      "Precision: 0.983232251159472\n",
      "Recall: 0.9931531531531531\n",
      "F1: 0.9881678020795984\n",
      "Time per data per iter: 11.0295002\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_corr_gt1_scaled,\n",
    "        \"Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4af9af28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15969\n",
      "           1       0.99      0.97      0.98     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9841341966753758\n",
      "Precision: 0.987639902676399\n",
      "Recall: 0.9720306513409962\n",
      "F1: 0.9797731112720252\n",
      "Time per data per iter: 15.1476308\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_corr_gt1_scaled,\n",
    "        \"Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8bed0ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.88     58138\n",
      "           1       0.82      0.10      0.18     17752\n",
      "\n",
      "    accuracy                           0.78     75890\n",
      "   macro avg       0.80      0.55      0.53     75890\n",
      "weighted avg       0.79      0.78      0.71     75890\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7846751877717749\n",
      "Precision: 0.8219990871748061\n",
      "Recall: 0.10145335736818387\n",
      "F1: 0.18061475204332347\n",
      "Time per data per iter: 24.3006565\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_corr_gt1_scaled,\n",
    "        \"Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31cbbb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                           SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                          SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                          SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                        GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                        GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                        GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                        GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                        GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                        GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                        GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                        GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                        GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                        GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                        GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                        GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b83278",
   "metadata": {},
   "source": [
    "### All features with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "38408f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, random_state=245, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, random_state=245, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, random_state=245, solver='liblinear')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pca = LogisticRegression(**{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, random_state=random_state)\n",
    "log_pca.fit(X_pca_train, y_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "056747d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7209\n",
      "         1.0       0.97      0.98      0.98      5550\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9797006034955718\n",
      "Precision: 0.9741889227460119\n",
      "Recall: 0.9792792792792793\n",
      "F1: 0.9767274687752718\n",
      "Time per data per iter: 16.594932699999998\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_pca,\n",
    "        \"Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a608826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15969\n",
      "           1       0.98      0.97      0.98     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9825059638759513\n",
      "Precision: 0.9834302325581395\n",
      "Recall: 0.9721264367816091\n",
      "F1: 0.9777456647398844\n",
      "Time per data per iter: 22.9889903\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_pca,\n",
    "        \"Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4afe5c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87     58138\n",
      "           1       0.53      0.04      0.08     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.65      0.52      0.47     75890\n",
      "weighted avg       0.72      0.77      0.68     75890\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7673079457108973\n",
      "Precision: 0.5333333333333333\n",
      "Recall: 0.041910770617395225\n",
      "F1: 0.07771452446858515\n",
      "Time per data per iter: 72.396318\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_pca,\n",
    "        \"Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\",\n",
    "        \"New attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6f374d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                           SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                          SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                          SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                        GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                        GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                        GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                        GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                        GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                        GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                        GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                        GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                        GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                        GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                        GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                        GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30       Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31       Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32       Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644fac2",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "97183156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', random_state=245, solver='liblinear')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_pca = LogisticRegression(**{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}, random_state=random_state)\n",
    "log_corr_gt1_pca.fit(X_corr_gt1_pca_train, y_corr_gt1_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c89be76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7209\n",
      "         1.0       0.97      0.98      0.98      5550\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n",
      "\n",
      "Model: Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9784465867230974\n",
      "Precision: 0.9737740255074546\n",
      "Recall: 0.9767567567567568\n",
      "F1: 0.9752631105514078\n",
      "Time per data per iter: 7.6282984\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_corr_gt1_pca,\n",
    "        \"Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7209d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     15969\n",
      "           1       0.98      0.97      0.98     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9817486462948237\n",
      "Precision: 0.9805056938814901\n",
      "Recall: 0.9731800766283525\n",
      "F1: 0.9768291510431689\n",
      "Time per data per iter: 13.8802562\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_corr_gt1_pca,\n",
    "        \"Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aac059da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87     58138\n",
      "           1       0.55      0.03      0.06     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.66      0.51      0.46     75890\n",
      "weighted avg       0.72      0.77      0.68     75890\n",
      "\n",
      "\n",
      "Model: Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7673606535775465\n",
      "Precision: 0.5457979225684608\n",
      "Recall: 0.0325597115817936\n",
      "F1: 0.06145340492265163\n",
      "Time per data per iter: 30.204715\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_corr_gt1_pca,\n",
    "        \"Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31bf3c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                           SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                          SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                            SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                           SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                          SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                          SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                        GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                        GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                        GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                        GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                        GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                        GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                        GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                        GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                        GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                        GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                        GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                        GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30       Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31       Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32       Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33       Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34       Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35       Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e15cac",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed5b05",
   "metadata": {},
   "source": [
    "### All features scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10e4d7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_scaled = XGBClassifier(**{'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}, random_state=random_state)\n",
    "xgb_scaled.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "793d17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9998432479034407\n",
      "Precision: 0.9998198198198198\n",
      "Recall: 0.9998198198198198\n",
      "F1: 0.9998198198198198\n",
      "Time per data per iter: 39.1345975\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        xgb_scaled,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "353d67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     15969\n",
      "           1       1.00      0.97      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9891703585898747\n",
      "Precision: 0.9993115656963021\n",
      "Recall: 0.9732758620689655\n",
      "F1: 0.9861218944099379\n",
      "Time per data per iter: 51.635734899999996\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        xgb_scaled,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4289033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86     58138\n",
      "           1       0.28      0.01      0.02     17752\n",
      "\n",
      "    accuracy                           0.76     75890\n",
      "   macro avg       0.52      0.50      0.44     75890\n",
      "weighted avg       0.65      0.76      0.67     75890\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7623270523125576\n",
      "Precision: 0.2755905511811024\n",
      "Recall: 0.009858044164037854\n",
      "F1: 0.019035187904497743\n",
      "Time per data per iter: 126.8047902\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        xgb_scaled,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}\",\n",
    "        \"New attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4af201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d27b6",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3595eec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_corr_gt1_scaled = XGBClassifier(**{'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}, random_state=random_state)\n",
    "xgb_corr_gt1_scaled.fit(X_corr_gt1_scaled_train, y_corr_gt1_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e666d778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}\n",
      "Data size: 12759\n",
      "Accuracy: 0.999764871855161\n",
      "Precision: 0.9996397045577373\n",
      "Recall: 0.9998198198198198\n",
      "F1: 0.9997297540762092\n",
      "Time per data per iter: 22.7488496\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        xgb_corr_gt1_scaled,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2ecc8871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     15969\n",
      "           1       1.00      0.98      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9908364572683555\n",
      "Precision: 0.9992167613080086\n",
      "Recall: 0.9775862068965517\n",
      "F1: 0.9882831412801395\n",
      "Time per data per iter: 46.506607200000005\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        xgb_corr_gt1_scaled,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e6156307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87     58138\n",
      "           1       0.75      0.09      0.16     17752\n",
      "\n",
      "    accuracy                           0.78     75890\n",
      "   macro avg       0.77      0.54      0.52     75890\n",
      "weighted avg       0.77      0.78      0.71     75890\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}\n",
      "Data size: 75890\n",
      "Accuracy: 0.779971010673343\n",
      "Precision: 0.7509523809523809\n",
      "Recall: 0.08883506083821541\n",
      "F1: 0.15887568003223854\n",
      "Time per data per iter: 122.5865796\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        xgb_corr_gt1_scaled,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9fe0f554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>22.748850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>46.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.779971</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>122.586580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790\n",
       "39  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999765   0.999640  0.999820  0.999730               22.748850\n",
       "40  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.990836   0.999217  0.977586  0.988283               46.506607\n",
       "41  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}      New attacks        |correlation| > 0.1 features scaled      75890  0.779971   0.750952  0.088835  0.158876              122.586580"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac5d6b",
   "metadata": {},
   "source": [
    "### All features with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c46bdaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pca = XGBClassifier(**{'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}, random_state=random_state)\n",
    "xgb_pca.fit(X_pca_train, y_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f81a77a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       0.99      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9957676933928992\n",
      "Precision: 0.9944224541201871\n",
      "Recall: 0.9958558558558559\n",
      "F1: 0.9951386388188693\n",
      "Time per data per iter: 89.6757421\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        xgb_pca,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c1177a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     15969\n",
      "           1       1.00      0.98      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}\n",
      "Data size: 26409\n",
      "Accuracy: 0.991480177212314\n",
      "Precision: 0.9963074531143717\n",
      "Recall: 0.9820881226053639\n",
      "F1: 0.9891466885340793\n",
      "Time per data per iter: 105.6543341\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        xgb_pca,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "79ec814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.60      0.02      0.03     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.69      0.51      0.45     75890\n",
      "weighted avg       0.73      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7674528923441823\n",
      "Precision: 0.6019607843137255\n",
      "Recall: 0.017293826047769266\n",
      "F1: 0.03362172817873179\n",
      "Time per data per iter: 169.95783930000002\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        xgb_pca,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}\",\n",
    "        \"New attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "95a38ee4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>22.748850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>46.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.779971</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>122.586580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.994422</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>89.675742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.989147</td>\n",
       "      <td>105.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>169.957839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790\n",
       "39  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999765   0.999640  0.999820  0.999730               22.748850\n",
       "40  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.990836   0.999217  0.977586  0.988283               46.506607\n",
       "41  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}      New attacks        |correlation| > 0.1 features scaled      75890  0.779971   0.750952  0.088835  0.158876              122.586580\n",
       "42   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}    Known attacks                  All features with 95% PCA      12759  0.995768   0.994422  0.995856  0.995139               89.675742\n",
       "43   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}  Similar attacks                  All features with 95% PCA      26409  0.991480   0.996307  0.982088  0.989147              105.654334\n",
       "44   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}      New attacks                  All features with 95% PCA      75890  0.767453   0.601961  0.017294  0.033622              169.957839"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db1f1d",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bddb4d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=245, ...)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_corr_gt1_pca = XGBClassifier(**{'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}, random_state=random_state)\n",
    "xgb_corr_gt1_pca.fit(X_corr_gt1_pca_train, y_corr_gt1_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1c1493f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9967082059722548\n",
      "Precision: 0.9960374639769453\n",
      "Recall: 0.9963963963963964\n",
      "F1: 0.9962168978562421\n",
      "Time per data per iter: 76.115402\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        xgb_corr_gt1_pca,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c518a206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     15969\n",
      "           1       0.99      0.98      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9898140785338332\n",
      "Precision: 0.9946503258437895\n",
      "Recall: 0.9795019157088123\n",
      "F1: 0.9870180010617249\n",
      "Time per data per iter: 88.7968702\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        xgb_corr_gt1_pca,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97b5fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.69      0.01      0.02     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.73      0.50      0.44     75890\n",
      "weighted avg       0.75      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}\n",
      "Data size: 75890\n",
      "Accuracy: 0.767479246277507\n",
      "Precision: 0.6920289855072463\n",
      "Recall: 0.010759351059035601\n",
      "F1: 0.021189261149323277\n",
      "Time per data per iter: 138.88963130000002\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        xgb_corr_gt1_pca,\n",
    "        \"XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "48f0e297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>22.748850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>46.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.779971</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>122.586580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.994422</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>89.675742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.989147</td>\n",
       "      <td>105.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>169.957839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.996037</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>0.996217</td>\n",
       "      <td>76.115402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989814</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.979502</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>88.796870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767479</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>138.889631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790\n",
       "39  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999765   0.999640  0.999820  0.999730               22.748850\n",
       "40  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.990836   0.999217  0.977586  0.988283               46.506607\n",
       "41  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}      New attacks        |correlation| > 0.1 features scaled      75890  0.779971   0.750952  0.088835  0.158876              122.586580\n",
       "42   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}    Known attacks                  All features with 95% PCA      12759  0.995768   0.994422  0.995856  0.995139               89.675742\n",
       "43   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}  Similar attacks                  All features with 95% PCA      26409  0.991480   0.996307  0.982088  0.989147              105.654334\n",
       "44   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}      New attacks                  All features with 95% PCA      75890  0.767453   0.601961  0.017294  0.033622              169.957839\n",
       "45   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996708   0.996037  0.996396  0.996217               76.115402\n",
       "46   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.989814   0.994650  0.979502  0.987018               88.796870\n",
       "47   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767479   0.692029  0.010759  0.021189              138.889631"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f8d6e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa9bbf",
   "metadata": {},
   "source": [
    "### All features scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "50ad2326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=245)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_scaled = RandomForestClassifier(**{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, random_state=random_state)\n",
    "RF_scaled.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a2f19efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9998432479034407\n",
      "Precision: 0.9998198198198198\n",
      "Recall: 0.9998198198198198\n",
      "F1: 0.9998198198198198\n",
      "Time per data per iter: 140.3135018\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        RF_scaled,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f9125342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     15969\n",
      "           1       1.00      0.97      0.98     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.98      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9874663940323375\n",
      "Precision: 1.0\n",
      "Recall: 0.9682950191570882\n",
      "F1: 0.9838921602024429\n",
      "Time per data per iter: 242.9810671\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        RF_scaled,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6fdf7166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       1.00      0.00      0.01     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.88      0.50      0.44     75890\n",
      "weighted avg       0.82      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7668203979443932\n",
      "Precision: 1.0\n",
      "Recall: 0.0031545741324921135\n",
      "F1: 0.006289308176100629\n",
      "Time per data per iter: 622.6986126\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        RF_scaled,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\",\n",
    "        \"New attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "807c57cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>22.748850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>46.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.779971</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>122.586580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.994422</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>89.675742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.989147</td>\n",
       "      <td>105.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>169.957839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.996037</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>0.996217</td>\n",
       "      <td>76.115402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989814</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.979502</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>88.796870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767479</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>138.889631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>140.313502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.987466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.983892</td>\n",
       "      <td>242.981067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>622.698613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790\n",
       "39  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999765   0.999640  0.999820  0.999730               22.748850\n",
       "40  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.990836   0.999217  0.977586  0.988283               46.506607\n",
       "41  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}      New attacks        |correlation| > 0.1 features scaled      75890  0.779971   0.750952  0.088835  0.158876              122.586580\n",
       "42   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}    Known attacks                  All features with 95% PCA      12759  0.995768   0.994422  0.995856  0.995139               89.675742\n",
       "43   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}  Similar attacks                  All features with 95% PCA      26409  0.991480   0.996307  0.982088  0.989147              105.654334\n",
       "44   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}      New attacks                  All features with 95% PCA      75890  0.767453   0.601961  0.017294  0.033622              169.957839\n",
       "45   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996708   0.996037  0.996396  0.996217               76.115402\n",
       "46   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.989814   0.994650  0.979502  0.987018               88.796870\n",
       "47   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767479   0.692029  0.010759  0.021189              138.889631\n",
       "48             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820              140.313502\n",
       "49             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}  Similar attacks                        All features scaled      26409  0.987466   1.000000  0.968295  0.983892              242.981067\n",
       "50             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}      New attacks                        All features scaled      75890  0.766820   1.000000  0.003155  0.006289              622.698613"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c171d5",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "395dddca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=245)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_corr_gt1_scaled = RandomForestClassifier(**{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, random_state=random_state)\n",
    "RF_corr_gt1_scaled.fit(X_corr_gt1_scaled_train, y_corr_gt1_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f50a6963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9998432479034407\n",
      "Precision: 0.9998198198198198\n",
      "Recall: 0.9998198198198198\n",
      "F1: 0.9998198198198198\n",
      "Time per data per iter: 68.0793478\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        RF_corr_gt1_scaled,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "261c4f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     15969\n",
      "           1       1.00      0.97      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9886402362830853\n",
      "Precision: 0.9998028391167192\n",
      "Recall: 0.971455938697318\n",
      "F1: 0.985425573260785\n",
      "Time per data per iter: 111.21452690000001\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        RF_corr_gt1_scaled,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d460fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.92      0.01      0.01     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.85      0.50      0.44     75890\n",
      "weighted avg       0.80      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Data size: 75890\n",
      "Accuracy: 0.767242060877586\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.005407841369986481\n",
      "F1: 0.01075268817204301\n",
      "Time per data per iter: 308.598819\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        RF_corr_gt1_scaled,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0a089191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>22.748850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>46.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.779971</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>122.586580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.994422</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>89.675742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.989147</td>\n",
       "      <td>105.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>169.957839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.996037</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>0.996217</td>\n",
       "      <td>76.115402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989814</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.979502</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>88.796870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767479</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>138.889631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>140.313502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.987466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.983892</td>\n",
       "      <td>242.981067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>622.698613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>68.079348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988640</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.971456</td>\n",
       "      <td>0.985426</td>\n",
       "      <td>111.214527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767242</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>308.598819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790\n",
       "39  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999765   0.999640  0.999820  0.999730               22.748850\n",
       "40  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.990836   0.999217  0.977586  0.988283               46.506607\n",
       "41  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}      New attacks        |correlation| > 0.1 features scaled      75890  0.779971   0.750952  0.088835  0.158876              122.586580\n",
       "42   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}    Known attacks                  All features with 95% PCA      12759  0.995768   0.994422  0.995856  0.995139               89.675742\n",
       "43   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}  Similar attacks                  All features with 95% PCA      26409  0.991480   0.996307  0.982088  0.989147              105.654334\n",
       "44   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}      New attacks                  All features with 95% PCA      75890  0.767453   0.601961  0.017294  0.033622              169.957839\n",
       "45   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996708   0.996037  0.996396  0.996217               76.115402\n",
       "46   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.989814   0.994650  0.979502  0.987018               88.796870\n",
       "47   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767479   0.692029  0.010759  0.021189              138.889631\n",
       "48             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820              140.313502\n",
       "49             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}  Similar attacks                        All features scaled      26409  0.987466   1.000000  0.968295  0.983892              242.981067\n",
       "50             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}      New attacks                        All features scaled      75890  0.766820   1.000000  0.003155  0.006289              622.698613\n",
       "51             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999843   0.999820  0.999820  0.999820               68.079348\n",
       "52             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.988640   0.999803  0.971456  0.985426              111.214527\n",
       "53             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}      New attacks        |correlation| > 0.1 features scaled      75890  0.767242   0.923077  0.005408  0.010753              308.598819"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f2334",
   "metadata": {},
   "source": [
    "### All features with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cf7ef4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=245)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_pca = RandomForestClassifier(**{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, random_state=random_state)\n",
    "RF_pca.fit(X_pca_train, y_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d977416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      7209\n",
      "         1.0       0.99      0.99      0.99      5550\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9942001724273062\n",
      "Precision: 0.9917385057471264\n",
      "Recall: 0.994954954954955\n",
      "F1: 0.9933441266414823\n",
      "Time per data per iter: 157.9316606\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        RF_pca,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "227441a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     15969\n",
      "           1       1.00      0.98      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9891703585898747\n",
      "Precision: 0.9953170731707317\n",
      "Recall: 0.9772030651340996\n",
      "F1: 0.9861768970517157\n",
      "Time per data per iter: 232.8057097\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        RF_pca,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5a344227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.58      0.01      0.02     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.67      0.50      0.45     75890\n",
      "weighted avg       0.72      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7668203979443932\n",
      "Precision: 0.5782122905027933\n",
      "Recall: 0.011660657954033348\n",
      "F1: 0.022860298177802316\n",
      "Time per data per iter: 525.6598595\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        RF_pca,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\",\n",
    "        \"New attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler_standard,\n",
    "        pca=pca_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dab588ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>22.748850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>46.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.779971</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>122.586580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.994422</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>89.675742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.989147</td>\n",
       "      <td>105.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>169.957839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.996037</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>0.996217</td>\n",
       "      <td>76.115402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989814</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.979502</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>88.796870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767479</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>138.889631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>140.313502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.987466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.983892</td>\n",
       "      <td>242.981067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>622.698613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>68.079348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988640</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.971456</td>\n",
       "      <td>0.985426</td>\n",
       "      <td>111.214527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767242</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>308.598819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>0.991739</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.993344</td>\n",
       "      <td>157.931661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.995317</td>\n",
       "      <td>0.977203</td>\n",
       "      <td>0.986177</td>\n",
       "      <td>232.805710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>525.659860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790\n",
       "39  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999765   0.999640  0.999820  0.999730               22.748850\n",
       "40  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.990836   0.999217  0.977586  0.988283               46.506607\n",
       "41  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}      New attacks        |correlation| > 0.1 features scaled      75890  0.779971   0.750952  0.088835  0.158876              122.586580\n",
       "42   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}    Known attacks                  All features with 95% PCA      12759  0.995768   0.994422  0.995856  0.995139               89.675742\n",
       "43   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}  Similar attacks                  All features with 95% PCA      26409  0.991480   0.996307  0.982088  0.989147              105.654334\n",
       "44   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}      New attacks                  All features with 95% PCA      75890  0.767453   0.601961  0.017294  0.033622              169.957839\n",
       "45   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996708   0.996037  0.996396  0.996217               76.115402\n",
       "46   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.989814   0.994650  0.979502  0.987018               88.796870\n",
       "47   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767479   0.692029  0.010759  0.021189              138.889631\n",
       "48             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820              140.313502\n",
       "49             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}  Similar attacks                        All features scaled      26409  0.987466   1.000000  0.968295  0.983892              242.981067\n",
       "50             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}      New attacks                        All features scaled      75890  0.766820   1.000000  0.003155  0.006289              622.698613\n",
       "51             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999843   0.999820  0.999820  0.999820               68.079348\n",
       "52             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.988640   0.999803  0.971456  0.985426              111.214527\n",
       "53             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}      New attacks        |correlation| > 0.1 features scaled      75890  0.767242   0.923077  0.005408  0.010753              308.598819\n",
       "54             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}    Known attacks                  All features with 95% PCA      12759  0.994200   0.991739  0.994955  0.993344              157.931661\n",
       "55             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}  Similar attacks                  All features with 95% PCA      26409  0.989170   0.995317  0.977203  0.986177              232.805710\n",
       "56             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}      New attacks                  All features with 95% PCA      75890  0.766820   0.578212  0.011661  0.022860              525.659860"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc7e1a",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7b430f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=50, random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, random_state=245)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_corr_gt1_pca = RandomForestClassifier(**{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, random_state=random_state)\n",
    "RF_corr_gt1_pca.fit(X_corr_gt1_pca_train, y_corr_gt1_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "433f5471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7209\n",
      "         1.0       1.00      1.00      1.00      5550\n",
      "\n",
      "    accuracy                           1.00     12759\n",
      "   macro avg       1.00      1.00      1.00     12759\n",
      "weighted avg       1.00      1.00      1.00     12759\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9968649580688141\n",
      "Precision: 0.9962175792507204\n",
      "Recall: 0.9965765765765766\n",
      "F1: 0.9963970455773734\n",
      "Time per data per iter: 84.76015890000001\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        RF_corr_gt1_pca,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6ee89dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     15969\n",
      "           1       1.00      0.98      0.99     10440\n",
      "\n",
      "    accuracy                           0.99     26409\n",
      "   macro avg       0.99      0.99      0.99     26409\n",
      "weighted avg       0.99      0.99      0.99     26409\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9904577984777917\n",
      "Precision: 0.9974609375\n",
      "Recall: 0.9783524904214559\n",
      "F1: 0.9878143133462282\n",
      "Time per data per iter: 135.49947469999998\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        RF_corr_gt1_pca,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d69d190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.63      0.01      0.01     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.70      0.50      0.44     75890\n",
      "weighted avg       0.73      0.77      0.67     75890\n",
      "\n",
      "\n",
      "Model: Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7666490973777836\n",
      "Precision: 0.6287425149700598\n",
      "Recall: 0.005914826498422713\n",
      "F1: 0.011719403984597355\n",
      "Time per data per iter: 272.3147027\n"
     ]
    }
   ],
   "source": [
    "benchmark_util.benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        RF_corr_gt1_pca,\n",
    "        \"Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_standard_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1_standard\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d06a703c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997207</td>\n",
       "      <td>518.729681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1037.263033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767137</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>2984.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>362.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.974617</td>\n",
       "      <td>0.985950</td>\n",
       "      <td>749.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>2147.515065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>689.647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991064</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.988603</td>\n",
       "      <td>1514.053682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>3798.191619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.995935</td>\n",
       "      <td>428.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>830.623430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2294.048158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.817384</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>9.916843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.661065</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.791856</td>\n",
       "      <td>19.194764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB {'var_smoothing': 1.519911082952933e-07}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.268195</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>50.294952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.715897</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>4.696661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.671891</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>7.988778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.699697</td>\n",
       "      <td>0.319349</td>\n",
       "      <td>0.250845</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>28.354416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>15.768047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.764229</td>\n",
       "      <td>30.440379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GaussianNB {'var_smoothing': 4.328761281083053e-06}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.664356</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>83.339836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>12.798576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.980172</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>22.165475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GaussianNB {'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.793372</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.185613</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>41.311833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>6.336827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>18.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>36.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>11.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>15.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>24.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974189</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>16.594933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>0.972126</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>22.988990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>72.396318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>7.628298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>13.880256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>30.204715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>39.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>51.635735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>126.804790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>22.748850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>46.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.779971</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>122.586580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.994422</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>89.675742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.989147</td>\n",
       "      <td>105.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>169.957839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.996037</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>0.996217</td>\n",
       "      <td>76.115402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989814</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.979502</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>88.796870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767479</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>138.889631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>140.313502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.987466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.983892</td>\n",
       "      <td>242.981067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>622.698613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>68.079348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.988640</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.971456</td>\n",
       "      <td>0.985426</td>\n",
       "      <td>111.214527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767242</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>308.598819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>0.991739</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.993344</td>\n",
       "      <td>157.931661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.995317</td>\n",
       "      <td>0.977203</td>\n",
       "      <td>0.986177</td>\n",
       "      <td>232.805710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.578212</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>525.659860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.996218</td>\n",
       "      <td>0.996577</td>\n",
       "      <td>0.996397</td>\n",
       "      <td>84.760159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.997461</td>\n",
       "      <td>0.978352</td>\n",
       "      <td>0.987814</td>\n",
       "      <td>135.499475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766649</td>\n",
       "      <td>0.628743</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>272.314703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks                        All features scaled      12759  0.997570   0.997118  0.997297  0.997207              518.729681\n",
       "1                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks                        All features scaled      26409  0.990458   0.994659  0.981130  0.987848             1037.263033\n",
       "2                                                                  SVM {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks                        All features scaled      75890  0.767137   0.656250  0.009464  0.018658             2984.306780\n",
       "3                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.995768   0.997106  0.993153  0.995125              362.891143\n",
       "4                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.989019   0.997549  0.974617  0.985950              749.063748\n",
       "5                                                                 SVM {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}      New attacks        |correlation| > 0.1 features scaled      75890  0.765621   0.382550  0.003211  0.006368             2147.515065\n",
       "6                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks                  All features with 95% PCA      12759  0.996865   0.995504  0.997297  0.996400              689.647095\n",
       "7                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks                  All features with 95% PCA      26409  0.991064   0.996884  0.980460  0.988603             1514.053682\n",
       "8                                                                   SVM {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks                  All features with 95% PCA      75890  0.766820   0.619658  0.008168  0.016124             3798.191619\n",
       "9                                                                  SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996473   0.998551  0.993333  0.995935              428.190194\n",
       "10                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.988602   0.999311  0.971839  0.985383              830.623430\n",
       "11                                                                 SVM {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766386   0.586466  0.004394  0.008722             2294.048158\n",
       "12                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}    Known attacks                        All features scaled      12759  0.817384   0.706888  0.991171  0.825233                9.916843\n",
       "13                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}  Similar attacks                        All features scaled      26409  0.794843   0.661065  0.987165  0.791856               19.194764\n",
       "14                                                               GaussianNB {'var_smoothing': 1.519911082952933e-07}      New attacks                        All features scaled      75890  0.691343   0.313347  0.268195  0.289018               50.294952\n",
       "15                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks        |correlation| > 0.1 features scaled      12759  0.826005   0.715897  0.994775  0.832604                4.696661\n",
       "16                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.805672   0.671891  0.993678  0.801700                7.988778\n",
       "17                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks        |correlation| > 0.1 features scaled      75890  0.699697   0.319349  0.250845  0.280982               28.354416\n",
       "18                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}    Known attacks                  All features with 95% PCA      12759  0.785563   0.671669  0.991892  0.800960               15.768047\n",
       "19                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}  Similar attacks                  All features with 95% PCA      26409  0.760006   0.624742  0.983908  0.764229               30.440379\n",
       "20                                                               GaussianNB {'var_smoothing': 4.328761281083053e-06}      New attacks                  All features with 95% PCA      75890  0.664356   0.382874  0.710793  0.497673               83.339836\n",
       "21                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.934556   0.922718  0.927207  0.924957               12.798576\n",
       "22                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.968685   0.942873  0.980172  0.961161               22.165475\n",
       "23                                                               GaussianNB {'var_smoothing': 0.0005336699231206307}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.793372   0.729144  0.185613  0.295900               41.311833\n",
       "24                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361                6.336827\n",
       "25                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231               18.706266\n",
       "26                                              Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534               36.033333\n",
       "27                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168               11.029500\n",
       "28                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773               15.147631\n",
       "29                                         Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615               24.300656\n",
       "30                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}    Known attacks                  All features with 95% PCA      12759  0.979701   0.974189  0.979279  0.976727               16.594933\n",
       "31                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  Similar attacks                  All features with 95% PCA      26409  0.982506   0.983430  0.972126  0.977746               22.988990\n",
       "32                                              Logistic Regression {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}      New attacks                  All features with 95% PCA      75890  0.767308   0.533333  0.041911  0.077715               72.396318\n",
       "33                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263                7.628298\n",
       "34                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829               13.880256\n",
       "35                                              Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453               30.204715\n",
       "36  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820               39.134597\n",
       "37  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}  Similar attacks                        All features scaled      26409  0.989170   0.999312  0.973276  0.986122               51.635735\n",
       "38  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 1}      New attacks                        All features scaled      75890  0.762327   0.275591  0.009858  0.019035              126.804790\n",
       "39  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999765   0.999640  0.999820  0.999730               22.748850\n",
       "40  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.990836   0.999217  0.977586  0.988283               46.506607\n",
       "41  XGBClassifier {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 800, 'scale_pos_weight': 5}      New attacks        |correlation| > 0.1 features scaled      75890  0.779971   0.750952  0.088835  0.158876              122.586580\n",
       "42   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}    Known attacks                  All features with 95% PCA      12759  0.995768   0.994422  0.995856  0.995139               89.675742\n",
       "43   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}  Similar attacks                  All features with 95% PCA      26409  0.991480   0.996307  0.982088  0.989147              105.654334\n",
       "44   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'scale_pos_weight': 1}      New attacks                  All features with 95% PCA      75890  0.767453   0.601961  0.017294  0.033622              169.957839\n",
       "45   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996708   0.996037  0.996396  0.996217               76.115402\n",
       "46   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.989814   0.994650  0.979502  0.987018               88.796870\n",
       "47   XGBClassifier {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'scale_pos_weight': 1}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767479   0.692029  0.010759  0.021189              138.889631\n",
       "48             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}    Known attacks                        All features scaled      12759  0.999843   0.999820  0.999820  0.999820              140.313502\n",
       "49             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}  Similar attacks                        All features scaled      26409  0.987466   1.000000  0.968295  0.983892              242.981067\n",
       "50             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}      New attacks                        All features scaled      75890  0.766820   1.000000  0.003155  0.006289              622.698613\n",
       "51             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}    Known attacks        |correlation| > 0.1 features scaled      12759  0.999843   0.999820  0.999820  0.999820               68.079348\n",
       "52             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.988640   0.999803  0.971456  0.985426              111.214527\n",
       "53             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}      New attacks        |correlation| > 0.1 features scaled      75890  0.767242   0.923077  0.005408  0.010753              308.598819\n",
       "54             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}    Known attacks                  All features with 95% PCA      12759  0.994200   0.991739  0.994955  0.993344              157.931661\n",
       "55             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}  Similar attacks                  All features with 95% PCA      26409  0.989170   0.995317  0.977203  0.986177              232.805710\n",
       "56             Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}      New attacks                  All features with 95% PCA      75890  0.766820   0.578212  0.011661  0.022860              525.659860\n",
       "57              Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.996865   0.996218  0.996577  0.996397               84.760159\n",
       "58              Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.990458   0.997461  0.978352  0.987814              135.499475\n",
       "59              Random Forest {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.766649   0.628743  0.005915  0.011719              272.314703"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_util.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ad101d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_util.to_csv(\"benchmark_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
